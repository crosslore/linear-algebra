\subsection{Matrix multiplication}

The multiplication of a matrix and a vector from the previous section
is a special case of the operation of multiplying two matrices, which
we now define.

\begin{definition}{Matrix multiplication}{matrix-multiplication}
  Let $A=\mat{a_{ij}}$ be an $m\times n$-matrix, and let
  $B=\mat{b_{jk}}$ be an $n\times p$-matrix. Then their product%
  \index{matrix!multiplication}%
  \index{multiplication!of matrices}%
  \index{product|see{multiplication}}%
  \index{matrix!multiplication!componentwise method}%
  \index{componentwise method!matrix multiplication} is the
  $m\times p$-matrix $AB=\mat{c_{ik}}$ whose $(i,k)$-entry is defined
  by
  \begin{equation*}
    c_{ik} = a_{i1}b_{1k} + a_{i2}b_{2k} + \ldots + a_{in}b_{nk}.
  \end{equation*}
\end{definition}

For matrices $A$ and $B$, in order to form the product $AB$, the
number of columns of $A$ must equal the number of rows of
$B$. Consider a product $AB$ where $A$ has dimensions $m\times n$ and
$B$ has dimensions $n \times p$. Then the dimensions of the product
are given by
\begin{equation*}
  (\overset{\text{these must match!}}{m\times\widehat{n)\;(n}\times p})=m\times p.
\end{equation*}
Note that the two outside numbers give the dimensions of the
product. If the two middle numbers do not match, we cannot multiply
the matrices.

To better visualize the rule of matrix multiplication, suppose
\begin{equation*}
  A = \begin{mymatrix}{cccc}
    a_{11} & a_{12} & \cdots & a_{1n} \\
    a_{21} & a_{22} & \cdots & a_{2n} \\
    \vdots & \vdots & \ddots & \vdots \\
    a_{m1} & a_{m2} & \cdots & a_{mn} \\
  \end{mymatrix}
  \quad\mbox{and}\quad
  B = \begin{mymatrix}{cccc}
    b_{11} & b_{12} & \cdots & b_{1p} \\
    b_{21} & b_{22} & \cdots & b_{2p} \\
    \vdots & \vdots & \ddots & \vdots \\
    b_{n1} & b_{n2} & \cdots & b_{np} \\
  \end{mymatrix}.
\end{equation*}
Then their product
\begin{equation*}
  AB = \begin{mymatrix}{cccc}
    c_{11} & c_{12} & \cdots & c_{1p} \\
    c_{21} & c_{22} & \cdots & c_{2p} \\
    \vdots & \vdots & \ddots & \vdots \\
    c_{m1} & c_{m2} & \cdots & c_{mp} \\
  \end{mymatrix}
\end{equation*}
is an $m\times p$-matrix whose $(i,k)$-entry is defined by
\begin{equation*}
  c_{ik} = a_{i1}b_{1k} + a_{i2}b_{2k} + \ldots + a_{in}b_{nk}.
\end{equation*}
Note that we can also write this as
\begin{equation*}
  c_{ik} ~=~ \begin{mymatrix}{cccc}a_{i1} & a_{i2} & \cdots & a_{in}\end{mymatrix}
  \begin{mymatrix}{c}b_{1k} \\ b_{2k} \\ \vdots \\ b_{nk}\end{mymatrix}.
\end{equation*}
In other words, the $(i,k)$-entry of the matrix product $AB$ is a kind
of dot product of the $i\th$ row of $A$ with the $k\th$ column of $B$.

\begin{example}{Matrix multiplication}{matrix-multiplication}
  Find $AB$, where
  \begin{equation*}
    A = \begin{mymatrix}{rrr}
      1 & 2 & 1 \\
      0 & 2 & 1
    \end{mymatrix}
    \quad\mbox{and}\quad
    B = \begin{mymatrix}{rrr}
      1 & 2 & 0 \\
      0 & 3 & 1 \\
      -2 & 1 & 1
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  First, let us note that since $A$ has size $2\times 3$ and $B$ has
  size $3\times 3$, the product $AB$ is well-defined and has size
  $2\times 3$. Let $C=AB$. We compute each of the six entries of $C$:
  \begin{itemize}
  \item The $(1,1)$-entry is the first row of $A$ times the first
    column of $B$: $c_{11} = 1\cdot 1+2\cdot 0+1\cdot(-2) = -1$.
  \item The $(1,2)$-entry is the first row of $A$ times the second
    column of $B$: $c_{12} = 1\cdot 2+2\cdot 3+1\cdot 1 = 9$.
  \item The $(1,3)$-entry is the first row of $A$ times the third
    column of $B$: $c_{13} = 1\cdot 0+2\cdot 1+1\cdot 1 = 3$.
  \item The $(2,1)$-entry is the second row of $A$ times the first
    column of $B$: $c_{21} = 0\cdot 1+2\cdot 0+1\cdot(-2) = -2$.
  \item The $(2,2)$-entry is the second row of $A$ times the second
    column of $B$: $c_{22} = 0\cdot 2+2\cdot 3+1\cdot 1 = 7$.
  \item The $(2,3)$-entry is the second row of $A$ times the third
    column of $B$: $c_{23} = 0\cdot 0+2\cdot 1+1\cdot 1 = 3$.
  \end{itemize}
  Therefore, we have
  \begin{equation*}
    AB = \begin{mymatrix}{rrr}
      -1 & 9 & 3 \\
      -2 & 7 & 3
    \end{mymatrix}.
  \end{equation*}
\end{solution}

As this example shows, calculating matrix products one component at a
time can be an extremely repetitive and tedious process. Fortunately,
we can speed this up by considering whole columns at once.

\begin{proposition}{Matrix multiplication, column method}{matrix-multiplication-columns}
  Let $A$ be an $m\times n$-matrix, and let $B$ be an
  $n\times p$-matrix.  Suppose that the columns of $B$ are
  $\vect{b}_1,\vect{b}_2,\ldots,\vect{b}_p$. Then the columns of $AB$
  are%
  \index{matrix!multiplication!column method}%
  \index{column method!matrix multiplication}
  \begin{equation*}
    A\vect{b}_1,~A\vect{b}_2,~\ldots,~A\vect{b}_p.
  \end{equation*}
  In other words, the $k\th$ column of the matrix product $AB$ is
  equal to $A$ times the $k\th$ column of $B$.
\end{proposition}

\begin{example}{Matrix multiplication by the column method}{matrix-multiplication-columns}
  Find the matrix product $AB$ by the column method, where
  \begin{equation*}
    A = \begin{mymatrix}{rrr}
      1 & 2 & 1 \\
      0 & 2 & 1
    \end{mymatrix}
    \quad\mbox{and}\quad
    B = \begin{mymatrix}{rrr}
      1 & 2 & 0 \\
      0 & 3 & 1 \\
      -2 & 1 & 1
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We multiply $A$ by each of the columns of $B$:
  \begin{equation*}
    \begin{mymatrix}{rrr}
      1 & 2 & 1 \\
      0 & 2 & 1
    \end{mymatrix}
    \begin{mymatrix}{r}
      1 \\
      0 \\
      -2
    \end{mymatrix}
    ~=~
    1 \begin{mymatrix}{r} 1 \\ 0 \end{mymatrix}
    + 0 \begin{mymatrix}{r} 2 \\ 2 \end{mymatrix}
    - 2 \begin{mymatrix}{r} 1 \\ 1 \end{mymatrix}
    ~=~
    \begin{mymatrix}{r}
      -1 \\
      -2
    \end{mymatrix},
  \end{equation*}
  \begin{equation*}
    \begin{mymatrix}{rrr}
      1 & 2 & 1 \\
      0 & 2 & 1
    \end{mymatrix}
    \begin{mymatrix}{r}
      2 \\
      3 \\
      1
    \end{mymatrix}
    ~=~
    2 \begin{mymatrix}{r} 1 \\ 0 \end{mymatrix}
    + 3 \begin{mymatrix}{r} 2 \\ 2 \end{mymatrix}
    + 1 \begin{mymatrix}{r} 1 \\ 1 \end{mymatrix}
    ~=~
    \begin{mymatrix}{r}
      9 \\
      7
    \end{mymatrix},
  \end{equation*}
  \begin{equation*}
    \begin{mymatrix}{rrr}
      1 & 2 & 1 \\
      0 & 2 & 1
    \end{mymatrix}
    \begin{mymatrix}{r}
      0 \\
      1 \\
      1
    \end{mymatrix}
    ~=~
    0 \begin{mymatrix}{r} 1 \\ 0 \end{mymatrix}
    + 1 \begin{mymatrix}{r} 2 \\ 2 \end{mymatrix}
    + 1 \begin{mymatrix}{r} 1 \\ 1 \end{mymatrix}
    ~=~
    \begin{mymatrix}{r}
      3 \\
      3
    \end{mymatrix}.
  \end{equation*}
  The resulting three column vectors form the columns of $AB$.  Thus,
  \begin{equation*}
    AB ~=~ \begin{mymatrix}{rrr}
      -1 & 9 & 3 \\
      -2 & 7 & 3
    \end{mymatrix}.
  \end{equation*}
\end{solution}

Of course, the answer in
Example~\ref{exa:matrix-multiplication-columns} is the same as that in
Example~\ref{exa:matrix-multiplication}. Please convince yourself that
both methods of matrix multiplication give the same answer, since they
each ultimately calculate the same thing. Nevertheless, with a bit of
practice, the column method is much faster, and you can even learn to
multiply matrices in your head! The key to understanding the column
method is that each column of $B$ provides instructions for taking a
linear combination of the columns of $A$. The method works especially
well if $B$ contains many zeros and ones.

Since column vectors are simply $n\times 1$-matrices, and row vectors
are $1\times m$-matrices, we can also multiply a column vector by a
row vector or vice versa.

\begin{example}{Column vector times row vector}{column-times-row}
  Multiply $\begin{mymatrix}{r}
    1 \\
    2 \\
    1
  \end{mymatrix}
  \begin{mymatrix}{rrrr}
    1 & 2 & 1 & 0
  \end{mymatrix}$.
\end{example}

\begin{solution}
  Here we are multiplying a $3\times 1$-matrix by a
  $1\times 4$-matrix, so the result will be a $3\times
  4$-matrix. Using the column method, we can compute this product as
  follows:
  \begin{equation*}
    \begin{mymatrix}{r}
      1 \\
      2 \\
      1
    \end{mymatrix} \begin{mymatrix}{rrrr}
      1 & 2 & 1 & 0
    \end{mymatrix} =
    \mat{
      \overset{\text{First column}}{
        \overbrace{
          \begin{mymatrix}{r}
            1 \\
            2 \\
            1
          \end{mymatrix}
          \begin{mymatrix}{r}
            1
          \end{mymatrix}
        }
      },
      \overset{\text{Second column}}{
        \overbrace{
          \begin{mymatrix}{r}
            1 \\
            2 \\
            1
          \end{mymatrix}
          \begin{mymatrix}{r}
            2
          \end{mymatrix}
        }
      },
      \overset{\text{Third column}}{
        \overbrace{
          \begin{mymatrix}{r}
            1 \\
            2 \\
            1
          \end{mymatrix}
          \begin{mymatrix}{r}
            1
          \end{mymatrix}
        }
      },
      \overset {\text{Fourth column}}{
        \overbrace{
          \begin{mymatrix}{r}
            1 \\
            2 \\
            1
          \end{mymatrix}
          \begin{mymatrix}{r}
            0
          \end{mymatrix}
        }}
    }
    ~=~
    \begin{mymatrix}{rrrr}
      1 & 2 & 1 & 0 \\
      2 & 4 & 2 & 0 \\
      1 & 2 & 1 & 0
    \end{mymatrix}
  \end{equation*}
\end{solution}

\begin{example}{Row vector times column vector}{row-times-column}
  Multiply $\begin{mymatrix}{rrrr}
    1 & 2 & 3
  \end{mymatrix}
  \begin{mymatrix}{r}
    1 \\
    2 \\
    -1
  \end{mymatrix}$.
\end{example}

\begin{solution}
  Here we are multiplying a $1\times 3$-matrix by a $3\times
  1$-matrix, so the result will be a $1\times 1$-matrix, or in other
  words, a scalar. (We regard a scalar and a $1\times 1$-matrix as the
  same thing). We have:
  \begin{equation*}
    \begin{mymatrix}{rrrr}
      1 & 2 & 3
    \end{mymatrix}
    \begin{mymatrix}{r}
      1 \\
      2 \\
      -1
    \end{mymatrix}
    ~=~
    1\cdot 1 + 2\cdot 2 + 3\cdot(-1) = 2.
  \end{equation*}
  Therefore, multiplying a row vector by a column vector works very
  similarly to an ordinary dot product (except that the dot product is
  defined between two column vectors, not a row vector and a column
  vector).
\end{solution}

\begin{example}{A multiplication that is not defined}{undefined-matrix-multiplication}
  Find $BA$, where
  \begin{equation*}
    B = \begin{mymatrix}{rrr}
      1 & 2 & 0 \\
      0 & 3 & 1 \\
      -2 & 1 & 1
    \end{mymatrix}
    \quad\mbox{and}\quad
    A = \begin{mymatrix}{rrr}
      1 & 2 & 1 \\
      0 & 2 & 1
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  The product $BA$ is not defined, since $B$ is a $3\times 3$-matrix
  and $A$ is a $2\times 3$-matrix. Since the number of columns of $B$
  does not match the number of rows of $A$, the product is not defined.
\end{solution}

Notice that the matrices in
Example~\ref{exa:undefined-matrix-multiplication} are the same as
those in Example~\ref{exa:matrix-multiplication}.  This
demonstrates an important property of matrix multiplication: it is
possible that $AB$ is defined by $BA$ is undefined. Even if $AB$ and
$BA$ are both defined, they may not be equal, as the following example
shows. Therefore, matrix multiplication is not commutative.

\begin{example}{Matrix multiplication is not commutative}{matrix-multiplication-not-commutative}
  Compute $AB$ and $BA$, where
  \begin{equation*}
    A ~=~ \begin{mymatrix}{rr}
      1 & 2 \\
      3 & 4
    \end{mymatrix}
    \quad\mbox{and}\quad
    B ~=~ \begin{mymatrix}{rr}
      0 & 1 \\
      1 & 0
    \end{mymatrix}
  \end{equation*}
  Are they equal?
\end{example}

\begin{solution}
  We have
  \begin{equation*}
    AB ~=~
    \begin{mymatrix}{rr}
      1 & 2 \\
      3 & 4
    \end{mymatrix}
    \begin{mymatrix}{rr}
      0 & 1 \\
      1 & 0
    \end{mymatrix}
    ~=~
    \begin{mymatrix}{rr}
      2 & 1 \\
      4 & 3
    \end{mymatrix}
  \end{equation*}
  and
  \begin{equation*}
    BA ~=~
    \begin{mymatrix}{rr}
      0 & 1 \\
      1 & 0
    \end{mymatrix}
    \begin{mymatrix}{rr}
      1 & 2 \\
      3 & 4
    \end{mymatrix}
    ~=~
    \begin{mymatrix}{rr}
      3 & 4 \\
      1 & 2
    \end{mymatrix}.
  \end{equation*}
  Therefore, $AB$ and $BA$ are not equal. Matrix multiplication is not
  commutative.
\end{solution}

We have seen two methods for matrix multiplication: one component at a
time, and by the column method. There is also a third method, called
the row method. It is exactly symmetric to the column method.

\begin{proposition}{Matrix multiplication, row method}{matrix-multiplication-rows}
  Let $A$ be an $m\times n$-matrix, and let $B$ be an
  $n\times p$-matrix.  Suppose that the rows of $A$ are
  $\vect{a}_1,\vect{a}_2,\ldots,\vect{a}_m$. Then the rows of $AB$
  are%
  \index{matrix!multiplication!row method}%
  \index{row method!matrix multiplication}
  \begin{equation*}
    \vect{a}_1B,~\vect{a}_2B,~\ldots,~\vect{a}_mB.
  \end{equation*}
  In other words, the $i\th$ column of the matrix product $AB$ is
  equal to the $i\th$ column of $A$ times $B$.
\end{proposition}

\begin{example}{Matrix multiplication by the row method}{matrix-multiplication-rows}
  Find the matrix product $AB$ by the row method, where
  \begin{equation*}
    A = \begin{mymatrix}{rrr}
      1 & 2 & 1 \\
      0 & 2 & 1
    \end{mymatrix}
    \quad\mbox{and}\quad
    B = \begin{mymatrix}{rrr}
      1 & 2 & 0 \\
      0 & 3 & 1 \\
      -2 & 1 & 1
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We multiply each of the rows of $A$ by $B$:
  \begin{equation*}
    \begin{mymatrix}{rrr}
      1 & 2 & 1
    \end{mymatrix}
    \begin{mymatrix}{rrr}
      1 & 2 & 0 \\
      0 & 3 & 1 \\
      -2 & 1 & 1
    \end{mymatrix}
    ~=~
    1 \begin{mymatrix}{rrr} 1 & 2 & 0 \end{mymatrix}
    + 2 \begin{mymatrix}{rrr} 0 & 3 & 1 \end{mymatrix}
    + 1 \begin{mymatrix}{rrr} -2 & 1 & 1 \end{mymatrix}
    ~=~
    \begin{mymatrix}{rrr} -1 & 9 & 3 \end{mymatrix},
  \end{equation*}
  \begin{equation*}
    \begin{mymatrix}{rrr}
      0 & 2 & 1
    \end{mymatrix}
    \begin{mymatrix}{rrr}
      1 & 2 & 0 \\
      0 & 3 & 1 \\
      -2 & 1 & 1
    \end{mymatrix}
    ~=~
    0 \begin{mymatrix}{rrr} 1 & 2 & 0 \end{mymatrix}
    + 2 \begin{mymatrix}{rrr} 0 & 3 & 1 \end{mymatrix}
    + 1 \begin{mymatrix}{rrr} -2 & 1 & 1 \end{mymatrix}
    ~=~
    \begin{mymatrix}{rrr} -2 & 7 & 3 \end{mymatrix}.
  \end{equation*}
  The resulting two row vectors form the rows of $AB$.  Thus,
  \begin{equation*}
    AB ~=~ \begin{mymatrix}{rrr}
      -1 & 9 & 3 \\
      -2 & 7 & 3
    \end{mymatrix}.
  \end{equation*}
  Once again this is the same answer as in
  Examples~\ref{exa:matrix-multiplication-columns} and
  {\ref{exa:matrix-multiplication}}. All three methods give the same
  result. But notice how in the row method, each row of $A$ provides
  instructions for taking a linear combinations of the rows of $B$.
\end{solution}

We finish this section by introducing an important square matrix
called the identity matrix.

\begin{definition}{Identity matrix}{identity-matrix}
  The \textbf{identity matrix}%
  \index{matrix!identity}%
  \index{identity matrix} of size $n\times n$ has ones along the
  diagonal, and zeros everywhere else. In other words, it is the
  matrix $\mat{\delta_{ij}}$ where $\delta_{ij}=1$ if $i=j$ and
  $\delta_{ij}=0$ otherwise. The identity matrix is always a square
  matrix. Here are some identity matrices of various sizes.
  \begin{equation*}
    \begin{mymatrix}{r}
      1
    \end{mymatrix},
    \quad
    \begin{mymatrix}{cc}
      1 & 0 \\
      0 & 1
    \end{mymatrix},
    \quad
    \begin{mymatrix}{ccc}
      1 & 0 & 0 \\
      0 & 1 & 0 \\
      0 & 0 & 1
    \end{mymatrix},
    \quad
    \begin{mymatrix}{cccc}
      1 & 0 & 0 & 0 \\
      0 & 1 & 0 & 0 \\
      0 & 0 & 1 & 0 \\
      0 & 0 & 0 & 1
    \end{mymatrix}.
  \end{equation*}
  When it is necessary to distinguish which size of identity matrix is
  being discussed, we will use the notation $I_n$ for the $n\times n$
  identity matrix.
\end{definition}

\begin{example}{Multiplying by the identity matrix}{identity-multiply}
  Calculate $AI$, where $I$ is the $2\times 2$ identity matrix and
  \begin{equation*}
    A ~=~ \begin{mymatrix}{rr}
      a_{11} & a_{12} \\
      a_{21} & a_{22} \\
      a_{31} & a_{32} \\
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We need to calculate
  \begin{equation*}
    AI ~=~
    \begin{mymatrix}{rr}
      a_{11} & a_{12} \\
      a_{21} & a_{22} \\
      a_{31} & a_{32} \\
    \end{mymatrix}
    \begin{mymatrix}{rr}
      1 & 0 \\
      0 & 1
    \end{mymatrix}.
  \end{equation*}
  Using the column method, we find that the first column of $AI$ is
  \begin{equation*}
    \begin{mymatrix}{rr}
      a_{11} & a_{12} \\
      a_{21} & a_{22} \\
      a_{31} & a_{32} \\
    \end{mymatrix}
    \begin{mymatrix}{r}
      1 \\
      0
    \end{mymatrix}
    ~=~
    1 \begin{mymatrix}{rr}
      a_{11} \\
      a_{21} \\
      a_{31} \\
    \end{mymatrix}
    + 0 \begin{mymatrix}{rr}
      a_{12} \\
      a_{22} \\
      a_{32} \\
    \end{mymatrix}
    ~=~
    \begin{mymatrix}{rr}
      a_{11} \\
      a_{21} \\
      a_{31} \\
    \end{mymatrix},
  \end{equation*}
  which is exactly the same as the first column of $A$.
  Similarly, the second column of $AI$ is
  \begin{equation*}
    \begin{mymatrix}{rr}
      a_{11} & a_{12} \\
      a_{21} & a_{22} \\
      a_{31} & a_{32} \\
    \end{mymatrix}
    \begin{mymatrix}{r}
      0 \\
      1
    \end{mymatrix}
    ~=~
    0 \begin{mymatrix}{rr}
      a_{11} \\
      a_{21} \\
      a_{31} \\
    \end{mymatrix}
    + 1 \begin{mymatrix}{rr}
      a_{12} \\
      a_{22} \\
      a_{32} \\
    \end{mymatrix}
    ~=~
    \begin{mymatrix}{rr}
      a_{12} \\
      a_{22} \\
      a_{32} \\
    \end{mymatrix},
  \end{equation*}
  which is exactly the same as the second column of $A$. Therefore
  \begin{equation*}
    AI ~=~
    \begin{mymatrix}{rr}
      a_{11} & a_{12} \\
      a_{21} & a_{22} \\
      a_{31} & a_{32} \\
    \end{mymatrix}
    ~=~ A.
  \end{equation*}
\end{solution}

The calculation of the last example generalizes to matrices of all
sizes, and is summarized in the following proposition.

\begin{proposition}{Multiplying by the identity matrix}{identity-matrix}
  Let $A$ be any $m\times n$-matrix. Then
  \begin{equation*}
    I_mA = A = AI_n.
  \end{equation*}
\end{proposition}

We can also raise a square matrix to a power. For example, $A^5$ means
$A\cdot A\cdot A\cdot A\cdot A$.

\begin{example}{Raising a matrix to a power}{matrix-power}
  Compute $A^3$, where
  \begin{equation*}
    A = \begin{mymatrix}{rr}
      1 & 2 \\
      -2 & 3 \\
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We have
  \begin{equation*}
    A^3 = A\cdot A\cdot A
    = \begin{mymatrix}{rr}
      1 & 2 \\
      -2 & 3 \\
    \end{mymatrix}
    \begin{mymatrix}{rr}
      1 & 2 \\
      -2 & 3 \\
    \end{mymatrix}
    \begin{mymatrix}{rr}
      1 & 2 \\
      -2 & 3 \\
    \end{mymatrix}
    =
    \begin{mymatrix}{rr}
      -3 & 8 \\
      -8 & 5 \\
    \end{mymatrix}
    \begin{mymatrix}{rr}
      1 & 2 \\
      -2 & 3 \\
    \end{mymatrix}
    =
    \begin{mymatrix}{rr}
      -19 & 18 \\
      -18 & -1 \\
    \end{mymatrix}.
  \end{equation*}
\end{solution}
