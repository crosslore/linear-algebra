
\subsection{The matrix exponential}

The goal of this section is to use the concept of the matrix exponential to solve first order linear differential equations. We begin by proving the matrix exponential. 

Suppose $A$ is a diagonalizable matrix. Then the {\bf matrix exponential}\index{matrix exponential}, written $e^{A}$, can be easily defined. 
Recall that if $D$ is a diagonal matrix, then  
\begin{equation*}
P^{-1}AP=D
\end{equation*}
$D$ is of the form 
\begin{equation}
\begin{mymatrix}{ccc}
\lambda _{1} &  & 0 \\ 
& \ddots &  \\ 
0 &  & \lambda _{n}
\end{mymatrix}  \label{diagonal-matrix}
\end{equation}
and it follows that 
\begin{equation*}
D^{m}=\begin{mymatrix}{ccc}
\lambda _{1}^{m} &  & 0 \\ 
& \ddots &  \\ 
0 &  & \lambda _{n}^{m}
\end{mymatrix}
\end{equation*}

Since $A$ is diagonalizable, 
\begin{equation*}
A=PDP^{-1}
\end{equation*}
and
\begin{equation*}
A^{m}=PD^{m}P^{-1}
\end{equation*}

Recall why this is true. 
\begin{equation*}
A=PDP^{-1}
\end{equation*}
and so 
\begin{eqnarray*}
A^{m} &=&\overset{
\text{m times}}{\overbrace{PDP^{-1}PDP^{-1}PDP^{-1}\cdots PDP^{-1}}} \\
&=&PD^{m}P^{-1}
\end{eqnarray*}

We now will examine what is meant by the matrix exponential $e^{A}$. Begin by formally writing the following power series for $e^{A}$:
\begin{equation*}
e^{A} =  \sum_{k=0}^{\infty }\frac{A^{k}}{k!}=\sum_{k=0}^{\infty }\frac{PD^{k}P^{-1}}{k!}=P \tup{\sum_{k=0}^{\infty }\frac{D^{k}}{k!} }P^{-1}
\end{equation*}
If $D$ is given above in {\eqref{diagonal-matrix}}, the above sum is of the form 
\begin{equation*}
P \tup{\sum_{k=0}^{\infty }\begin{mymatrix}{ccc}
\frac{1}{k!}\lambda _{1}^{k} &  & 0 \\ 
& \ddots &  \\ 
0 &  & \frac{1}{k!}\lambda _{n}^{k}
\end{mymatrix} } P^{-1}
\end{equation*}
This can be rearranged as follows:
\begin{equation*}
e^{A}=P\begin{mymatrix}{ccc}
\sum_{k=0}^{\infty }\frac{1}{k!}\lambda _{1}^{k} &  & 0 \\ 
& \ddots &  \\ 
0 &  & \sum_{k=0}^{\infty }\frac{1}{k!}\lambda _{n}^{k}
\end{mymatrix} P^{-1}
\end{equation*}
\begin{equation*}
=P\begin{mymatrix}{ccc}
e^{\lambda _{1}} &  & 0 \\ 
& \ddots &  \\ 
0 &  & e^{\lambda _{n}}
\end{mymatrix} P^{-1}
\end{equation*}

This justifies the following theorem. 

\begin{theorem}{The matrix exponential}{matrix-exponential}
Let $A$ be a diagonalizable matrix, with eigenvalues $\lambda_1, ..., \lambda_n$and corresponding matrix of eigenvectors $P$. Then the matrix exponential, $e^{A}$, is given by
\begin{equation*}
e^{A} = 
P\begin{mymatrix}{ccc}
e^{\lambda _{1}} &  & 0 \\ 
& \ddots &  \\ 
0 &  & e^{\lambda _{n}}
\end{mymatrix} P^{-1}
\end{equation*}
\end{theorem}

\begin{example}{Compute $e^A$ for a matrix $A$}{}
Let
\begin{equation*}
A=\begin{mymatrix}{rrr}
2 & -1 & -1 \\
1 & 2 & 1 \\
-1 & 1 & 2
\end{mymatrix}
\end{equation*}
Find $e^{A}$.
\end{example}

\begin{solution}
The eigenvalues work out to be $1,2,3$ and eigenvectors associated with these
eigenvalues are 
\begin{equation*}
\begin{mymatrix}{r}
0 \\ 
-1 \\ 
1
\end{mymatrix} \leftrightarrow 1,
\begin{mymatrix}{r}
-1 \\ 
-1 \\ 
1
\end{mymatrix} \leftrightarrow 2,\begin{mymatrix}{r}
-1 \\ 
0 \\ 
1
\end{mymatrix} \leftrightarrow 3
\end{equation*}
Then let 
\begin{equation*}
D=\begin{mymatrix}{rrr}
1 & 0 & 0 \\ 
0 & 2 & 0 \\ 
0 & 0 & 3
\end{mymatrix}, P=\begin{mymatrix}{rrr}
0 & -1 & -1 \\ 
-1 & -1 & 0 \\ 
1 & 1 & 1
\end{mymatrix}
\end{equation*}
and so 
\begin{equation*}
P^{-1}=\begin{mymatrix}{rrr}
1 & 0 & 1 \\ 
-1 & -1 & -1 \\ 
0 & 1 & 1
\end{mymatrix}
\end{equation*}

Then the matrix exponential is 
\begin{equation*}
e^{At} = \begin{mymatrix}{rrr}
0 & -1 & -1 \\ 
-1 & -1 & 0 \\ 
1 & 1 & 1
\end{mymatrix} \begin{mymatrix}{ccc}
e^{1} & 0 & 0 \\ 
0 & e^{2} & 0 \\ 
0 & 0 & e^{3}
\end{mymatrix} \begin{mymatrix}{rrr}
1 & 0 & 1 \\ 
-1 & -1 & -1 \\ 
0 & 1 & 1
\end{mymatrix}
\end{equation*}
\begin{equation*}
\begin{mymatrix}{ccc}
e^{2} & e^{2}-e^{3} & e^{2}-e^{3} \\ 
e^{2}-e & e^{2} & e^{2}-e \\ 
-e^{2}+e & -e^{2}+e^{3} & -e^{2}+e+e^{3}
\end{mymatrix} 
\end{equation*}
\end{solution}

The matrix exponential is a useful tool to solve autonomous
systems of first order linear differential equations. These are equations
which are of the form 
\begin{equation*}
X^{\prime }=AX, X(0) = C
\end{equation*}
where $A $ is a diagonalizable $n\times n$-matrix and $C$ is a constant vector. $X$ is a vector of functions in one variable, $t$:
\begin{equation*}
X = X(t) = \begin{mymatrix}{c}
x_1(t) \\
x_2(t) \\
\vdots \\
x_n(t) 
\end{mymatrix}
\end{equation*}
Then $X^{\prime }$ refers to the first derivative of $X$ and is given by 
\begin{equation*}
X^{\prime} = X^{\prime}(t) = \begin{mymatrix}{c}
x_1^{\prime}(t) \\
x_2^{\prime}(t) \\
\vdots \\
x_n^{\prime}(t) 
\end{mymatrix}, \; x_i^{\prime}(t) = \text{the derivative of}\; x_i(t)
\end{equation*}

Then it turns out that the solution to the
above system of equations is $X\tup{t} =e^{At}C$. To see this, suppose $A$ is
diagonalizable so that 
\begin{equation*}
A=P\begin{mymatrix}{ccc}
\lambda _{1} &  &  \\ 
& \ddots &  \\ 
&  & \lambda _{n}
\end{mymatrix} P^{-1}
\end{equation*}
Then 
\begin{equation*}
e^{At}=P\begin{mymatrix}{ccc}
e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & e^{\lambda _{n}t}
\end{mymatrix} P^{-1}
\end{equation*} 
\begin{equation*}
e^{At}C=P\begin{mymatrix}{ccc}
e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & e^{\lambda _{n}t}
\end{mymatrix} P^{-1}C
\end{equation*}

Differentiating $e^{At}C$ yields
\begin{equation*}
X^{\prime} = \tup{e^{At}C} ^{\prime }=P\begin{mymatrix}{ccc}
\lambda _{1}e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & \lambda _{n}e^{\lambda _{n}t}
\end{mymatrix} P^{-1}C
\end{equation*}
\begin{equation*}
=P\begin{mymatrix}{ccc}
\lambda _{1} &  &  \\ 
& \ddots &  \\ 
&  & \lambda _{n}
\end{mymatrix} \begin{mymatrix}{ccc}
e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & e^{\lambda _{n}t}
\end{mymatrix} P^{-1}C
\end{equation*}
\begin{eqnarray*}
&=&P\begin{mymatrix}{ccc}
\lambda _{1} &  &  \\ 
& \ddots &  \\ 
&  & \lambda _{n}
\end{mymatrix} P^{-1}P\begin{mymatrix}{ccc}
e^{\lambda _{1}t} &  &  \\ 
& \ddots &  \\ 
&  & e^{\lambda _{n}t}
\end{mymatrix} P^{-1}C \\
&=&A\tup{e^{At}C} = AX
\end{eqnarray*}
Therefore $X = X(t) = e^{At}C$ is a solution to $X^{\prime }=AX$. 

To prove that $X(0) =  C$ if $X(t) = e^{At}C$:
\begin{equation*}
X(0) = e^{A0}C=P\begin{mymatrix}{ccc}
1 &  &  \\ 
& \ddots &  \\ 
&  & 1
\end{mymatrix} P^{-1}C=C
\end{equation*}

\begin{example}{Solving an initial value problem}{}
Solve the initial value problem
\begin{equation*}
\begin{mymatrix}{c}
x \\
y
\end{mymatrix} ^{\prime }=\begin{mymatrix}{rr}
0 & -2 \\
1 & 3
\end{mymatrix} \begin{mymatrix}{c}
x \\
y
\end{mymatrix} ,\ \begin{mymatrix}{c}
x(0)\\
y(0)
\end{mymatrix}  =\begin{mymatrix}{c}
1 \\
1
\end{mymatrix}
\end{equation*}
\end{example}

\begin{solution}
The matrix is diagonalizable and can be written as  
\begin{eqnarray*}
A &=& PDP^{-1} \\
\begin{mymatrix}{rr}
0 & -2 \\ 
1 & 3
\end{mymatrix} &=&\begin{mymatrix}{rr}
1 & 1 \\ 
-\frac{1}{2} & -1
\end{mymatrix} \begin{mymatrix}{rr}
1 & 0 \\ 
0 & 2
\end{mymatrix} \begin{mymatrix}{rr}
2 & 2 \\ 
-1 & -2
\end{mymatrix}
\end{eqnarray*}
Therefore, the matrix exponential is of the form 
\begin{equation*}
e^{At} = \begin{mymatrix}{rr}
1 & 1 \\ 
-\frac{1}{2} & -1
\end{mymatrix} \begin{mymatrix}{cc}
e^{t} & 0 \\ 
0 & e^{2t}
\end{mymatrix} \begin{mymatrix}{rr}
2 & 2 \\ 
-1 & -2
\end{mymatrix}
\end{equation*}
The solution to the initial value problem is
\begin{eqnarray*}
X(t) &=& e^{At}C \\
\begin{mymatrix}{c}
x\tup{t} \\ 
y\tup{t}
\end{mymatrix} &=& \begin{mymatrix}{rr}
1 & 1 \\ 
-\frac{1}{2} & -1
\end{mymatrix} \begin{mymatrix}{cc}
e^{t} & 0 \\ 
0 & e^{2t}
\end{mymatrix} \begin{mymatrix}{rr}
2 & 2 \\ 
-1 & -2
\end{mymatrix} \begin{mymatrix}{c}
1 \\ 
1
\end{mymatrix} \\
&=&\begin{mymatrix}{c}
4e^{t}-3e^{2t} \\ 
3e^{2t}-2e^{t}
\end{mymatrix}
\end{eqnarray*}
We can check that this works: 
\begin{eqnarray*}
\begin{mymatrix}{c}
x\tup{0} \\ 
y\tup{0}
\end{mymatrix} &=&
\begin{mymatrix}{c}
4e^{0}-3e^{2(0)} \\ 
3e^{2(0)}-2e^{0}
\end{mymatrix} \\
&=&
\begin{mymatrix}{c}
1 \\ 
1
\end{mymatrix}
\end{eqnarray*}

Lastly, 
\begin{equation*}
X^{\prime} = 
\begin{mymatrix}{c}
4e^{t}-3e^{2t} \\ 
3e^{2t}-2e^{t}
\end{mymatrix} ^{\prime }=\begin{mymatrix}{c}
4e^{t}-6e^{2t} \\ 
6e^{2t}-2e^{t}
\end{mymatrix}
\end{equation*}
and 
\begin{equation*}
AX = \begin{mymatrix}{rr}
0 & -2 \\ 
1 & 3
\end{mymatrix} \begin{mymatrix}{c}
4e^{t}-3e^{2t} \\ 
3e^{2t}-2e^{t}
\end{mymatrix} =\begin{mymatrix}{c}
4e^{t}-6e^{2t} \\ 
6e^{2t}-2e^{t}
\end{mymatrix}
\end{equation*}
which is the same thing. Thus this is the solution to the initial value
problem.
\end{solution}


