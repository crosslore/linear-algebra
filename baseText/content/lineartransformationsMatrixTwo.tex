\section{The matrix of a linear transformation II}

%Requires Linear Transformations. 

\begin{outcome}
  \begin{enumerate}
  \item Find the matrix of a linear transformation with respect to
    general bases.
  \end{enumerate}
\end{outcome}

We begin this section with an important lemma. 

\begin{lemma}{Mapping of a basis}{mapping-basis}
Let $T: \R^n \mapsto \R^n$ be an isomorphism.  Then $T$ maps any basis of
$\R^n$ to another basis for $\R^n$. 

Conversely, if $T:
\R^n \mapsto \R^n$ is a linear transformation which
maps a basis of $\R^n$ to another basis of $\R^n$,
then it is an isomorphism.
\end{lemma}

\begin{proof}
First, suppose $T:\R^n \mapsto \R^n$ is a linear
transformation which is one to one and onto. Let $\set{
\vect{v}_{1},\cdots ,\vect{v}_{n}} $ be a basis for
$\R^n$. We wish to show that $\set{T(\vect{v}_{1}),\cdots ,
T(\vect{v}_{n})} $ is also a basis for $\R^n$. 

First consider why it is linearly independent. Suppose
$\sum_{k=1}^{n}a_{k}T(\vect{v}_{k})=\vect{0}$. Then by linearity we have $T\tup{
\sum_{k=1}^{n}a_{k}\vect{v}_{k}} =\vect{0}$ and since $T$ is one
to one, it follows that $\sum_{k=1}^{n}a_{k}\vect{v}_{k}=\vect{0}$.
This requires that  each $a_{k}=0$ because $\set{\vect{v}_{1},\cdots,
\vect{v}_{n}} $ is independent, and it follows that $\set{
T(\vect{v}_{1}),\cdots , T(\vect{v}_{n})} $ is linearly
independent. 


Next take $\vect{w}\in \R^n$. Since $T$ is onto,
there exists $\vect{v}\in \R^n$ such that
$T(\vect{v})=\vect{w}$. Since $ \set{\vect{v}_{1},\cdots
,\vect{v}_{n}} $ is a basis, in particular it is a spanning set
and there are scalars $b_{k}$ such that $T\tup{
\sum_{k=1}^{n}b_{k}\vect{v} _{k}} =T\tup{\vect{v}}
=\vect{w}$. Therefore $\vect{w} =\sum_{k=1}^{n}b_{k}T(\vect{v}_{k})$
which is in the $\sspan\set{T(\vect{v}_{1}),\cdots ,
T(\vect{v}_{n})}$. Therefore, $\set{T(\vect{v}_{1}),\cdots
,T(\vect{v}_{n}) } $ is a basis as claimed.

Suppose now that $T: \R^n \mapsto \R^n$ is a linear
transformation such that $T(\vect{v}_{i})=\vect{w}_{i}$ where
$\set{\vect{v} _{1},\cdots ,\vect{v}_{n}} $ and $\set{
\vect{w}_{1},\cdots , \vect{w}_{n}} $ are two bases for
$\R^n$. 

To show that $T$ is one to one, let $T\tup{
\sum_{k=1}^{n}c_{k}\vect{v}_{k}} =\vect{0}$. Then
$\sum_{k=1}^{n}c_{k}T(\vect{v}_{k})=\sum_{k=1}^{n}c_{k}\vect{w}_{k}=\vect{
0}$. It follows that each $c_{k} = 0$ because it is given that
$\set{\vect{w} _{1},\cdots ,\vect{w}_{n}} $ is linearly
independent. Hence $T\tup{\sum_{k=1}^{n}c_{k}\vect{v}_{k}}
=\vect{0}$ implies that $\sum_{k=1}^{n}c_{k}\vect{v}_{k}=\vect{0}$ and
so $T$ is one to one.  

To show that $T$ is onto, let $\vect{w}$ be an arbitrary vector in
$\R^n$. This vector can be written as $\vect{w} =
\sum_{k=1}^{n}d_k\vect{w}_k =
\sum_{k=1}^{n}d_{k}T(\vect{v}_{k})=T\tup{\sum_{k=1}^{n}d_{k}
\vect{v}_{k}}$.  Therefore, $T$ is also onto. 
\end{proof}

Consider now an important definition.

\begin{definition}{Coordinate vector}{coordinate-vector}
Let $B = \set{\vect{v}_1, \vect{v}_2, \cdots, \vect{v}_n }$
be a basis for $\R^n$ and let $\vect{x}$ be an arbitrary
vector in $\R^n$. Then $\vect{x}$ is uniquely represented as
$\vect{x} = a_1\vect{v}_1 +
a_2\vect{v}_2 + \cdots + a_n\vect{v}_n$ for scalars $a_1, \cdots,
a_n$. 

The  \textbf{coordinate vector}\index{vector!coordinate vector}\index{coordinate vector} of $\vect{x}$ with respect to the
basis $B$, written $C_B(\vect{x})$ or  $[\vect{x}]_B$,  is given by
\[
C_B(\vect{x}) =  C_B \tup{a_1\vect{v}_1 + a_2\vect{v}_2 + \cdots + a_n\vect{v}_n } = \begin{mymatrix}{c}
a_1 \\
a_2 \\
\vdots \\
a_n
\end{mymatrix}
\] 
\end{definition}

Consider the following example.

\begin{example}{Coordinate vector}{coordinate-vector}
Let $B = \set{\begin{mymatrix}{r}
1 \\
0 
\end{mymatrix}, \begin{mymatrix}{r}
-1 \\
1
\end{mymatrix} }$ be a basis of $\R^2$ and let $\vect{x} = \begin{mymatrix}{r}
3 \\
-1
\end{mymatrix}$ be a vector in $\R^2$. Find $C_B(\vect{x})$. 
\end{example}

\begin{solution}
First, note the order of the basis is important so label the vectors in the basis $B$ as 
\[
B = \set{\begin{mymatrix}{r}
1 \\
0 
\end{mymatrix}, \begin{mymatrix}{r}
-1 \\
1
\end{mymatrix} } = \set{\vect{v}_1, \vect{v}_2 } \]
Now we need to find $a_1, a_2$ such that $\vect{x} = a_1 \vect{v}_1 + a_2 \vect{v}_2$, that is:
\[
\begin{mymatrix}{r}
3 \\
-1
\end{mymatrix}
=
a_1 
\begin{mymatrix}{r}
1 \\
0 
\end{mymatrix}
+ a_2
\begin{mymatrix}{r}
-1 \\
1 
\end{mymatrix}\]
Solving this system gives $a_1 = 2, a_2 = -1$. Therefore the coordinate vector of $\vect{x}$ with respect to the basis $B$ is 
\[
C_B(\vect{x})
=
\begin{mymatrix}{r}
a_1 \\
a_2 
\end{mymatrix}
= \begin{mymatrix}{r}
2 \\
-1 
\end{mymatrix}
\]
\end{solution}

Given any basis $B$, one can easily verify that the coordinate function is actually an isomorphism. 

\begin{theorem}{$C_B$ is a linear transformation}{coord-lin-transf}
For any basis $B$ of $\R^n$, the coordinate function
\[ C_B: \R^n  \rightarrow \R^n  \]
is a linear transformation, and moreover an isomorphism. 
\end{theorem}

We now discuss the main  result  of this section, that is how
to represent a linear transformation with respect to different
bases.

\begin{theorem}{The matrix of a linear transformation}{matrix-lin-transf-bases}
Let $T: \R^n \mapsto \R^m$ be a linear transformation,
and let $B_1$ and $B_2$ be bases of $\R^{n}$ and
$\R^{m}$ respectively.

Then the following holds
\begin{equation}
C_{B_2} T = M_{B_{2} B_{1}} C_{B_1}   \label{matrix-equation}
\end{equation}
where $M_{B_{2} B_{1}}$  is a unique $m \times n$-matrix.

If the basis $B_1$ is given by $B_1=\{\vect{v}_1, \cdots, \vec{v}_n\}$ in this order, then 

\[  M_{B_{2} B_{1}} = \mat{C_{B_2}(T(\vec{v}_1)) \; C_{B_2}(T(\vec{v}_2)) \; \cdots C_{B_2}(T(\vec{v}_n)) } \]
\end{theorem}

\begin{proof}
The above equation {\eqref{matrix-equation}} can be represented by the following diagram.
\begin{equation*}
\begin{array}{rrcll}
&  & T &  &  \\
& \R^n & \rightarrow  & \R^m & \\
& C_{B_{1} }\downarrow  & \circ  & \downarrow C_{B_{2} } &  \\
& \R^{n} & \rightarrow  & \R^{m} &  \\
&  & M_{B_{2} B_{1} } &  &
\end{array}
\end{equation*}

Since $C_{B_1}$ is an isomorphism, then the matrix we are looking for is the matrix of the linear transformation 
\[   C_{B_2} T C^{-1}_{B_1} : \R^n \mapsto \R^m. \]
By Theorem~\ref{thm:matrix-of-linear-transformation}, the columns are
given by the image of the standard basis $\set{\vect{e}_1,
\vect{e}_2, \cdots, \vect{e}_n }$. But since $C^{-1}_{B_1}( \vec{e}_i) = \vec{v}_i$, we readily obtain that 

\[ \begin{array}{ll} 
M_{B_{2} B_{1}} 
& = \mat{C_{B_2}T C^{-1}_{B_1} (\vec{e}_1) \;\; C_{B_2}T C^{-1}_{B_1} (\vec{2}_2) \;\; \cdots \;\; C_{B_2}T C^{-1}_{B_1} (\vec{e}_n) } \\
& = \mat{C_{B_2}(T(\vec{v}_1)) \;\; C_{B_2}(T(\vec{v}_2)) \;\; \cdots \;\; C_{B_2}(T(\vec{v}_n)) } 
\end{array}\]
and this completes the proof. 
\end{proof}

Consider the following example.

\begin{example}{Matrix of a linear transformation}{matrix-lin-transf}
Let $T: \R^2 \mapsto \R^2$ be a linear transformation defined by $T \tup{\begin{mymatrix}{r}
a \\
b
\end{mymatrix} } = \begin{mymatrix}{r}
b \\
a 
\end{mymatrix}$. 

Consider the two bases
\[
B_1 = \set{\vect{v}_{1}, \vect{v}_{2} } = \set{\begin{mymatrix}{r}
1 \\
0
\end{mymatrix}, \begin{mymatrix}{r}
-1 \\
1
\end{mymatrix}
}
\]
 and 
\[
B_2 = \set{\begin{mymatrix}{r}
1 \\
1
\end{mymatrix}, \begin{mymatrix}{r}
1 \\
-1
\end{mymatrix}
}
\]

Find the matrix $M_{B_2,B_1}$ of $T$ with respect to the bases $B_1$ and $B_2$. 
\end{example}

\begin{solution}
By Theorem~\ref{thm:matrix-lin-transf-bases}, the columns of $M_{B_{2} B_{1}}$ are the
coordinate vectors of $T(\vect{v}_{1}), T(\vect{v}_{2})$ with respect
to $B_2$.

Since \[
T \tup{
\begin{mymatrix}{r}
1 \\
0
\end{mymatrix} }
= \begin{mymatrix}{r}
0 \\
1
\end{mymatrix} ,\]
a standard calculation yields 
\[
 \begin{mymatrix}{r}
0 \\
1
\end{mymatrix} 
 =  
\tup{\frac{1}{2} }\begin{mymatrix}{r}
1 \\
1
\end{mymatrix}
+
\tup{-\frac{1}{2} }
\begin{mymatrix}{r}
1 \\
-1
\end{mymatrix},
\]
the first column of $M_{B_{2} B_{1}}$ is $\begin{mymatrix}{r}
\vspace{0.05in}\frac{1}{2}\\
\vspace{0.05in}-\frac{1}{2}
\end{mymatrix}$. 

The second column is found in a similar way. We have 
\[
T \tup{
\begin{mymatrix}{r}
-1 \\
1
\end{mymatrix} }
= \begin{mymatrix}{r}
1 \\
-1
\end{mymatrix} , \]
and with respect to $B_2$ calculate:
\[ 
\begin{mymatrix}{r}
1 \\
-1
\end{mymatrix}
=
0 \begin{mymatrix}{r}
1 \\
1
\end{mymatrix}
+
1
\begin{mymatrix}{r}
1 \\
-1
\end{mymatrix}
\]
Hence the second column of $M_{B_{2} B_{1}}$ is given by $\begin{mymatrix}{r}
0 \\
1
\end{mymatrix}$. We thus obtain 
\[
M_{B_{2} B_{1}} = \begin{mymatrix}{rr}
\vspace{0.05in}\frac{1}{2} & 0 \\
\vspace{0.05in}-\frac{1}{2} & 1 
\end{mymatrix} \]

We can verify that this is the correct matrix $M_{B_{2} B_{1}}$ on the specific example
\[
\vect{v} = \begin{mymatrix}{r}
3 \\
-1 
\end{mymatrix} \]
First applying $T$ gives
\[
T( \vect{v} ) =
T \tup{
\begin{mymatrix}{r}
3 \\
-1 
\end{mymatrix} } = \begin{mymatrix}{r}
-1\\
3
\end{mymatrix}
\]
and one can compute that  
\[ C_{B_2} 
 \tup{
\begin{mymatrix}{r}
-1 \\
3 
\end{mymatrix} } = \begin{mymatrix}{r}
1\\
-2
\end{mymatrix} .\]

On the other hand, one compute $C_{B_1}( \vect{v})$ as 
\[ C_{B_1} 
 \tup{
\begin{mymatrix}{r}
3 \\
-1 
\end{mymatrix} } = \begin{mymatrix}{r}
2\\
-1
\end{mymatrix} ,\]
and finally applying $M_{B_1 B_2}$ gives

\[\begin{mymatrix}{rr}
\vspace{0.05in}\frac{1}{2} & 0 \\
\vspace{0.05in}-\frac{1}{2} & 1 
\end{mymatrix} 
\begin{mymatrix}{r}
2 \\
-1
\end{mymatrix} 
= \begin{mymatrix}{r}
1 \\
-2
\end{mymatrix} \]
as above. 

We see that the same vector results from either method, as suggested by Theorem~\ref{thm:matrix-lin-transf-bases}.
\end{solution}

If the bases $B_1$ and $B_2$ are equal, say $B$, then we write $M_{B}$ instead of  $M_{B B}$. 
The following example illustrates how to compute  such a matrix. Note that this is what we did earlier when we considered only
$B_1=B_2$ to be the standard basis. 

\begin{example}{Matrix of a linear transformation with respect to an arbitrary   basis}{arbitrary-bases}

Consider the basis $B$ of $\R^3$ given by 
\begin{equation*}
B = \{\vect{v}_1 , \vect{v}_2,  \vect{v}_3\} =
\set{
\begin{mymatrix}{r}
1 \\
0 \\
1
\end{mymatrix} ,\begin{mymatrix}{r}
1 \\
1 \\
1
\end{mymatrix} ,\begin{mymatrix}{r}
-1 \\
1 \\
0
\end{mymatrix} }
\]

And let $T :\R^{3}\mapsto \R^{3}$ be the linear transformation 
defined on $B$ as:
\begin{equation*}
T\begin{mymatrix}{r}
1 \\
0 \\
1
\end{mymatrix} =\begin{mymatrix}{r}
1 \\
-1 \\
1
\end{mymatrix} ,T \begin{mymatrix}{c}
1 \\
1 \\
1
\end{mymatrix} =\begin{mymatrix}{r}
1 \\
2 \\
-1
\end{mymatrix} ,T\begin{mymatrix}{r}
-1 \\
1 \\
0
\end{mymatrix} =\begin{mymatrix}{r}
0 \\
1 \\
1
\end{mymatrix}
\end{equation*}

\begin{enumerate}
\item Find the matrix  $M_{B}$ of $T$ relative to the basis $B$.
\item Then find the usual matrix of $T$ with respect to the standard basis of $\R^{3}$.
\end{enumerate}

\end{example}

\begin{solution}

Equation  {\eqref{matrix-equation}}  gives $ C_BT=M_{B}C_B$, and thus 
$M_{B} = C_BTC^{-1}_B$. 

Now $C_B(\vec{v}_i) = \vec{e}_i$, so the matrix of $C_B^{-1}$ (with respect to the standard basis) is given by
\[ \mat{C_B^{-1}(\vec{e}_1) \;\; C_B^{-1}(\vec{e}_2) \;\; C_B^{-1}(\vec{e}_2) } =  
\begin{mymatrix}{rrr}
1 & 1 & -1 \\ 
0 & 1 & 1 \\ 
1 & 1 & 0
\end{mymatrix}
\]
Moreover the matrix of  $T C_B^{-1}$ is given by 
\[ \mat{TC_B^{-1}(\vec{e}_1) \;\; TC_B^{-1}(\vec{e}_2) \;\; TC_B^{-1}(\vec{e}_2) } =  
\begin{mymatrix}{rrr}
1 & 1 & 0 \\ 
-1 & 2 & 1 \\ 
1 & -1 & 1
\end{mymatrix}
\]
Thus 
\[ \begin{array}{ll}
M_{B} & =  C_BTC^{-1}_B =  [C^{-1}_B]^{-1} [TC^{-1}_B] \\
	& = 
\begin{mymatrix}{rrr}
1 & 1 & -1 \\ 
0 & 1 & 1 \\ 
1 & 1 & 0
\end{mymatrix} ^{-1}\begin{mymatrix}{rrr}
1 & 1 & 0 \\ 
-1 & 2 & 1 \\ 
1 & -1 & 1
\end{mymatrix} \\
&=\begin{mymatrix}{rrr}
2 & -5 & 1 \\ 
-1 & 4 & 0 \\ 
0 & -2 & 1
\end{mymatrix}
\end{array}
\]


Consider how this works. Let $\vect{b} = \begin{mymatrix}{r}
b_1 \\
b_2 \\
b_3
\end{mymatrix}$ be an arbitrary vector in $\R^3$. 

Apply $C^{-1}_{B}$ to $\vect{b}$ to get 
\begin{equation*}
b_1\begin{mymatrix}{r}
1 \\
0 \\
1
\end{mymatrix} + b_2\begin{mymatrix}{r}
1 \\
1 \\
1
\end{mymatrix} + b_3\begin{mymatrix}{r}
-1 \\
1 \\
0
\end{mymatrix} 
\end{equation*}
Apply $T$ to this linear combination to obtain 
\begin{equation*}
b_1\begin{mymatrix}{r}
1 \\ 
-1 \\ 
1
\end{mymatrix} + b_2\begin{mymatrix}{r}
1 \\ 
2 \\ 
-1
\end{mymatrix} + b_3\begin{mymatrix}{r}
0 \\ 
1 \\ 
1
\end{mymatrix} =\begin{mymatrix}{c}
b_1+b_2 \\ 
-b_1 + 2b_2+ b_3 \\ 
b_1-b_2+b_3
\end{mymatrix}
\end{equation*}
Now take the matrix $M_{B}$ of the transformation (as found above) and multiply it by $\vect{b}$. 
\begin{equation*}
\begin{mymatrix}{rrr}
2 & -5 & 1 \\ 
-1 & 4 & 0 \\ 
0 & -2 & 1
\end{mymatrix} \begin{mymatrix}{c}
b_1 \\ 
b_2 \\ 
b_3
\end{mymatrix} =\begin{mymatrix}{c}
2b_1-5b_2+b_3 \\ 
-b_1 + 4b_2 \\ 
-2b_2 + b_3
\end{mymatrix}
\end{equation*}
Is this the coordinate vector of the above relative to the given basis? We check as follows. 
\begin{equation*}
\tup{2b_1-5b_2+b_3} \begin{mymatrix}{c}
1 \\ 
0 \\ 
1
\end{mymatrix} +\tup{-b_1 + 4b_2} \begin{mymatrix}{c}
1 \\ 
1 \\ 
1
\end{mymatrix} +\tup{-2b_2+b_3} \begin{mymatrix}{c}
-1 \\ 
1 \\ 
0
\end{mymatrix}
\end{equation*}
\begin{equation*}
= \begin{mymatrix}{c}
b_1+b_2 \\ 
-b_1 + 2b_2+b_3 \\ 
b_1-b_2+b_3
\end{mymatrix}
\end{equation*}
You see it is the same thing.

Now lets find the matrix of $T$ with respect to the standard basis. Let $A$ be
this matrix. That is, multiplication by $A$ is the same as doing $T$. Thus 
\begin{equation*}
A\begin{mymatrix}{rrr}
1 & 1 & -1 \\ 
0 & 1 & 1 \\ 
1 & 1 & 0
\end{mymatrix} =\begin{mymatrix}{rrr}
1 & 1 & 0 \\ 
-1 & 2 & 1 \\ 
1 & -1 & 1
\end{mymatrix}
\end{equation*}
Hence 
\begin{equation*}
A=\begin{mymatrix}{rrr}
1 & 1 & 0 \\ 
-1 & 2 & 1 \\ 
1 & -1 & 1
\end{mymatrix} \begin{mymatrix}{rrr}
1 & 1 & -1 \\ 
0 & 1 & 1 \\ 
1 & 1 & 0
\end{mymatrix} ^{-1}=\begin{mymatrix}{rrr}
0 & 0 & 1 \\ 
2 & 3 & -3 \\ 
-3 & -2 & 4
\end{mymatrix}
\end{equation*}
Of course this is a very different matrix than the matrix of the linear
transformation with respect to the non standard basis.
\end{solution}
