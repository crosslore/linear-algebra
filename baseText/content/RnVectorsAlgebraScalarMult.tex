\subsection{Scalar multiplication of vectors in \texorpdfstring{$\R^n$}{Rn}}

Scalar multiplication of vectors in $\R^n$ is defined as 
follows.

\begin{definition}{Scalar multiplication of vectors in $\R^n$}{vectorscalarmultiplication}
If $\vect{u}\in \R^{n}$ and $k\in \R$ is a
scalar\index{scalars}, then $k\vect{u}\in \R^{n}$\index{vector!scalar multiplication} is defined by
\begin{equation*}
k\vect{u}=k\begin{mymatrix}{c}
u_{1} \\
\vdots \\
u_{n}
\end{mymatrix} = \begin{mymatrix}{c}
ku_{1} \\
\vdots \\
ku_{n}
\end{mymatrix}
\end{equation*}
\end{definition}

For example 
$3 \begin{mymatrix}{rrr}
1 & 2 & 3
\end{mymatrix}^T =
\begin{mymatrix}{rrr}
3 & 6 & 9
\end{mymatrix}^T$
 and 
$-2\begin{mymatrix}{rrr}
1 & 2 & 3
\end{mymatrix}^T
=
\begin{mymatrix}{rrr}
-2 & -4 & -6
\end{mymatrix}^T$.

Just as with addition, scalar multiplication of vectors satisfies several important properties. These are 
outlined in the following theorem. 

\begin{theorem}{Properties of scalar multiplication}{vectorscalarmult}
The following properties hold for vectors $\vect{u},\vect{v}\in \R^{n}$ and $k,p $
scalars.
\begin{itemize}
\item The Distributive Law over Vector Addition
\begin{equation*}
k \tup{\vect{u}+\vect{v}} = k\vect{u}+ k\vect{v}
\end{equation*}
\item The Distributive Law over Scalar Addition
\begin{equation*}
\tup{k + p  }\vect{u} = k \vect{u}+p \vect{u}
\end{equation*}
\item The Associative Law for Scalar Multiplication
\begin{equation*}
k \tup{p \vect{u}} = \tup{k p }\vect{u}
\end{equation*}
\item Rule for Multiplication by $1$
\begin{equation*}
1\vect{u}=\vect{u}  
\end{equation*}
\end{itemize}
\end{theorem}

\begin{proof}
We will show the proof of: 
\begin{equation*}
k \tup{\vect{u}+\vect{v}} = k \vect{u}+ k \vect{v}
\end{equation*}
Note that:
\begin{equation*}
\begin{array}{ll}
k \tup{\vect{u}+\vect{v}} & =k \mat{u_{1}+v_{1} \cdots u_{n}+v_{n}}^T \\
& = \mat{k \tup{u_{1}+v_{1}} \cdots k \tup{u_{n}+v_{n}} }^T \\
& = \mat{k u_{1}+ k  v_{1} \cdots k u_{n}+ k v_{n}}^T \\
& = \mat{k u_{1} \cdots k u_{n} }^T + \mat{k v_{1} \cdots k v_{n} }^T \\
& = k \vect{u}+k \vect{v} \\
\end{array}
\end{equation*}
\end{proof}

We now present a useful notion you may have seen earlier combining vector addition and scalar multiplication

\begin{definition}{Linear combination}{linearcombination}
A vector $\vect{v}$ is said to be a \textbf{linear combination}\index{linear combination} of the vectors $\vect{u}_1,\cdots , \vect{u}_n $ 
if there exist scalars, $a_{1},\cdots ,a_{n}$ such
that
\begin{equation*}
\vect{v} = a_1 \vect{u}_1 + \cdots + a_n \vect{u}_n
\end{equation*}
\end{definition}

For example, 
\begin{equation*}
3
\begin{mymatrix}{r}
-4 \\
1 \\
0
\end{mymatrix}
+
2
\begin{mymatrix}{r}
-3 \\
0\\
1
\end{mymatrix}
 =
\begin{mymatrix}{r}
-18 \\
3 \\
2
\end{mymatrix}. 
\end{equation*}
Thus we can say that
\begin{equation*}
\vect{v}= \begin{mymatrix}{r}
-18 \\
3 \\
2
\end{mymatrix}
\end{equation*}
is a linear combination of the vectors 
\begin{equation*}
\vect{u}_1 = \begin{mymatrix}{r}
-4 \\
1 \\
0
\end{mymatrix}
\mbox{ and } 
\vect{u}_2 = 
\begin{mymatrix}{r}
-3 \\
0\\
1
\end{mymatrix}
\end{equation*}

For the specific case of $\R^3$, there are three special vectors which we often use. 
They are given by 
\begin{equation*}
\vect{i} = 
\begin{mymatrix}{rrr}
1 & 0 & 0
\end{mymatrix}^T
\end{equation*}
\begin{equation*}
\vect{j} = 
\begin{mymatrix}{rrr}
0 & 1 & 0
\end{mymatrix}^T
\end{equation*}
\begin{equation*}
\vect{k} = 
\begin{mymatrix}{rrr}
0 & 0 & 1
\end{mymatrix}^T
\end{equation*}
We can write any vector $\vect{u} = 
\begin{mymatrix}{rrr}
a_1 & a_2 & a_3
\end{mymatrix}^T$
as a linear combination of these vectors, written as $\vect{u} = a_1 \vect{i} + a_2 \vect{j} + a_3 \vect{k}$. This notation will be used throughout 
this chapter.

\begin{example}{Determining if linear combination}{determinelincomb}
Can $\vect{v}=\begin{mymatrix}{rrr}1 & 3 & 5 \end{mymatrix}^T$ be written as a linear combination of $\vect{u}_1=\begin{mymatrix}{rrr}2 & 2 & 6 \end{mymatrix}^T$, $\vect{u}_2=\begin{mymatrix}{rrr}1 & 6 & 8 \end{mymatrix}^T$ and $\vect{u}_3=\begin{mymatrix}{rrr}3 & 8 & 18 \end{mymatrix}^T$?
\end{example}

\begin{solution}
This question can be rephrased as: can we find $x,y,z$ such that
$$x\vect{u}_1+y\vect{u}_2+z\vect{u}_3=\vect{v}$$
where $x,y,z$ are scalars? Multiplying out produces the system of linear equations
\begin{align*}
2x+y+3z&=1\\
2x+6y+8z&=3\\
6x+8y+18z&=5
\end{align*}
now we row reduce the corresponding augmented matrix to solve
\begin{align*}
&\begin{mymatrix}{rrr|r} 2 & 1 & 3 & 1 \\ 2 & 6 & 8 & 3\\ 6 & 8 & 18 & 5 \end{mymatrix}  \stackrel{R_1\leftarrow R_1-R_2}{\stackrel{R_3\leftarrow R_3-3R_1}{\sim}}
\begin{mymatrix}{rrr|r} 0 & -5 & -5 & -2 \\ 2 & 6 & 8 & 3 \\ 0 & 5 & 9 & 2 \end{mymatrix} \stackrel{R_1\leftarrow R_1+R_3}{\sim}
\begin{mymatrix}{rrr|r} 0 & 0 & 4 & 0 \\ 2 & 6 & 8 & 3 \\ 0 & 5 & 9 & 2 \end{mymatrix} \stackrel{R_2\leftrightarrow R_1}{\sim} \\
&\begin{mymatrix}{rrr|r} 2 & 6 & 8 & 3 \\ 0 & 0 & 4 & 0 \\ 0 & 5 & 9 & 2 \end{mymatrix} \stackrel{\frac{1}{2}R_1}{\stackrel{R_2\leftrightarrow R_3}{\sim}}
\begin{mymatrix}{rrr|r} 1 & 3 & 4 & \frac{3}{2} \\ 0 & 5 & 9 & 2\\  0 & 0 & 4 & 0\end{mymatrix} \stackrel{\frac{1}{4}R_3}{\sim}
\begin{mymatrix}{rrr|r} 1 & 3 & 4 & \frac{3}{2} \\ 0 & 5 & 9 & 2\\  0 & 0 & 1 & 0 \end{mymatrix} \stackrel{R_1\leftarrow R_1-4R_3}{\stackrel{R_2\leftarrow R_2-9R_3}{\sim}} \\
& \begin{mymatrix}{rrr|r} 1 & 3 & 0 & \frac{3}{2} \\ 0 & 5 & 0 & 2\\  0 & 0 & 1 & 0 \end{mymatrix}  \stackrel{\frac{1}{5}R_2}{\sim}
\begin{mymatrix}{rrr|r} 1 & 3 & 0 & \frac{3}{2} \\ 0 & 1 & 0 & \frac{2}{5}\\  0 & 0 & 1 & 0 \end{mymatrix} \stackrel{R_1\leftarrow R_1-3R_2}{\sim}
\begin{mymatrix}{rrr|r} 1 & 0 & 0 & \frac{3}{10} \\ 0 & 1 & 0 & \frac{2}{5}\\  0 & 0 & 1 & 0 \end{mymatrix}
\end{align*}
we are in the case where we have a unique solution:
\begin{align*}
x&=\frac{3}{10}\\
y&=\frac{2}{5}\\
z&=0
\end{align*}
this means that $\vect{v}$ is a linear combination of $\vect{u}_1$ and $\vect{u}_2$ only: $\vect{v}=\frac{3}{10}\vect{u}_1+\frac{2}{5}\vect{v}_2$.
\end{solution}

