\section{Elementary operations}

\begin{outcome}
  \begin{enumerate}
  \item Use elementary operations to simplify a system of equations.
  \item Solve some systems of equations by back substitution.
  \item Write a system of equations in augmented matrix form.
  \item Perform elementary row operations on augmented matrices.
  \end{enumerate}
\end{outcome}

Our strategy for solving systems of linear equations is to
successively transform a difficult system of equations into a simpler
equivalent system. Here, by an ``equivalent'' system of equations we
mean one that has the same solutions as the original one. We will
perform the process of simplifying a system of equations by applying
certain basic steps called ``elementary operations''.

\begin{definition}{Equivalent systems}{equivalent-systems}
  Two systems of equations are called
  \textbf{equivalent}\index{system of linear equations!equivalence}
  if they have the same solutions. This means that every solution of
  the first system is also a solution of the second system, and every
  solution of the second system is also a solution of the first system.
\end{definition}

How can we know whether two systems of equations are equivalent? It
turns out that the following basic operations always transform a
system of equations into an equivalent system. In face, these
operations are the {\em key tool} we use in linear algebra to solve
systems of equations.

\begin{definition}{Elementary operations}{elementary-operations}
\textbf{Elementary operations}\index{elementary operations} are the
following operations:

\begin{enumerate}
\item Interchange the order in which the equations are listed.

\item Multiply any equation by a non-zero scalar.

\item Add a multiple of one equation to another equation.
\end{enumerate}
\end{definition}

The most important property of the elementary operations is that they
do not change the solutions to the system of equations. Before proving
that this is true in general, we will first verify it in an example.

\begin{example}{Equivalent systems}{equivalent-systems}
Show that the systems
\begin{equation*}
\begin{array}{r@{~}c@{~}l}
x+2y&=&7 \\
-2x  &=& -6
\end{array}
\end{equation*}
and 
\begin{equation*}
\begin{array}{r@{~}c@{~}l}
x+2y&=&7 \\
4y &=& 8
\end{array}
\end{equation*}
are equivalent.
\end{example}

\begin{solution}
  We can see that the second system is obtained from the first one by
  applying an elementary operation, namely, adding 2 times the first
  equation to the second equation:
  \begin{equation*}
      -2x + 2(x+2y) = -6 + 2(7)
  \end{equation*}
  By simplifying, we obtain $4y = 8$.

  To verify that the two systems are indeed equivalent, let us first
  solve the first system. From the second equation, we see that
  $x=3$. Substituting $x=3$ into the first equation, the equation
  becomes $3+2y=7$, which we can solve to find $y=2$. Therefore, the
  only solution to the first system of equations is $(x,y) = (3,2)$.

  Now let us solve the second system. From the second equation, we
  find that $y=2$. Substituting $y=2$ into the first equation, we get
  $x+4=7$, which we can solve to find $x=3$. Therefore, the only
  solution to the second system of equations is $(x,y) = (3,2)$.
  Since the two systems have the same solutions, they are equivalent.
\end{solution}

This example illustrates how an elementary operation applied to a
system of two equations in two variables does not affect the set of
solutions. The same is true for any size of system in any number of
variables.  In the following theorem, we use the notation $E_i$ to
represent the left-hand side of an equation, while $b_i$ denotes a
constant term.

\begin{theorem}{Elementary operations and solutions}{elementary-operations-and-solns}
Suppose you have a system of two linear equations in any number of variables
\begin{equation}
 \begin{array}{c}
  E_{1}=b_{1}\\
  E_{2}=b_{2}.
\end{array} \label{system}
\end{equation}
Then the following systems are equivalent to \eqref{system}: 
\begin{enumerate}
\item   \begin{equation}
	\begin{array}{c}
	E_{2}=b_{2}\\
	E_{1}=b_{1}.
	\end{array}
	\label{thm-1.9.1}
	\end{equation}
\item  \begin{equation}
	\begin{array}{c}
	E_{1}=b_{1} \\
	kE_{2}=kb_{2}\\        
	\end{array}
	\label{thm-1.9.2}
	\end{equation}
  for any scalar $k$, provided $k\neq0$.
\item \begin{equation}
      \begin{array}{c}
       E_{1}=b_{1} \\
       E_{2}+kE_{1}=b_{2}+kb_{1}
       \end{array}  
	\label{thm-1.9.3}
	\end{equation}
	for any scalar $k$ (including $k=0$).

\end{enumerate}
\end{theorem}

\begin{proof} 
\begin{enumerate}
\item By definition, a solution of \eqref{system} is an assignment of
  scalars to the variables that is a solution to $E_1=b_1$ and to
  $E_2=b_2$. But that is exactly the same thing as a solution of
  \eqref{thm-1.9.1}.

\item To prove that the systems \eqref{system} and \eqref{thm-1.9.2}
  have the same solution set, let $\tup{x_{1},\cdots,x_{n}}$ be
  any solution of \eqref{system}. Then $E_1=b_1$ and $E_2=b_2$ are
  both true. Multiplying both sides of the last equation by $k$, we
  know that $kE_2=kb_2$ is true, and so
  $\tup{x_{1},\cdots,x_{n}}$ is a solution of
  \eqref{thm-1.9.2}. Conversely, let $\tup{x_{1},\cdots,x_{n}}$
  be any solution of \eqref{thm-1.9.2}.  Then $E_1=b_1$ and $kE_2=kb_2$
  are true. Because $k\neq 0$, we are allowed to divide both sides of
  the last equation by $k$, and therefore $E_2=b_2$ is true. Hence,
  $\tup{x_{1},\cdots,x_{n}}$ is also a solution of
  \eqref{system}. Since we have shown that every solution of
  \eqref{system}  is a solution of \eqref{thm-1.9.2} and vice versa,
  the two systems are equivalent.

\item To prove that the systems \eqref{system} and \eqref{thm-1.9.3}
  have the same solution set, let $\tup{x_{1},\cdots,x_{n}}$ be
  any solution of \eqref{system}. Then $E_1=b_1$ and $E_2=b_2$ are
  both true. We multiply both sides of the first equation by $k$ to
  obtain $kE_1=kb_1$. Then $kE_1+E_2 = kb_1+b_2$, and hence
  $\tup{x_{1},\cdots,x_{n}}$ is a solution of
  \eqref{thm-1.9.3}. For the converse direction, assume
  $\tup{x_{1},\cdots,x_{n}}$ is a solution of $E_1=b_1$ and
  $kE_1+E_2 = kb_1+b_2$. From the first equation, we have $kE_1=kb_1$,
  and subtracting this from the second equation, we get $E_2=b_2$,
  hence $\tup{x_{1},\cdots,x_{n}}$ is a solution of
  \eqref{system}. Note that unlike in case 2., there was no need to
  divide by $k$, and therefore it was not necessary to require $k\neq 0$.
\end{enumerate}
\end{proof}

We will now use elementary operations to solve a system of three
equations and three variables.

\begin{example}{Solving a system of equations with elementary operations}{solving-a-system-with-elementary-ops}
Solve the system of equations
\begin{equation*}
\begin{array}{c@{~}c@{~}c@{~}c@{~}c@{~}c@{~}c}
x&+&3y&+&6z&=&25 \\
2x&+&7y&+&14z&=&58 \\
&&2y&+&5z&=&19.
\end{array}
\label{solving-a-system1}
\end{equation*}
\end{example}

\begin{solution}
  By Theorem \ref{thm:elementary-operations-and-solns}, we can do
  elementary operations on this system without changing the solution
  set. We will therefore use elementary operations to try to simplify
  the system of equations.  First, we add $\tup{-2}$ times the
  first equation to the second equation. This yields the system
  \begin{equation*}
    \begin{array}{c@{~}c@{~}c@{~}c@{~}c@{~}c@{~}c}
      x&+&3y&+&6z&=&25 \\
       &&y&+&2z&=&8 \\
       &&2y&+&5z&=&19.
    \end{array}
    \label{solving-a-system2}
  \end{equation*}
  Next, we add $\tup{-2}$ times the second equation to the
  third equation. This yields the system
  \begin{equation}
    \begin{array}{c@{~}c@{~}c@{~}c@{~}c@{~}c@{~}c}
      x&+&3y&+&6z&=&25 \\
      &&y&+&2z&=&8 \\
      &&&&z&=&3.
    \end{array}
    \label{solving-a-system3}
  \end{equation}
  At this point, it is easy to find the solution. The last equation
  tells us that $z=3$. We can substitute this value of $z$ back into
  the second equation to get
  \begin{equation*}
    y+2(3)=8,
  \end{equation*}
  which we can simplify and solve for $y$ to find that $y=2$. Finally,
  we can substitute the values $z=3$ and $y=2$ back into the first
  equation to get
  \begin{equation*}
    x+3(2)+6(3)=25.
  \end{equation*}
  Simplifying and solving for $x$, we find that $x=1$. Hence, the
  solution to the system is $(x,y,z)=(1,2,3)$.

  The process we followed for solving \eqref{solving-a-system3} by first
  computing $z$, then $y$, then $x$ is called \textbf{back
    substitution}\index{back substitution}.  Alternatively, we could
  have continued from \eqref{solving-a-system3} with more elementary
  operations as follows. Add $\tup{-2} $ times the third
  equation to the second and then add $\tup{-6} $ times the
  second to the first. This yields
  \begin{equation*}
    \allowbreak
    \begin{array}{c@{~}c@{~}c@{~}c@{~}c@{~}c@{~}c}
      x&+&3y&&&=&7 \\
      &&y&&&=&2 \\
      &&&&z&=&3.
    \end{array}
  \end{equation*}
  Now add $\tup{-3} $ times the second to the first. This yields
  \begin{equation*}
    \allowbreak
    \begin{array}{c@{~}c@{~}c@{~}c@{~}c@{~}c@{~}c}
      x&&&&&=&1 \\
      &&y&&&=&2 \\
      &&&&z&=&3,
    \end{array}
  \end{equation*}
  a system which has the same solution set as the original
  system. This second method avoided back substitution and led to the
  same solution set. It is your decision which you prefer to use, as
  both methods lead to the correct solution,
  $\tup{x,y,z } = \tup{1,2,3}$.
\end{solution}

Note how we have written each system of equations so that ``like''
variables line up on columns: one column for $x$, one column for $y$,
and one column for $z$. This makes it easier to perform elementary
operations. It is often useful to simplify the notation further,
writing systems of equations in \textbf{augmented matrix}\index{augmented matrix|seealso{matrix}}\index{augmented matrix}\index{matrix!augmented matrix} notation. Recall the
system of equations from Example \ref{exa:solving-a-system-with-elementary-ops}:
\begin{equation*}
\begin{array}{c@{~}c@{~}c@{~}c@{~}c@{~}c@{~}c}
x&+&3y&+&6z&=&25 \\
2x&+&7y&+&14z&=&58 \\
&&2y&+&5z&=&19.
\end{array}
\end{equation*}
This system can be written as an augmented matrix as follows:
\begin{equation*}
\begin{mymatrix}{rrr|r}
1 & 3 & 6 & 25 \\
2 & 7 & 14 & 58 \\
0 & 2 & 5 & 19
\end{mymatrix}.
\end{equation*}
A \textbf{matrix}\index{matrix} is just a 2-dimensional array of
numbers. An augmented matrix has two parts separated by a vertical
line. Notice that the augmented matrix notation has exactly the same
information as the original system of equations. All the coefficients
are written on the left side of the vertical line, and all the
constant terms are written on the right side of the vertical
line. These two parts of the augmented matrix are also called the
\textbf{coefficient matrix}\index{coefficient matrix}%
\index{matrix!coefficient matrix} and the \textbf{constant
  matrix}\index{constant matrix}\index{matrix!constant matrix}.  Each
row of the augmented matrix corresponds to one linear equation. For
example, the top row $\begin{mymatrix}{rrrrr} 1 & 3 & 6 & | & 25
\end{mymatrix}$
 corresponds to the equation
\begin{equation*}
x+3y+6z=25.
\end{equation*}
Each column of the coefficient matrix contains the coefficients
for one particular variable. For example, the first column $\begin{mymatrix}{r}
1 \\
2 \\
0
\end{mymatrix}$ contains all of the coefficients for the variable $x$. If a
variable does not appear in an equation, the corresponding coefficient
is $0$. In general, the augmented matrix of a linear system of
equations is defined as follows.

\begin{definition}{Augmented matrix of a system of linear equations}{augmented-matrix}
  The \textbf{augmented matrix}\index{augmented matrix}\index{matrix!augmented matrix}
  of the system of linear equations
  \begin{equation*}
    \begin{array}{c}
      a_{11}x_{1}+\cdots +a_{1n}x_{n}=b_{1} \\
      \vdots \\
      a_{m1}x_{1}+\cdots +a_{mn}x_{n}=b_{m}
    \end{array}
  \end{equation*}
  is
  \begin{equation*}
    \begin{mymatrix}{rrr|r}
      a_{11} & \cdots & a_{1n} &  b_{1} \\
      \vdots &  & \vdots &  \vdots \\
      a_{m1} & \cdots & a_{mn} &  b_{m}
    \end{mymatrix}.
  \end{equation*}
\end{definition}

We can consider elementary operations in the context of the augmented
matrix. The elementary operations can be used on the rows of an
augmented matrix just as we used them on equations previously. For
example, instead of adding a multiple of one equation to another, we
will now be adding a multiple of one row to another. Note that Theorem
\ref{thm:elementary-operations-and-solns} implies that any elementary row
operation used on an augmented matrix will not change the solutions
to the corresponding system of equations. For reference, here are the
three kinds of elementary row operations, along with a shorthand
notation we are going to use for them.

\begin{definition}{Elementary row operations}{row-operations}
  The \textbf{elementary row operations}\index{row operations}\index{elementary row operations} are the following:
  

  \begin{enumerate}
  \item Switch two rows. (Notation: $R_i\leftrightarrow R_j$ to switch
    rows $i$ and $j$).
    
  \item Multiply a row by a non-zero number.  (Notation: $R_i\leftarrow
    kR_i$ to multiply row $i$ by $k$).    
    
  \item Add a multiple of one row to another row. (Notation:
    $R_i\leftarrow R_i+kR_j$ to add $k$ times row $j$ to row $i$.)
  \end{enumerate}
\end{definition}

We write ``$\sim$'' to indicate that two augmented matrices are
equivalent, i.e., that the corresponding systems of equations have the
same set of solutions.

\begin{example}{Elementary row operations}{}
  Repeat the calculations of Example
  \ref{exa:solving-a-system-with-elementary-ops}, using the notations we
  just introduced.
\end{example}

\begin{solution}
  We have:
  \begin{equation*}
    \begin{mymatrix}{rrr|r}
      1 & 3 & 6 &  25 \\
      2 & 7 & 14 &  58 \\
      0 & 2 & 5 &  19
    \end{mymatrix} 
    \stackrel{R_2\leftarrow R_2-2R_1}{\sim}
    \begin{mymatrix}{rrr|r}
      1 & 3 & 6 & 25 \\
      0 & 1 & 2 & 8 \\
      0 & 2 & 5 & 19
    \end{mymatrix} 
    \stackrel{R_3\leftarrow R_3-2R_2}{\sim}
    \begin{mymatrix}{rrr|r}
      1 & 3 & 6 & 25 \\
      0 & 1 & 2 & 8 \\
      0 & 0 & 1 & 3
    \end{mymatrix}.
  \end{equation*}
  The final augmented matrix corresponds to the system
  \begin{equation*}
    \begin{array}{c@{~}c@{~}c@{~}c@{~}c@{~}c@{~}c}
      x&+&3y&+&6z&=&25 \\
      &&y&+&2z&=&8 \\
      &&&&z&=&3,
    \end{array}
  \end{equation*}
  which is the same as \ref{solving-a-system3}. We can solve it by back
  substitution to obtain the solution $x=1,y=2,$ and $z=3$.

  Alternatively, we can continue with additional row operations:
  \begin{equation*}
    \begin{mymatrix}{rrr|r}
      1 & 3 & 6 & 25 \\
      0 & 1 & 2 & 8 \\
      0 & 0 & 1 & 3
    \end{mymatrix}
    \stackrel{R_1\leftarrow R_1-6R_3}{\stackrel{R_2\leftarrow R_2-2R_3}{\sim}}
    \begin{mymatrix}{rrr|r}
      1 & 3 & 0 & 7 \\
      0 & 1 & 0 & 2\\
      0 & 0 & 1 & 3
    \end{mymatrix}
    \stackrel{R_1\leftarrow R_1-3R_2}{\sim}
    \begin{mymatrix}{rrr|r}
      1 & 0 & 0 & 1\\
      0 & 1 & 0 & 2\\
      0 & 0 & 1 & 3
    \end{mymatrix}.
  \end{equation*}
  Notice how this notation is much more succinct than what we used in
  Example~\ref{exa:solving-a-system-with-elementary-ops}.
\end{solution}

We end this section with a final word of caution: logically, you can
only perform one elementary row operation at a time. For example, it
would not be correct to simultaneously add $R_1$ to $R_2$ and add
$R_2$ to $R_1$. What is permitted is to first add $R_1$ to $R_2$, then
then add the {\em new} $R_2$ to $R_1$. Although we may sometimes try
to save space by skipping an intermediate step, as in the last example
where we applied the row operations $R_1\leftarrow R_1-6R_3$ and
$R_2\leftarrow R_2-2R_3$ in one step, it is important to realize that
logically, each row operation must be performed separately before the
next one can be done. When in doubt, the only safe course of action is
not to skip any steps.
