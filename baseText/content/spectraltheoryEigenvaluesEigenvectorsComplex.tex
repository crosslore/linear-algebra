\section{Complex eigenvalues and eigenvectors}

\begin{outcome}
  \begin{enumerate}
  \item Find the complex eigenvalues and eigenvectors of a matrix.
  \item Diagonalize a matrix over the complex numbers.
  \end{enumerate}
\end{outcome}

An $n\times n$-matrix is diagonalizable if and only if it has $n$
linearly independent eigenvectors. But as we saw in
Example~\ref{exa:no-real-eigenvalue}, if we work over the real
numbers, it can sometimes happen that a matrix has no eigenvalues, and
therefore no eigenvectors, at all. For example, the matrix
\begin{equation*}
  A=\begin{mymatrix}{rr}
      0 & -1 \\
      1 &  0 \\
    \end{mymatrix}
\end{equation*}
has characteristic polynomial $\eigenvar^2+1$. Since the equation
$\eigenvar^2+1$ does not have any roots in the real numbers, there are
no real eigenvalues.

On the other hand, the fundamental theorem of algebra tell us that
over the {\em complex} numbers, every non-constant polynomial has a
root. In fact, every polynomial of degree $n$ factors into $n$ linear
factors. Therefore, every matrix has at least one eigenvalue over the
complex numbers%
\index{eigenvalue!complex}%
\index{matrix!eigenvalue!complex}%
\index{eigenvector!complex}%
\index{matrix!eigenvector!complex}%
\index{vector!eigenvector!complex}. Some matrices are diagonalizable
over the complex numbers but not over the real numbers. An
introduction to complex numbers and the fundamental theorem of algebra
can be found in Appendix~\ref{app:complex}.

\begin{example}{Complex eigenvalues and eigenvectors}{complex-eigenvalue1}
  Find the eigenvectors and eigenvalues of
  \begin{equation*}
    A=\begin{mymatrix}{rr}
      0 & -1 \\
      1 &  0 \\
    \end{mymatrix}
  \end{equation*}
  over the complex numbers. Diagonalize $A$ if possible.
\end{example}

\begin{solution}
  The characteristic polynomial is $\eigenvar^2+1$. This has no roots
  in the real numbers, but it has two roots $\eigenvar=i$ and
  $\eigenvar=-i$\, in the complex numbers. To find the eigenvectors for
  $\eigenvar=i$, we solve $(A-iI)\vect{v}=\vect{0}$:
  \begin{equation*}
    \begin{mymatrix}{rr|r}
      -i & -1 & 0 \\
      1 & -i & 0 \\
    \end{mymatrix}
    \quad\stackrel{R_1\rowswap R_2}{\roweq}\quad
    \begin{mymatrix}{rr|r}
      1 & -i & 0 \\
      -i & -1 & 0 \\
    \end{mymatrix}
    \quad\stackrel{R_2\rowop R_2+iR_1}{\roweq}\quad
    \begin{mymatrix}{rr|r}
      1 & -i & 0 \\
      0 & 0 & 0 \\
    \end{mymatrix}.
  \end{equation*}
  Thus, the basic eigenvector for $\eigenvar=i$\, is
  \begin{equation*}
    \vect{v}_1 = \begin{mymatrix}{c} i \\ 1 \end{mymatrix}.
  \end{equation*}
  Similarly, to find the eigenvectors for $\eigenvar=-i$, we solve
  $(A+iI)\vect{v}=\vect{0}$:
  \begin{equation*}
    \begin{mymatrix}{cc|c}
      i & -1 & 0 \\
      1 &  i & 0 \\
    \end{mymatrix}
    \quad\stackrel{R_1\rowswap R_2}{\roweq}\quad
    \begin{mymatrix}{cc|c}
      1 &  i & 0 \\
      i & -1 & 0 \\
    \end{mymatrix}
    \quad\stackrel{R_2\rowop R_2-iR_1}{\roweq}\quad
    \begin{mymatrix}{cc|c}
      1 & i & 0 \\
      0 & 0 & 0 \\
    \end{mymatrix}.
  \end{equation*}
  Thus, the basic eigenvector for $\eigenvar=-i$\, is
  \begin{equation*}
    \vect{v}_2 = \begin{mymatrix}{r} -i \\ 1 \end{mymatrix}.
  \end{equation*}
  Since we have found two linearly independent eigenvectors, the
  matrix $A$ is diagonalizable. We have $A=PDP^{-1}$, where
  \begin{equation*}
    P =
    \begin{mymatrix}{cr}
      i & -i \\
      1 &  1 \\
    \end{mymatrix}
    \quad\mbox{and}\quad
    D =
    \begin{mymatrix}{cr}
      i &  0 \\
      0 & -i \\
    \end{mymatrix}.
  \end{equation*}
\end{solution}

\begin{example}{Complex eigenvalues and eigenvectors}{complex-eigenvalue2}
  Find the eigenvectors and eigenvalues of
  \begin{equation*}
    A=\begin{mymatrix}{rr}
      1 & -1 \\
      1 &  1 \\
    \end{mymatrix}
  \end{equation*}
  over the complex numbers. Diagonalize $A$ if possible.
\end{example}

\begin{solution}
  The characteristic polynomial is
  \begin{equation*}
    \det(A-\eigenvar I)
    = \begin{absmatrix}{cc}
      1-\eigenvar & -1 \\
      1 & 1-\eigenvar \\
    \end{absmatrix}
    = (1-\eigenvar)^2 + 1
    = \eigenvar^2 - 2\eigenvar + 2.
  \end{equation*}
  To find the roots, we use the quadratic formula. The roots are given
  by:
  \begin{equation*}
    \eigenvar
    = \frac{-b\pm\sqrt{b^2-4ac}}{2a}
    = \frac{2\pm\sqrt{-4}}{2} = 1\pm i.
  \end{equation*}
  Note that since the discriminant $b^2-4ac$ is negative, there are no
  real solutions. However, we find two complex solutions $\eigenvar=1+i$
  and $\eigenvar=1-i$. To find the eigenvectors for $\eigenvar=1+i$, we
  solve the equation $(A-(1+i)I)\vect{v}=\vect{0}$:
  \begin{equation*}
    \begin{mymatrix}{rr|r}
      -i & -1 & 0 \\
      1 & -i & 0 \\
    \end{mymatrix}
    \quad\roweq\ldots\roweq\quad
    \begin{mymatrix}{rr|r}
      1 & -i & 0 \\
      0 & 0 & 0 \\
    \end{mymatrix}.
  \end{equation*}
  The basic eigenvector for $\eigenvar=1+i$\, is
  \begin{equation*}
    \vect{v}_1 = \begin{mymatrix}{c} i \\ 1 \end{mymatrix}.
  \end{equation*}
  Similarly, the basic eigenvector for $\eigenvar=1-i$\, is
  \begin{equation*}
    \vect{v}_2 = \begin{mymatrix}{r} -i \\ 1 \end{mymatrix}.
  \end{equation*}
  Since we have found two linearly independent eigenvectors, the
  matrix $A$ is diagonalizable. We have $A=PDP^{-1}$, where
  \begin{equation*}
    P =
    \begin{mymatrix}{cr}
      i & -i \\
      1 &  1 \\
    \end{mymatrix}
    \quad\mbox{and}\quad
    D =
    \begin{mymatrix}{cc}
      1+i &  0 \\
      0 & 1-i \\
    \end{mymatrix}.
  \end{equation*}
\end{solution}

\begin{example}{Diagonalize a matrix over the complex numbers}{complex-diagonalize}
  Diagonalize the matrix
  \begin{equation*}
    A = \begin{mymatrix}{rrr}
      -3 & -2 & 4 \\
      2  &  1 & 0 \\
      -2 & -2 & 3 \\
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  The characteristic polynomial is
  \begin{equation*}
    p(\eigenvar)
    = (-3-\eigenvar)(1-\eigenvar)(3-\eigenvar) - 16 +8(1-\eigenvar) + 4(3-\eigenvar)
    = -\eigenvar^3 + \eigenvar^2 - 3\eigenvar - 5.
  \end{equation*}
  By trial and error, we find that $\eigenvar=-1$ is one of the
  roots. We factor out $(\eigenvar + 1)$:
  \begin{equation*}
    p(\eigenvar) = (\eigenvar+1)(-\eigenvar^2 + 2\eigenvar - 5).
  \end{equation*}
  We then use the quadratic formula to find the other two eigenvalues,
  i.e., the roots of $-\eigenvar^2 + 2\eigenvar - 5$. They are:
  \begin{equation*}
    \eigenvar = \frac{-2\pm\sqrt{-16}}{-2} = 1\pm 2i.
  \end{equation*}
  Eigenvectors:
  \begin{itemize}
  \item For $\eigenvar=-1$, we solve $(A-(-1)I)\vect{v}=\vect{0}$:
    \begin{equation*}
      \begin{mymatrix}{rrr|r}
        -2 & -2 & 4 & 0 \\
        2  &  2 & 0 & 0 \\
        -2 & -2 & 4 & 0 \\
      \end{mymatrix}
      \quad\roweq\ldots\roweq\quad
      \begin{mymatrix}{rrr|r}
        1 & 1 &  0 & 0 \\
        0 & 0 &  1 & 0 \\
        0 & 0 &  0 & 0 \\
      \end{mymatrix}.
    \end{equation*}
    The basic eigenvector is
    \begin{equation*}
      \vect{v}_1 = \begin{mymatrix}{r} -1 \\ 1 \\ 0 \end{mymatrix}.
    \end{equation*}
  \item For $\eigenvar=1+2i$, we solve $(A-(1+2i)I)\vect{v}=\vect{0}$:
    \begin{eqnarray*}
      \begin{mymatrix}{ccc|c}
        -4-2i & -2  & 4    & 0 \\
        2     & -2i & 0    & 0 \\
        -2    & -2  & 2-2i & 0 \\
      \end{mymatrix}
      & \stackrel{R_1\rowop-R_1/2}{
        \stackrel{R_2\rowop R_2/2}{
        \stackrel{R_3\rowop -R_3/2}{\roweq}}} &
      \begin{mymatrix}{ccc|c}
        2+i &  1 &  -2 & 0 \\
        1   & -i &  0  & 0 \\
        1   &  1 & i-1 & 0 \\
      \end{mymatrix}
      \\
      &\stackrel{R_1\rowswap R_2}{\roweq} &
      \begin{mymatrix}{ccc|c}
        1   & -i &  0  & 0 \\
        2+i &  1 &  -2 & 0 \\
        1   &  1 & i-1 & 0 \\
      \end{mymatrix}
      \\
      & \stackrel{R_2\rowop R_2-(2+i)R_1}{
        \stackrel{R_3\rowop R_3-R_1}{\roweq}} &
      \begin{mymatrix}{ccc|c}
        1   & -i  &  0  & 0 \\
        0   & 2i  & -2  & 0 \\
        0   & 1+i & i-1 & 0 \\
      \end{mymatrix}
      \\
      & \stackrel{R_2 \rowop R_2/2i}{
        \stackrel{R_3 \rowop R_3/(1+i)}{\roweq}} &
      \begin{mymatrix}{ccc|c}
        1   & -i  &  0  & 0 \\
        0   & 1  &   i  & 0 \\
        0   & 1   &  i  & 0 \\
      \end{mymatrix}
      \\
      & \stackrel{R_1 \rowop R_1+iR_2}{
        \stackrel{R_3 \rowop R_3-R_2}{\roweq}} &
      \begin{mymatrix}{ccc|c}
        1     & 0   & -1  & 0 \\
        0     & 1   & i   & 0 \\
        0     & 0   & 0   & 0 \\
      \end{mymatrix}.
    \end{eqnarray*}
    The basic eigenvector is
    \begin{equation*}
      \vect{v}_2 = \begin{mymatrix}{r} 1 \\ -i \\ 1 \end{mymatrix}.
    \end{equation*}
  \item For $\eigenvar=1-2i$, we solve $(A-(1-2i)I)\vect{v}=\vect{0}$:
    \begin{equation*}
      \begin{mymatrix}{ccc|c}
        -4+2i & -2  & 4    & 0 \\
        2     &  2i & 0    & 0 \\
        -2    & -2  & 2+2i & 0 \\
      \end{mymatrix}
      \quad\roweq\ldots\roweq\quad
      \begin{mymatrix}{ccc|c}
        1     & 0   & -1  & 0 \\
        0     & 1   & -i  & 0 \\
        0     & 0   & 0   & 0 \\
      \end{mymatrix}.
    \end{equation*}
    The basic eigenvector is
    \begin{equation*}
      \vect{v}_3 = \begin{mymatrix}{c} 1 \\ i \\ 1 \end{mymatrix}.
    \end{equation*}
    Therefore, $A=PDP^{-1}$, where
    \begin{equation*}
      P =
      \begin{mymatrix}{ccc}
        -1 &  1 & 1 \\
        1  & -i & i \\
        0  &  1 & 1 \\
      \end{mymatrix}
      \quad\mbox{and}\quad
      D =
      \begin{mymatrix}{ccc}
        -1 &  0   & 0    \\
        0  & 1+2i & 0    \\
        0  &  0   & 1-2i \\
      \end{mymatrix}.
    \end{equation*}
  \end{itemize}
\end{solution}

In Example~\ref{exa:complex-eigenvalue1}, the complex eigenvalues were
$i$ and $-i$. In Example~\ref{exa:complex-eigenvalue2}, the complex
eigenvalues were $1+i$ and $1-i$. In
Example~\ref{exa:complex-diagonalize}, the complex eigenvalues were
$1+2i$ and $1-2i$, and there was also a real eigenvalue of $-1$.  Is
it a coincidence that the complex eigenvalues always come in conjugate
pairs? The following proposition states that this is always the case.

\begin{proposition}{Complex conjugate eigenvalues}{conjugate-eigenvalues}
  Let $A$ be a square matrix whose entries are real numbers. If
  $\eigenvar$ is an eigenvalue of $A$, then so is $\overline{\eigenvar}$.
\end{proposition}

\begin{proof}
  Assume $\eigenvar$ is an eigenvalue of $A$ with corresponding
  eigenvector $\vect{v}$. Then $A\vect{v} = \eigenvar\vect{v}$. Taking
  complex conjugates of both sides of the equation, we have
  $\overline{A\vect{v}} = \overline{\eigenvar\vect{v}}$, and therefore
  $\overline{A}\overline{\vect{v}} =
  \overline{\eigenvar}\overline{\vect{v}}$. Since $A$ is matrix with
  real entries, we have $\overline{A}=A$, and therefore
  $A\overline{\vect{v}} = \overline{\eigenvar}\overline{\vect{v}}$.
  It follows that $\overline{\eigenvar}$ is an eigenvalue of $A$ with
  corresponding eigenvector $\overline{\vect{v}}$.
\end{proof}

It is important to note that even over the complex numbers, not all
matrices are diagonalizable. On the one hand, the characteristic
polynomial of an $n\times n$-matrix always factors into $n$ linear
factors over the complex numbers. Therefore, the sum of the algebraic
multiplicities%
\index{algebraic multiplicity!of an eigenvalue}%
\index{eigenvalue!algebraic multiplicity}%
\index{multiplicity!of eigenvalue!algebraic} of the eigenvalues is
always $n$. However, it can still happen that the geometric
multiplicity%
\index{geometric multiplicity!of an eigenvalue}%
\index{eigenvalue!geometric multiplicity}%
\index{multiplicity!of eigenvalue!geometric} of some eigenvalue is
less than its algebraic multiplicity. In that case, the matrix is not
diagonalizable, even over the complex numbers. We have:

\begin{proposition}{Diagonalizability criterion}{complex-diagonalizability}
  A square matrix $A$ is diagonalizable over the complex numbers if
  and only if the geometric multiplicity of each eigenvalue is equal
  to its algebraic multiplicity.
\end{proposition}

\begin{proof}
  Let $A$ be an $n\times n$-matrix. By the fundamental theorem of
  algebra, the characteristic polynomial factors into $n$ linear
  factors. Therefore, the sum of the algebraic multiplicities of all
  the eigenvalues is $n$. We know by
  Proposition~\ref{prop:dimension-eigenspace} that the geometric
  multiplicity of each eigenvalue less than or equal to its algebraic
  multiplicity. If the geometric multiplicity of each eigenvalue is
  equal to its algebraic multiplicity, then the sum of the geometric
  multiplicities is $n$, and therefore $A$ is diagonalizable by
  Proposition~\ref{prop:multiplicity-and-diagonalization}. On the
  other hand, if the geometric multiplicity of some eigenvalue is less
  than its algebraic multiplicity, then the sum of the geometric
  multiplicities is less than $n$, and $A$ is not diagonalizable.
\end{proof}

\begin{example}{Non-diagonalizable matrix}{complex-non-diagonalizable}
  Show that the matrix $A =
    \begin{mymatrix}{rr}
      1 & 1 \\
      0 & 1
    \end{mymatrix}$ cannot be diagonalized, even over the complex numbers.
\end{example}

\begin{solution}
  The characteristic polynomial is $(1-\eigenvar)^2$, and therefore
  the only eigenvalue is $\eigenvar=1$, with algebraic multiplicity
  $2$. On the other hand, the eigenspace for $\eigenvar=1$ is
  $1$-dimensional:
  \begin{equation*}
    \begin{mymatrix}{rr}
      0 & 1 \\
      0 & 0
    \end{mymatrix}
    \vect{v}
    = \begin{mymatrix}{r} 0 \\ 0 \end{mymatrix}
  \end{equation*}
  has a $1$-dimensional solution space. Therefore, we can find only one
  basic eigenvector, and the matrix is not diagonalizable.
\end{solution}

To finish up this chapter, we will consider an application of complex
eigenvalues. We will solve a recurrence as in
Section~\ref{sec:recurrence}. But this time, although the recurrence
relation only uses real numbers, complex numbers will be required to
solve it.

\begin{example}{Solving a recurrence using complex eigenvalues}{recurrence-complex}
  Consider the sequence of numbers defined by the recurrence
  \begin{equation*}
    \begin{array}{l@{~}c@{~}l}
      f_0 &=& 1, \\
      f_1 &=& 3, \\
      f_{n+2} &=& 2f_{n+1} - 2f_{n}, \quad\mbox{for all $n\geq 0$.}\\
    \end{array}
  \end{equation*}
  Solve the recurrence, i.e., find a closed formula for $f_n$.
\end{example}

\begin{solution}
  The first few members of the sequence are:
  \begin{equation*}
    1, 3, 4, 2, -4, -12, -16, -8, 16, \ldots
  \end{equation*}
  To solve the recurrence, let
  \begin{equation*}
    \vect{v}_n = \begin{mymatrix}{c} f_n \\ f_{n+1} \end{mymatrix},
  \end{equation*}
  so that for all $n\geq 0$,
  \begin{equation*}
    \vect{v}_{n+1}
    = \begin{mymatrix}{c} f_{n+1} \\ f_{n+2} \end{mymatrix}
    = \begin{mymatrix}{c} f_{n+1} \\ 2f_{n+1} - 2f_{n} \end{mymatrix}
    = \begin{mymatrix}{rr}
      0  & 1 \\
      -2 & 2 \\
    \end{mymatrix}
    \begin{mymatrix}{c} f_n \\ f_{n+1} \end{mymatrix}
    = \begin{mymatrix}{rr}
      0  & 1 \\
      -2 & 2 \\
    \end{mymatrix}
    \vect{v}_n.
  \end{equation*}
  We then diagonalize the matrix
  \begin{equation*}
    A = \begin{mymatrix}{rr}
      0  & 1 \\
      -2 & 2 \\
    \end{mymatrix}.
  \end{equation*}
  The characteristic polynomial is
  \begin{equation*}
    p(\eigenvar) = \eigenvar^2 - 2\eigenvar + 2.
  \end{equation*}
  The eigenvalues are the roots of the characteristic polynomial. We
  compute them using the quadratic formula:
  \begin{equation*}
    \eigenvar_1,\eigenvar_2
    = \frac{2\pm\sqrt{4-8}}{2}
    = \frac{2\pm2i}{2}
    = 1\pm i.    
  \end{equation*}
  To find the eigenvectors for $\eigenvar_1 = 1+i$, we solve the
  equation $(A-(1+i)I)\vect{v} = \vect{0}$:
  \begin{equation*}
    \begin{mymatrix}{cc|r}
      -1-i & 1 & 0 \\
      -2 & 1-i & 0 \\
    \end{mymatrix}
    \quad\stackrel{R_1\rowop (1-i)R_1}{\roweq}\quad
    \begin{mymatrix}{cc|r}
      -2 & 1-i & 0 \\
      -2 & 1-i & 0 \\
    \end{mymatrix}
    \quad\roweq\quad
    \begin{mymatrix}{cc|r}
      -2 & 1-i & 0 \\
      0  &  0  & 0 \\
    \end{mymatrix}.
  \end{equation*}
  A basic eigenvector for $\eigenvar=1+i$\, is
  \begin{equation*}
    \vect{v} = \begin{mymatrix}{c} 1-i \\ 2 \end{mymatrix}.
  \end{equation*}
  Similarly, a basic eigenvector for $\eigenvar=1-i$\, is
  \begin{equation*}
    \vect{u} = \begin{mymatrix}{r} 1+i \\ 2 \end{mymatrix}.
  \end{equation*}
  Since we have found two linearly independent eigenvectors, the
  matrix $A$ is diagonalizable. We have $A = PDP^{-1}$, where
  \begin{equation*}
    P = \begin{mymatrix}{cc}
      1-i & 1+i \\
      2   & 2   \\
    \end{mymatrix}
    \quad\mbox{and}\quad
    D = \begin{mymatrix}{cc}
      1+i & 0   \\
      0   & 1-i \\
    \end{mymatrix}.
  \end{equation*}
  The inverse of $P$ is
  \begin{equation*}
    P^{-1} =
    \frac{1}{4}
    \begin{mymatrix}{cc}
      2i  & 1-i \\
      -2i & 1+i \\
    \end{mymatrix}.
  \end{equation*}
  Finally, we use this information to solve the recurrence:
  \begin{eqnarray*}
    f_n
    &=& \begin{mymatrix}{cc} 1 & 0 \end{mymatrix}
        \begin{mymatrix}{c} f_n \\ f_{n+1} \end{mymatrix} \\
    &=& \begin{mymatrix}{cc} 1 & 0 \end{mymatrix}\vect{v}_n \\
    &=& \begin{mymatrix}{cc} 1 & 0 \end{mymatrix}A^n\,\vect{v}_0 \\
    &=& \begin{mymatrix}{cc} 1 & 0 \end{mymatrix}PD^nP^{-1}\,\vect{v}_0 \\
    &=& \begin{mymatrix}{cc} 1 & 0 \end{mymatrix}
        \begin{mymatrix}{cc} 1-i & 1+i \\ 2 & 2 \end{mymatrix}
        \begin{mymatrix}{cc} (1+i)^n & 0 \\ 0 & (1-i)^n \end{mymatrix}
        \frac{1}{4}
        \begin{mymatrix}{cc} 2i & 1-i \\ -2i & 1+i \end{mymatrix}
        \begin{mymatrix}{c} 1 \\ 3 \end{mymatrix} \\
    &=& \frac{1}{4}
        \begin{mymatrix}{cc} 1-i & 1+i \end{mymatrix}
        \begin{mymatrix}{cc} (1+i)^n & 0 \\ 0 & (1-i)^n \end{mymatrix}
        \begin{mymatrix}{c} 3-i \\ 3+i \end{mymatrix} \\
    &=& \frac{1}{4}\paren{(1-i)(1+i)^n(3-i) + (1+i)(1-i)^n(3+i)} \\
    &=& \frac{1}{4}\paren{(2-4i)(1+i)^n + (2+4i)(1-i)^n} \\
    &=& \frac{1}{2}\paren{(1-2i)(1+i)^n + (1+2i)(1-i)^n}.
  \end{eqnarray*}
  We can use this, for example, to calculate the $8\th$ element of the
  sequence:
  \begin{equation*}
    f_{8}
    ~=~ \frac{1}{2}\paren{(1-2i)(1+i)^8 + (1+2i)(1-i)^8}
    ~=~ \frac{1}{2}\paren{(1-2i)16 + (1+2i)16}
    ~=~ \frac{32}{2}
    ~=~ 16.
  \end{equation*}

\end{solution}
