\section{Linear transformations}

\begin{outcome}
\begin{enumerate}
\item[A.] Understand the definition of a linear transformation in the context of vector spaces. 
\end{enumerate}
\end{outcome}

Recall that a function is simply a transformation of a vector to result in a new vector. Consider the following definition. 

\begin{definition}{Linear transformation}{lineartransformation}
 Let $V$ and $W$ be vector spaces. Suppose $T: V \mapsto W$ is a function, where for each
$\vect{x} \in V ,T\tup{\vect{x}}\in W.$ Then $T$ is a
\textbf{linear transformation}\index{linear transformation} if whenever $k ,p $ are scalars and 
$\vect{v}_1$ and $\vect{v}_2$ are vectors in $V$
\begin{equation*}
T\tup{k \vect{v}_1 + p \vect{v}_2 } = kT\tup{\vect{v}_1}+ pT\tup{\vect{v}_{2} }
\end{equation*}
\end{definition}

Several important examples of linear transformations include the zero transformation, the identity transformation, and the scalar transformation. 

\begin{example}{Linear transformations}{lineartransformations}
Let $V$ and $W$ be vector spaces.

\begin{enumerate}
\item \textbf{The zero transformation}\index{zero transformation}

$0:V\to W$ is defined by $0(\vect{v})=\vect{0}$ for all $\vect{v}\in V$.


\item \textbf{The identity transformation}\index{identity transformation}

$1_V:V\to V$ is defined by $1_V(\vect{v})=\vect{v}$ for all $\vect{v}\in V$.

\item \textbf{The scalar transformation}\index{scalar transformation}
Let $a\in\R$.

$s_a:V\to V$ is defined by $s_a(\vect{v})=a\vect{v}$ for all $\vect{v}\in V$.
\end{enumerate}
\end{example}

\begin{solution}
We will show that the scalar transformation $s_a$ is linear, the rest are left as an exercise. 

By Definition \ref{def:lineartransformation} we must show that for all scalars $k ,p $ and 
vectors $\vect{v}_1$ and $\vect{v}_2$ in $V$, $s_a\tup{k \vect{v}_1 + p \vect{v}_2 } = k s_a\tup{\vect{v}_1}+ p s_a\tup{\vect{v}_{2} }$. Assume that $a$ is also a scalar. 
\begin{eqnarray*}
s_a\tup{k \vect{v}_1 + p \vect{v}_2 } &=& a \tup{k \vect{v}_1 + p \vect{v}_2 } \\
&=&  ak \vect{v}_1 + ap \vect{v}_2  \\
 &=&  k \tup{a \vect{v}_1} + p\tup{a \vect{v}_2}  \\
&=& k s_a\tup{\vect{v}_1 }  + p s_a \tup{\vect{v}_2 }
\end{eqnarray*}
Therefore $s_a$ is a linear transformation.
\end{solution}

Consider the following important theorem.

\begin{theorem}{Properties of linear transformations}{properties}
Let $V$ and $W$ be vector spaces, and $T:V \mapsto W$ a linear
transformation. 
Then
\begin{enumerate}
\item $T$ preserves the zero vector.
\[
T(\vect{0})=\vect{0}
\]
\item $T$ preserves additive inverses. 
For all $\vect{v}\in V$, 
\[
T(-\vect{v})= -T(\vect{v})
\]
\item $T$ preserves linear combinations.
For all $\vect{v}_1, \vect{v}_2, \ldots, \vect{v}_m \in V$ and
all $k_1, k_2, \ldots, k_m\in\R$,
\[ T(k_1\vect{v}_1 + k_2\vect{v}_2 + \cdots + k_m\vect{v}_m)
= k_1T(\vect{v}_1) + k_2T(\vect{v}_2) + \cdots + k_mT(\vect{v}_m).\]
\end{enumerate}
\end{theorem}

\begin{proof}
\begin{enumerate}
\item Let $\vect{0}_V$ denote the zero vector of $V$ and let
$\vect{0}_W$ denote the zero vector of $W$.
We want to prove that $T(\vect{0}_V)=\vect{0}_W$.
Let $\vect{v}\in V$. 
Then $0\vect{v}=\vect{0}_V$ and
\[ T(\vect{0}_V)=T(0\vect{v})=0T(\vect{v})=\vect{0}_W.\]
\item
Let $\vect{v}\in V$; then $-\vect{v}\in V$ is the additive
inverse of $\vect{v}$, so $\vect{v} + (-\vect{v})=\vect{0}_V$.
Thus
\begin{eqnarray*}
T(\vect{v} + (-\vect{v})) & = & T(\vect{0}_V) \\
T(\vect{v}) + T(-\vect{v})) & = & \vect{0}_W \\
T(-\vect{v}) & = & \vect{0}_W - T(\vect{v}) =  - T(\vect{v}).
\end{eqnarray*}
\item This result follows from 
preservation of addition and preservation of scalar multiplication.
A formal proof would be by induction on $m$.
\end{enumerate}
\end{proof}

Consider the following example using the above theorem. 

\begin{example}{Linear combination}{lintransfcombination2}
Let $T:\Poly_2 \to \R$ be a linear transformation such that
\[ T(x^2+x)=-1; T(x^2-x)=1; T(x^2+1)=3.\]
Find $T(4x^2+5x-3)$.
\end{example}

\begin{solution}
We provide two solutions to this problem.

\textbf{Solution 1:}
Suppose
$a(x^2+x) + b(x^2-x) + c(x^2+1) = 4x^2+5x-3$. 
Then
\[ (a+b+c)x^2 + (a-b)x + c = 4x^2+5x-3.\]
Solving for $a$, $b$, and $c$ results in the unique solution
$a=6$, $b=1$, $c=-3$.

Thus
\begin{eqnarray*}
T(4x^2+5x-3) & = & T\tup{6(x^2+x) + (x^2-x) -3(x^2+1) } \\
& = & 6T(x^2+x) + T(x^2-x) -3T(x^2+1) \\
& = & 6(-1) + 1 -3(3) = -14. \\
\end{eqnarray*}

\textbf{Solution 2:}
Notice that
$S=\{x^2+x, x^2-x, x^2+1\}$ is a basis of $\Poly_2$, and
thus $x^2$, $x$, and $1$ can each be written as a linear 
combination of elements of $S$.

\begin{eqnarray*}
x^2 & = & \textstyle \frac{1}{2}(x^2+x) + \frac{1}{2}(x^2-x) \\
x & = & \textstyle \frac{1}{2}(x^2+x) - \frac{1}{2}(x^2-x) \\
1 & = & (x^2+1)-\textstyle \frac{1}{2}(x^2+x) - \frac{1}{2}(x^2-x).
\end{eqnarray*}
Then
\begin{eqnarray*}
T(x^2) & = & \textstyle T\tup{\frac{1}{2}(x^2+x) + \frac{1}{2}(x^2-x)}
=\frac{1}{2}T(x^2+x) + \frac{1}{2}T(x^2-x)\\
& = & \textstyle \frac{1}{2}(-1) + \frac{1}{2}(1) = 0.  \\
T(x) & = & \textstyle T\tup{\frac{1}{2}(x^2+x) - \frac{1}{2}(x^2-x)}
= \frac{1}{2}T(x^2+x) - \frac{1}{2}T(x^2-x) \\
& = & \textstyle \frac{1}{2}(-1) - \frac{1}{2}(1) = -1.\\
T(1) & = & \textstyle T\tup{(x^2+1)-\frac{1}{2}(x^2+x) -
\frac{1}{2}(x^2-x)}\\
& = & \textstyle T(x^2+1)-\frac{1}{2}T(x^2+x) - \frac{1}{2}T(x^2-x) \\
& = & \textstyle 3-\frac{1}{2}(-1) - \frac{1}{2}(1) = 3.
\end{eqnarray*}

Therefore,
\begin{eqnarray*}
T(4x^2+5x-3) & = & 4T(x^2) + 5T(x) -3T(1) \\
& = & 4(0) + 5(-1) - 3(3)=-14.
\end{eqnarray*}
The advantage of \textbf{Solution 2} over \textbf{Solution 1} is that 
if you were now asked to find $T(-6x^2-13x+9)$, it is easy to
use $T(x^2)=0$, $T(x)=-1$ and $T(1)= 3$:
\begin{eqnarray*}
T(-6x^2-13x+9) & = & -6T(x^2)-13T(x)+9T(1) \\
& = & -6(0)-13(-1)+9(3)=13+27=40.
\end{eqnarray*}
More generally, 
\begin{eqnarray*}
T(ax^2+bx+c) & = & aT(x^2)+bT(x)+cT(1) \\
& = & a(0)+b(-1)+c(3)=-b+3c.
\end{eqnarray*}
\end{solution}

Suppose two linear transformations act in the same way on $\vect{v}$ for all vectors. Then we say that these transformations are equal.

\begin{definition}{Equal transformations}{equaltransformations}
Let $S$ and $T$ be linear transformations from $V$ to $W$. Then $S = T$ if and only if for every $\vect{v} \in V$, 
\[
S \tup{\vect{v} } = T \tup{\vect{v} }
\]
\end{definition}

The definition above requires that two transformations have the same action on every vector in order for them to be equal. The next theorem argues that it is only necessary to check the action of the transformations on basis vectors.

\begin{theorem}{Transformation of a spanning set}{transformationspanningset}
Let $V$ and $W$ be vector spaces and suppose that $S$ and $T$ are linear transformations from $V$ to $W$. Then in order for $S$ and $T$ to be equal, it suffices that $S(\vect{v}_i) = T(\vect{v}_i)$ where $V=\func{span} \{\vect{v}_1, \vect{v}_2, \ldots, \vect{v}_n\}.$
\end{theorem}

This theorem tells us that a linear transformation is completely
determined by its actions on a spanning set. We can also examine the effect of a linear transformation on a basis.

\begin{theorem}{Transformation of a basis}{transformationbasis}
Suppose $V$ and $W$ are vector spaces and let $\{\vect{w}_1, \vect{w}_2, \ldots, \vect{w}_n\}$ be any given vectors in $W$ that may not be distinct. Then there exists a basis $\{\vect{v}_1, \vect{v}_2, \ldots, \vect{v}_n\}$ of $V$ and a unique linear transformation $T: V \mapsto W$ with $T (\vect{v}_i) = \vect{w}_i$.

Furthermore, if 
\[ \vect{v} = k_1\vect{v}_1+k_2\vect{v}_2+ \cdots+ k_n\vect{v}_n\]
is a vector of $V$, then
\[ T(\vect{v}) = k_1\vect{w}_1+k_2\vect{w}_2+ \cdots+ k_n\vect{w}_n.\]
\end{theorem}
