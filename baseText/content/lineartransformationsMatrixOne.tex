\section{The matrix of a linear transformation I}

\begin{outcome}
  \begin{enumerate}
  \item Find the matrix of a linear transformation with respect to the
    standard basis.
  \item Determine the action of a linear transformation on a vector in
    $\R^n$.
  \end{enumerate}
\end{outcome}

In the above examples, the action of the linear transformations was to multiply by a matrix. 
It turns out that this is always the case for linear transformations.
If $T$ is \textbf{any} linear transformation which maps $\R^{n}$ to 
$\R^{m}$, there is \textbf{always} an $m\times n$ matrix $A$ with the
property that
\begin{equation}
T\tup{\vect{x}} = A\vect{x} \label{matrix-of-transf}
\end{equation}
for all $\vect{x} \in \R^{n}$.

\begin{theorem}{Matrix of a linear transformation}{matrix-lin-transf}
Let $T:\R^{n}\mapsto \R^{m}$ be a linear transformation. Then we can find a matrix $A$ such that $T(\vect{x}) = A\vect{x}$. 
 In this case, we say that $T$ is {\em determined\em} or {\em induced\em}
by the matrix $A$.
\end{theorem}

Here is why. Suppose $T:\R^{n}\mapsto \R^{m}$ is a linear transformation and you want to find
the matrix defined by this linear transformation as described in \ref{matrix-of-transf}.
 Note that
\begin{equation*}
\vect{x} =\begin{mymatrix}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{mymatrix} = x_{1}\begin{mymatrix}{c}
1 \\
0 \\
\vdots \\
0
\end{mymatrix} + x_{2}\begin{mymatrix}{c}
0 \\
1 \\
\vdots \\
0
\end{mymatrix} +\cdots + x_{n}\begin{mymatrix}{c}
0 \\
0 \\
\vdots \\
1
\end{mymatrix} = \sum_{i=1}^{n}x_{i}\vect{e}_{i}
\end{equation*}
where $\vect{e}_{i}$ is the $i^{th}$ column of $I_n$, that is the $n \times
1$ vector which has zeros in every slot but the $i^{th}$ and a 1 in
this slot.

Then since $T$ is linear,
\begin{eqnarray*}
T\tup{\vect{x} }&=&\sum_{i=1}^{n}x_{i}T\tup{\vect{e}_{i}} \\
&=&\begin{mymatrix}{ccc}
| &  & | \\
T\tup{\vect{e}_{1}} & \cdots & T\tup{\vect{e}_{n}} \\
| &  & |
\end{mymatrix} \begin{mymatrix}{c}
x_{1} \\
\vdots \\
x_{n}
\end{mymatrix} \\
&=& A\begin{mymatrix}{c}
x_{1} \\
\vdots \\
x_{n}
\end{mymatrix}
\end{eqnarray*}
The desired matrix is obtained from constructing the $i^{th}$
column as $T\tup{\vect{e}_{i}} $. Recall that the set $\set{\vect{e}_1, \vect{e}_2, \cdots, \vect{e}_n }$ is called the standard basis of $\R^n$. Therefore the matrix of $T$ is found by applying $T$ to the standard basis. We state this formally as the
following theorem.

\begin{theorem}{Matrix of a linear transformation}{matrix-of-linear-transformation}
Let $T: \R^{n} \mapsto \R^{m}$ be a linear transformation. Then the matrix $A$ satisfying $T\tup{\vect{x}}=A\vect{x}$\index{linear transformation!matrix} is given by
\begin{equation*}
A=
\begin{mymatrix}{ccc}
| &  & | \\
T\tup{\vect{e}_{1}} & \cdots & T\tup{\vect{e}_{n}} \\
| &  & |
\end{mymatrix}
\end{equation*}
where $\vect{e}_{i}$ is the $i^{th}$ column of $I_n$, and then $T\tup{\vect{e}_{i}
}$ is the $i^{th}$ column of $A$.
\end{theorem}

The following Corollary is an essential result.

\begin{corollary}{Matrix and linear transformation}{matrix-lin-transf-equivalence}
A transformation $T:\R^n\rightarrow \R^m$ is a linear transformation if and only if it is a matrix transformation. 
\end{corollary}

Consider the following example.

\begin{example}{The matrix of a linear transformation}{matrix-of-linear-transformation}
Suppose $T$ is a linear transformation, $T:\R^{3}\rightarrow \R^{2}$ where 
\begin{equation*}
T\begin{mymatrix}{r}
1 \\
0 \\
0
\end{mymatrix} =\begin{mymatrix}{r}
1 \\
2
\end{mymatrix} ,\ T\begin{mymatrix}{r}
0 \\
1 \\
0
\end{mymatrix} =\begin{mymatrix}{r}
9 \\
-3
\end{mymatrix} ,\ T\begin{mymatrix}{r}
0 \\
0 \\
1
\end{mymatrix} =\begin{mymatrix}{r}
1 \\
1
\end{mymatrix}
\end{equation*}
Find the matrix $A$ of $T$ such that $T \tup{\vect{x} }=A\vect{x}$  for all $\vect{x}$.
\end{example}

\begin{solution} By Theorem \ref{thm:matrix-of-linear-transformation} we construct $A$ as follows:
\begin{equation*}
A = 
\begin{mymatrix}{ccc}
| &  & | \\
T\tup{\vect{e}_{1}} & \cdots & T\tup{\vect{e}_{n}} \\
| &  & |
\end{mymatrix}
\end{equation*}

In this case, $A$ will be a $2 \times 3$ matrix, so we need to find $T
\tup{\vect{e}_1 }, T \tup{\vect{e}_2 }$, and $T \tup{\vect{e}_3
}$. Luckily, we have been given these values so we can fill in
$A$ as needed, using these vectors as the columns of $A$.  Hence,
\begin{equation*}
A=\begin{mymatrix}{rrr}
1 & 9 & 1 \\
2 & -3 & 1
\end{mymatrix}
\end{equation*}
\end{solution}

In this example, we were given the resulting vectors of $T \tup{\vect{e}_1 }, 
T \tup{\vect{e}_2 }$, and $T \tup{\vect{e}_3 }$. Constructing the matrix $A$ was simple, as we
could simply use these vectors as the columns of $A$. The next example shows how to find $A$ when we are not given the $T \tup{\vect{e}_i }$ so clearly. 

\begin{example}{The matrix of linear transformation: inconveniently \\ defined}{2x2-inconvenient-matrix-of-lin-transf}
Suppose $T$ is a linear transformation, $T:\R^{2}\rightarrow \R^{2}$ and
\begin{equation*}
T\begin{mymatrix}{r}
1 \\
1
\end{mymatrix} =\begin{mymatrix}{r}
1 \\
2
\end{mymatrix} ,\ T\begin{mymatrix}{r}
0 \\
-1 
\end{mymatrix} =\begin{mymatrix}{r}
3 \\
2
\end{mymatrix}
\end{equation*}
Find the matrix $A$ of $T$ such that $T \tup{\vect{x} }=A\vect{x}$  for all $\vect{x}$.
\end{example}

\begin{solution} By Theorem \ref{thm:matrix-of-linear-transformation} to find this matrix, we need to determine the action of $T$ on
$\vect{e}_{1}$ and $\vect{e}_{2}$. In Example \ref{exa:matrix-of-linear-transformation}, we were given these resulting vectors.
However, in this example, we have been given $T$ of two different vectors. How can we find out the action
of $T$ on $\vect{e}_{1}$ and $\vect{e}_{2}$? In particular for $\vect{e}_{1}$, suppose there exist $x$ and $y$ such that
\begin{equation}
\begin{mymatrix}{r}
1 \\
0
\end{mymatrix} = x\begin{mymatrix}{r}
1\\
1
\end{mymatrix} +y\begin{mymatrix}{r}
0 \\
-1 
\end{mymatrix} 
\label{matrix-values}
\end{equation}

Then, since $T$ is linear,
\begin{equation*}
T\begin{mymatrix}{r}
1 \\
0 
\end{mymatrix}  = x T\begin{mymatrix}{r}
1 \\
1
\end{mymatrix} +y T\begin{mymatrix}{r}
0 \\
-1 
\end{mymatrix}
\end{equation*}

Substituting in values, this sum becomes
\begin{equation}
T\begin{mymatrix}{r}
1 \\
0 
\end{mymatrix} = 
 x\begin{mymatrix}{r}
1 \\
2
\end{mymatrix} +y\begin{mymatrix}{r}
3 \\
2
\end{mymatrix} 
\label{matrix-values2}
\end{equation}

Therefore, if we know the values of $x$ and $y$ which satisfy \ref{matrix-values}, we can substitute these into equation \ref{matrix-values2}. By doing so,
we find $T\tup{\vect{e}_1}$ which is the first column of the matrix $A$. 

We proceed to find $x$ and $y$. We do so by solving \ref{matrix-values}, which can be done by solving the system
\begin{equation*}
\begin{array}{c}
x = 1 \\
x - y = 0
\end{array}
\end{equation*}

We see that $x=1$ and $y=1$ is the solution to this system. 
Substituting these values into equation \ref{matrix-values2}, we have 
\begin{equation*}
T\begin{mymatrix}{r}
1 \\
0 
\end{mymatrix} = 
 1 \begin{mymatrix}{r}
1 \\
2
\end{mymatrix} + 1 \begin{mymatrix}{r}
3 \\
2
\end{mymatrix} 
= 
 \begin{mymatrix}{r}
1 \\
2
\end{mymatrix} + \begin{mymatrix}{r}
3 \\
2
\end{mymatrix}
=
\begin{mymatrix}{r}
4 \\
4
\end{mymatrix}
\end{equation*}

Therefore $\begin{mymatrix}{r}
4 \\
4
\end{mymatrix}$
is the first column of $A$. 

Computing the second column is done in the same way, and is left as an exercise.

The resulting matrix $A$ is given by 
\begin{equation*}
A
=
\begin{mymatrix}{rr}
4 & -3 \\
4 & -2
\end{mymatrix}
\end{equation*}
\end{solution}

This example illustrates a very long procedure for finding the matrix of $A$. While this method is reliable and
will always result in the correct matrix $A$, the following procedure provides an alternative method. 

\begin{procedure}{Finding the matrix of inconveniently defined linear transformation}{finding-matrix-of-linear-transformation}
Suppose $T:\R^{n}\rightarrow \R^{m}$ is a linear transformation. Suppose there exist vectors $\set{\vect{a}_{1},\cdots ,\vect{a}_{n}} $ in $\R^{n}$ such that $\begin{mymatrix}{ccc}
\vect{a}_{1} & \cdots & \vect{a}_{n}
\end{mymatrix} ^{-1}$ exists, and 
\begin{equation*}
T \tup{\vect{a}_{i}}=\vect{b}_{i}
\end{equation*}
Then the matrix of $T$ must be of the form
\begin{equation*}
\begin{mymatrix}{ccc}
\vect{b}_{1} & \cdots & \vect{b}_{n}
\end{mymatrix} \begin{mymatrix}{ccc}
\vect{a}_{1} & \cdots & \vect{a}_{n}
\end{mymatrix} ^{-1}
\end{equation*}
\end{procedure}

We will illustrate this procedure in the following example. You may also find it useful
to work through Example \ref{exa:2x2-inconvenient-matrix-of-lin-transf} using this procedure.

\begin{example}{Matrix of a linear transformation \\ given inconveniently}{inconvenient-matrix-lin-transf}
Suppose $T:\R^{3}\rightarrow \R^{3}$ is a linear
transformation and
\begin{equation*}
T\begin{mymatrix}{r}
1 \\
3 \\
1
\end{mymatrix} =\begin{mymatrix}{r}
0 \\
1 \\
1
\end{mymatrix} ,T\begin{mymatrix}{r}
0 \\
1 \\
1
\end{mymatrix} =\begin{mymatrix}{r}
2 \\
1 \\
3
\end{mymatrix} ,T\begin{mymatrix}{r}
1 \\
1 \\
0
\end{mymatrix} =\begin{mymatrix}{r}
0 \\
0 \\
1
\end{mymatrix}
\end{equation*}
Find the matrix of this linear transformation.
\end{example}

\begin{solution}
By Procedure \ref{proc:finding-matrix-of-linear-transformation}, 
$A=  \begin{mymatrix}{rrr}
1 & 0 & 1 \\
3 & 1 & 1 \\
1 & 1 & 0
\end{mymatrix} ^{-1}$ and 
 $B=\begin{mymatrix}{rrr}
0 & 2 & 0 \\
1 & 1 & 0 \\
1 & 3 & 1
\end{mymatrix}$

Then, Procedure \ref{proc:finding-matrix-of-linear-transformation} claims that the matrix of $T$ is 
\begin{equation*}
C= BA^{-1} 
=\begin{mymatrix}{rrr}
2 & -2 & 4 \\
0 & 0 & 1 \\
4 & -3 & 6
\end{mymatrix}
\end{equation*}

Indeed you can first verify that $T(\vect{x})=C\vect{x}$ for the 3 vectors above:

\begin{equation*}
 \begin{mymatrix}{ccc}
2 & -2 & 4 \\
0 & 0 & 1 \\
4 & -3 & 6
\end{mymatrix} \begin{mymatrix}{c}
1 \\
3 \\
1
\end{mymatrix} =\begin{mymatrix}{c}
0 \\
1 \\
1
\end{mymatrix} ,\ \begin{mymatrix}{ccc}
2 & -2 & 4 \\
0 & 0 & 1 \\
4 & -3 & 6
\end{mymatrix} \begin{mymatrix}{c}
0 \\
1 \\
1
\end{mymatrix} =\begin{mymatrix}{c}
2 \\
1 \\
3
\end{mymatrix}
\end{equation*}
\begin{equation*}
\begin{mymatrix}{ccc}
2 & -2 & 4 \\
0 & 0 & 1 \\
4 & -3 & 6
\end{mymatrix} \begin{mymatrix}{c}
1 \\
1 \\
0
\end{mymatrix} =\begin{mymatrix}{c}
0 \\
0 \\
1
\end{mymatrix}
\end{equation*}

But more generally $T(\vect{x})= C\vect{x}$ for any $\vect{x}$. To see this, let $\vect{y}=A^{-1}\vect{x}$ and then using linearity of $T$:
\[ T(\vect{x})= T(A\vect{y}) = T \tup{\sum_i \vect{y}_i\vect{a}_i } = \sum \vect{y}_i T(\vect{a}_i) \sum \vect{y}_i \vect{b}_i = B\vect{y} = BA^{-1}\vect{x} = C\vect{x}\]
\end{solution}

Recall the dot product discussed earlier. Consider the map $\vect{v}$\textbf{$\mapsto $}
$\func{proj}_{\vect{u}}\tup{\vect{v}} $ which takes a vector a transforms it to its projection onto a given vector $\vect{u}$. It turns out that
this map is linear, a result which follows from the properties of the
dot product. This is shown as follows.
\begin{eqnarray*}
\func{proj}_{\vect{u}}\tup{k \vect{v}+ p \vect{w}}
&=&\tup{\vspace{0.05in}\frac{(k \vect{v}+ p \vect{w})\dotprod \vect{u}}{
\vect{u}\dotprod \vect{u}}} \vect{u} \\
&=& k  \tup{\vspace{0.05in}\frac{
\vect{v}\dotprod \vect{u}}{\vect{u}\dotprod \vect{u}}} \vect{u}+p \tup{\vspace{
0.05in}\frac{\vect{w}\dotprod \vect{u}}{\vect{u}\dotprod \vect{u}}} \vect{u} \\
&=& k \; \func{proj}_{\vect{u}}\tup{\vect{v}} +p \; \func{proj}
_{\vect{u}}\tup{\vect{w}} 
\end{eqnarray*}

Consider the following example.

\begin{example}{Matrix of a projection map}{projection-matrix}
Let $\vect{u} = \begin{mymatrix}{r}
1 \\
2 \\
3
\end{mymatrix}$ and let $T$ be the projection map $T: \R^3 \mapsto \R^3$ defined by 
\[
T(\vect{v}) = \func{proj}_{\vect{u}}\tup{\vect{v}}
\]
for any $\vect{v} \in \R^3$.  
\begin{enumerate}
\item Does this transformation come from
multiplication by a matrix?
\item If so, what is the matrix?
\end{enumerate}
\end{example}

\begin{solution}
\begin{enumerate}
\item
First, we have just seen that $T (\vect{v}) = \func{proj}_{\vect{u}}\tup{\vect{v}}$ is linear. Therefore by Theorem \ref{thm:matrix-lin-transf}, we can find a matrix $A$ such that $T(\vect{x}) = A\vect{x}$. 

\item
The columns of the matrix for $T$ are defined above as $T(\vect{e}_{i})$. 
It follows that $T(\vect{e}_{i}) = \func{proj}
_{\vect{u}}\tup{\vect{e}_{i}} $ gives the $i^{th}$ column of the
desired matrix. Therefore, we need to find
\begin{equation*}
\func{proj}_{\vect{u}}\tup{\vect{e}_{i}} = \tup{\vspace{0.05in}
\frac{\vect{e}_{i}\dotprod \vect{u}}{\vect{u}\dotprod \vect{u}}}
\vect{u}
\end{equation*}
For the given vector $\vect{u}$ , this implies the columns of the desired
matrix are
\begin{equation*}
\vspace{0.05in}\frac{1}{14}\begin{mymatrix}{r}
1 \\
2 \\
3
\end{mymatrix} ,\vspace{0.05in}\frac{2}{14}\begin{mymatrix}{r}
1 \\
2 \\
3
\end{mymatrix} ,\vspace{0.05in}\frac{3}{14}\begin{mymatrix}{r}
1 \\
2 \\
3
\end{mymatrix} 
\end{equation*}
which you can verify.
Hence the matrix of $T$ is
\begin{equation*}
\vspace{0.05in}\frac{1}{14}\begin{mymatrix}{rrr}
1 & 2 & 3 \\
2 & 4 & 6 \\
3 & 6 & 9
\end{mymatrix} 
\end{equation*}
\end{enumerate}
\end{solution}
