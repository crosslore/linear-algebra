\subsection{Multiplication of matrices}

The next important matrix operation we will explore is multiplication
of matrices. The
operation of matrix multiplication is one of the most important and
useful of the matrix operations.  Throughout this section, we will
also demonstrate how matrix multiplication relates to linear systems
of equations.

First, we provide a formal definition of row and column vectors. 

\begin{definition}{Row and column vectors}{rowandcolumnvectors}
Matrices of size $n\times 1$ or $1\times n$ are called \textbf{vectors}\index{vectors}. If $X$ is such a matrix, then we write $x_{i}$ to 
denote the entry of $X$ in the $i^{th}$ row of a column matrix, or the $i^{th}$ column of a row matrix\index{vectors!column}. 


The $n\times 1$ matrix
\begin{equation*}
X=\begin{mymatrix}{c}
x_{1} \\
\vdots \\
x_{n}
\end{mymatrix}
\end{equation*}
is called
a \textbf{column vector}\index{vectors!row vector}.
The $1\times n$ matrix
\begin{equation*}
X = \begin{mymatrix}{ccc}
x_{1} & \cdots & x_{n}
\end{mymatrix}
\end{equation*}
is called a \textbf{row vector}.
\end{definition}

We may simply use the term \textbf{vector} throughout this text to refer to either a column or row vector. 
If we do so, the context will make it clear which we are referring to.

In this chapter, we will again use the notion of linear combination of
vectors as in  Definition \ref{def:linearcombination}.  In this context, a linear combination is a sum
consisting of vectors multiplied by scalars.  For example,
\begin{equation*}
\begin{mymatrix}{r}
50 \\
122
\end{mymatrix}
=
7\begin{mymatrix}{r}
1 \\
4
\end{mymatrix} +8\begin{mymatrix}{r}
2 \\
5
\end{mymatrix} +9\begin{mymatrix}{r}
3 \\
6
\end{mymatrix}
\end{equation*}
is a linear combination of three vectors. 

It turns out that we can express any system of linear equations as a linear combination of vectors. In fact,
the vectors that we will use are just the columns of the corresponding augmented matrix! 

\begin{definition}{The vector form of a system of linear equations}{vectorform}
Suppose we have a system of equations given by
\begin{equation*}
\begin{array}{c}
a_{11}x_{1}+\cdots +a_{1n}x_{n}=b_{1} \\
\vdots \\
a_{m1}x_{1}+\cdots +a_{mn}x_{n}=b_{m}
\end{array}
\end{equation*}
We can express this system in \textbf{vector form}\index{system of equations!vector form} which is as follows:
\begin{equation*}
x_1
\begin{mymatrix}{c}
a_{11}\\
a_{21}\\
\vdots \\
a_{m1}
\end{mymatrix}
+
x_2
\begin{mymatrix}{c}
a_{12}\\
a_{22}\\
\vdots \\
a_{m2}
\end{mymatrix}
+
\cdots
+
x_n
\begin{mymatrix}{c}
a_{1n}\\
a_{2n}\\
\vdots \\
a_{mn}
\end{mymatrix}
=
\begin{mymatrix}{c}
b_1\\
b_2\\
\vdots \\
b_m
\end{mymatrix}
\end{equation*}
\end{definition}

Notice that each vector used here is one column from the corresponding augmented  matrix. There is one vector for each variable in the system,
along with the constant vector. 

The first important form of matrix multiplication is multiplying a matrix by a vector. 
Consider the product given by
\begin{equation*}
\begin{mymatrix}{rrr}
1 & 2 & 3 \\
4 & 5 & 6
\end{mymatrix} \begin{mymatrix}{r}
7 \\
8 \\
9
\end{mymatrix}
\end{equation*}
We will soon see that this equals
\begin{equation*}
7\begin{mymatrix}{c}
1 \\
4
\end{mymatrix} +8\begin{mymatrix}{c}
2 \\
5
\end{mymatrix} +9\begin{mymatrix}{c}
3 \\
6
\end{mymatrix} =\begin{mymatrix}{c}
50 \\
122
\end{mymatrix}
\end{equation*}

In general terms,
\begin{eqnarray*}
\begin{mymatrix}{ccc}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23}
\end{mymatrix} \begin{mymatrix}{c}
x_{1} \\
x_{2} \\
x_{3}
\end{mymatrix} &=&\allowbreak x_{1}\begin{mymatrix}{c}
a_{11} \\
a_{21}
\end{mymatrix} +x_{2}\begin{mymatrix}{c}
a_{12} \\
a_{22}
\end{mymatrix} +x_{3}\begin{mymatrix}{c}
a_{13} \\
a_{23}
\end{mymatrix} \\
&=&\begin{mymatrix}{c}
a_{11}x_{1}+a_{12}x_{2}+a_{13}x_{3} \\
a_{21}x_{1}+a_{22}x_{2}+a_{23}x_{3}
\end{mymatrix} 
\end{eqnarray*}
Thus you take $x_{1}$ times the first column, add to $x_{2}$ times the
second column, and finally $x_{3}$ times the third column. The above sum is a linear combination of the columns of the matrix.
When you multiply a matrix on the left by a vector on the right,
the numbers making up the vector are just the scalars to be used in the
linear combination of the columns as illustrated above.

Here is the formal definition of how to multiply an $m\times
n $ matrix by an $ n\times 1 $ column vector.

\begin{definition}{Multiplication of vector by matrix}{multiplicationvectormatrix}
Let $A=\mat{a_{ij} }$ be an $m\times n$ matrix and let $X$
be an $n\times 1$ matrix given by 
\begin{equation*}
A=\mat{A_{1} \cdots A_{n}},  X = \begin{mymatrix}{r}
x_{1} \\
\vdots \\
x_{n}
\end{mymatrix} 
\end{equation*}

Then the product $AX$ is the $m\times 1$ column
vector\index{matrix multiplication!vectors}
which equals the following
linear combination of the columns of $A$:
\begin{equation*}
x_{1}A_{1}+x_{2}A_{2}+\cdots +x_{n}A_{n} = 
\sum_{j=1}^{n}x_{j}A_{j}  
\end{equation*}
\end{definition}

If we write the columns of $A$ in terms of their entries, they are of the form
\begin{equation*}
A_{j}  =
\begin{mymatrix}{c}
a_{1j} \\
a_{2j} \\
\vdots \\
a_{mj}
\end{mymatrix} 
\end{equation*}
Then, we can write the product $AX$ as
\begin{equation*}
AX = 
x_{1}\begin{mymatrix}{c}
a_{11} \\
a_{21} \\
\vdots \\
a_{m1}
\end{mymatrix} + x_{2}\begin{mymatrix}{c}
a_{12} \\
a_{22} \\
\vdots \\
a_{m2}
\end{mymatrix} +\cdots + x_{n}\begin{mymatrix}{c}
a_{1n} \\
a_{2n} \\
\vdots \\
a_{mn}
\end{mymatrix} 
\end{equation*}

Note that multiplication of an $m \times n$ matrix and an $n \times 1$ vector produces an $m \times 1$ vector.

Here is an example.

\begin{example}{A vector multiplied by a matrix}{vectormultbymatrix}
Compute the product $AX$ for 
\begin{equation*}
A = \begin{mymatrix}{rrrr}
1 & 2 & 1 & 3 \\
0 & 2 & 1 & -2 \\
2 & 1 & 4 & 1
\end{mymatrix}, X =  \begin{mymatrix}{r}
1 \\
2 \\
0 \\
1
\end{mymatrix} 
\end{equation*}
\end{example}

\begin{solution} We will use Definition \ref{def:multiplicationvectormatrix} to compute the product.
Therefore, we compute the product $AX$ as follows. 
\begin{eqnarray*}
& 1\begin{mymatrix}{r}
1 \\
0 \\
2
\end{mymatrix} + 2\begin{mymatrix}{r}
2 \\
2 \\
1
\end{mymatrix} + 0\begin{mymatrix}{r}
1 \\
1 \\
4
\end{mymatrix} + 1 \begin{mymatrix}{r}
3 \\
-2\\
1
\end{mymatrix} \\ 
&=
\begin{mymatrix}{r}
1 \\
0 \\
2
\end{mymatrix} + \begin{mymatrix}{r}
4 \\
4 \\
2
\end{mymatrix} + \begin{mymatrix}{r}
0 \\
0 \\
0
\end{mymatrix} +  \begin{mymatrix}{r}
3 \\
-2\\
1
\end{mymatrix} \\
&=
\begin{mymatrix}{r}
8 \\
2 \\
5
\end{mymatrix}
\end{eqnarray*}
\end{solution}

Using the above operation, we can also write a system of linear equations in \textbf{matrix form}. In this form, 
we express the system as a matrix multiplied by a vector. Consider the following definition.

\begin{definition}{The matrix form of a system of linear equations}{matrixform}
Suppose we have a system of equations given by
\begin{equation*}
\begin{array}{c}
a_{11}x_{1}+\cdots +a_{1n}x_{n}=b_{1} \\
a_{21}x_{1}+ \cdots + a_{2n}x_{n} = b_{2} \\
\vdots \\
a_{m1}x_{1}+\cdots +a_{mn}x_{n}=b_{m}
\end{array}
\end{equation*}
Then we can express this system in \textbf{matrix form}\index{system of equations!matrix form} as follows.
\begin{equation*}
\begin{mymatrix}{cccc}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{mymatrix}
\begin{mymatrix}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{mymatrix}
=
\begin{mymatrix}{c}
b_{1}\\
b_{2}\\
\vdots \\
b_{m}
\end{mymatrix}
\end{equation*}
 
\end{definition}

The expression $AX=B$ is also known as the \textbf{Matrix Form}\index{matrix form AX=B} of the
corresponding system of linear equations. The
matrix $A$ is simply the coefficient matrix of the system, the vector
$X$ is the column vector constructed from the variables of the system,
and finally the vector $B$ is the column vector constructed from the constants
of the system.  It is important to note that any system of linear
equations can be written in this form.

Notice that if we write a homogeneous system of equations in matrix form, it would have the form
$AX=0$, for the zero vector $0$.

You can see from this definition that a vector 
\begin{equation*}
X =
\begin{mymatrix}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{mymatrix}
\end{equation*}
will satisfy the equation $AX=B$
only when the entries $x_{1}, x_{2}, \cdots, x_{n}$ of the vector $X$ are solutions to the original system.

Now that we have examined how to multiply a matrix by a vector, we
wish to consider the case where we multiply two matrices of more
general sizes, although these sizes still need to be appropriate as we
will see. For example, in Example \ref{exa:vectormultbymatrix}, we
multiplied a $3 \times 4$ matrix by a $4 \times 1$ vector.  We want to
investigate how to multiply other sizes of matrices.

We have not yet given any conditions on when matrix multiplication is
possible!  For matrices $A$ and $B$, in order to form the product
$AB$, the number of columns of $A$ must equal the number of rows of
$B.$ Consider a product $AB$ where $A$ has size $m\times n$ and $B$
has size $n \times p$. Then, the product in terms of size of matrices
is given by
\begin{equation*}
(m\times\overset{\text{these must match!}}{\widehat{n)\;(n}\times p})=m\times p
\end{equation*}

Note the two outside numbers give the size of the product. One of the most important rules regarding matrix multiplication is the following. 
If the two middle numbers don't match, you can't multiply the
matrices!

When the number of columns of $A$ equals the number of rows
of $B$ the two matrices are said to be
\textbf{conformable}\index{matrix!conformable} and the product
$AB$\index{matrix multiplication}  is obtained as follows.

\begin{definition}{Multiplication of two matrices}{multiplicationoftwomatrices}
 Let $A$ be an $m\times n$ matrix
and let $B$ be an $n\times p$ matrix of the form
\begin{equation*}
B=\mat{B_{1} \cdots  B_{p}}
\end{equation*}
where $B_{1},...,B_{p}$ are the $n\times 1$ columns of $B$. Then the 
$m\times p$ matrix $AB$ is defined as follows:
\begin{equation*}
AB = A \mat{B_{1} \cdots  B_{p}} =  \mat{(A B)_{1} \cdots  (AB)_{p}} 
\end{equation*}
where $(AB)_{k}$ is an $m\times 1$ matrix or column vector which
gives the $k^{th}$ column of $AB$. 
\end{definition}

Consider the following example.

\begin{example}{Multiplying two matrices}{multiplicationoftwomatrices}
Find $AB$ if possible.
\begin{equation*}
A = \begin{mymatrix}{rrr}
1 & 2 & 1 \\
0 & 2 & 1
\end{mymatrix}, B = \begin{mymatrix}{rrr}
1 & 2 & 0 \\
0 & 3 & 1 \\
-2 & 1 & 1
\end{mymatrix}
\end{equation*}
\end{example}

\begin{solution} The first thing you need to verify when calculating a
product is whether the multiplication is possible.  The first matrix
has size $2\times 3$ and the second matrix has size $3\times 3$. The
inside numbers are equal, so $A$ and $B$ are conformable matrices.
According to the above discussion $AB$ will be a $2\times 3$ matrix.
Definition \ref{def:multiplicationoftwomatrices} gives us a way to
calculate each column of $AB$, as follows.
\begin{equation*}
\mat{\overset{
\text{First column}}{\overbrace{\begin{mymatrix}{rrr}
1 & 2 & 1 \\
0 & 2 & 1
\end{mymatrix} \begin{mymatrix}{r}
1 \\
0 \\
-2
\end{mymatrix} }},\overset{\text{Second column}}{\overbrace{\begin{mymatrix}{rrr}
1 & 2 & 1 \\
0 & 2 & 1
\end{mymatrix} \begin{mymatrix}{r}
2 \\
3 \\
1
\end{mymatrix} }},\overset{\text{Third column}}{\overbrace{\begin{mymatrix}{rrr}
1 & 2 & 1 \\
0 & 2 & 1
\end{mymatrix} \begin{mymatrix}{r}
0 \\
1 \\
1
\end{mymatrix} }}}
\end{equation*}
You know how to multiply a matrix times a vector, using Definition \ref{def:multiplicationvectormatrix} for 
each of the three columns. Thus
\begin{equation*}
\begin{mymatrix}{rrr}
1 & 2 & 1 \\
0 & 2 & 1
\end{mymatrix} \begin{mymatrix}{rrr}
1 & 2 & 0 \\
0 & 3 & 1 \\
-2 & 1 & 1
\end{mymatrix} =\allowbreak \begin{mymatrix}{rrr}
-1 & 9 & 3 \\
-2 & 7 & 3
\end{mymatrix} 
\end{equation*}
\end{solution}

Since vectors are simply $ n \times 1$ or $1 \times m$
matrices, we can also multiply a vector by another vector. 

\begin{example}{Vector times vector multiplication}{vectormultiplication}
Multiply if possible $\begin{mymatrix}{r}
1 \\
2 \\
1
\end{mymatrix} \begin{mymatrix}{rrrr}
1 & 2 & 1 & 0
\end{mymatrix} .$
\end{example}

\begin{solution} In this case we are multiplying a matrix of size $3 \times 1$ by a matrix of size $1 \times
4.$ The inside numbers match so the product is defined. Note that the product will be a matrix of size $3 \times 4$. 
Using Definition \ref{def:multiplicationoftwomatrices}, we can compute this product as follows $\:$
\begin{equation*}
\begin{mymatrix}{r}
1 \\
2 \\
1
\end{mymatrix} \begin{mymatrix}{rrrr}
1 & 2 & 1 & 0
\end{mymatrix} = 
\mat{\overset{
\text{First column}}{\overbrace{\begin{mymatrix}{r}
1 \\
2 \\
1
\end{mymatrix} \begin{mymatrix}{r}
1
\end{mymatrix} }},\overset{\text{Second column}}{\overbrace{\begin{mymatrix}{r}
1 \\
2\\
1
\end{mymatrix} \begin{mymatrix}{r}
2 
\end{mymatrix} }},\overset{\text{Third column}}{\overbrace{\begin{mymatrix}{r}
1 \\
2 \\
1
\end{mymatrix} \begin{mymatrix}{r}
1
\end{mymatrix} }}, \overset {\text{Fourth column}}{\overbrace{\begin{mymatrix}{r}
1\\
2\\
1
\end{mymatrix} \begin{mymatrix}{r}
0
\end{mymatrix}}}
}
\end{equation*}

You can use Definition \ref{def:multiplicationvectormatrix} to verify that this product is
\begin{equation*}
\begin{mymatrix}{cccc}
1 & 2 & 1 & 0 \\
2 & 4 & 2 & 0 \\
1 & 2 & 1 & 0
\end{mymatrix}
\end{equation*}
\end{solution}

\begin{example}{A multiplication which is not defined}{undefinedmatrixmultiplication}
Find $BA$ if possible.
\begin{equation*}
B = \begin{mymatrix}{ccc}
1 & 2 & 0 \\
0 & 3 & 1 \\
-2 & 1 & 1
\end{mymatrix},  A = \begin{mymatrix}{ccc}
1 & 2 & 1 \\
0 & 2 & 1
\end{mymatrix}
\end{equation*}
\end{example}

\begin{solution} First check if it is possible. This product is of the form $\left( 3\times 3\right)
\left( 2\times 3\right) .$ The inside numbers do not match and so you can't
do this multiplication. 
\end{solution}

In this case, we say that the multiplication is not defined. 
Notice that these are the same matrices which we used in Example \ref{exa:multiplicationoftwomatrices}.
In this example, we tried to calculate $BA$ instead of $AB$. This demonstrates another property 
of matrix multiplication. While the product $AB$ maybe be defined, we cannot assume that
the product $BA$ will be possible. Therefore, it is important to always check that the product is defined
before carrying out any calculations.

Earlier, we defined the zero matrix $0$ to be the matrix (of
appropriate size) containing zeros in all entries.  Consider the
following example for multiplication by the zero matrix.

\begin{example}{Multiplication by the zero matrix}{multbyzeromatrix}
Compute the product $A0$ for the matrix
\begin{equation*}
A=
\begin{mymatrix}{rr}
1 & 2 \\
3 & 4
\end{mymatrix}
\end{equation*}
and the $2 \times 2$ zero matrix given by
\begin{equation*}
0=
\begin{mymatrix}{rr}
0 & 0 \\
0 & 0
\end{mymatrix}
\end{equation*}
\end{example}

\begin{solution} 
In this product, we compute
\begin{equation*}
\begin{mymatrix}{rr}
1 & 2 \\
3 & 4
\end{mymatrix}
\begin{mymatrix}{rr}
0 & 0 \\
0 & 0
\end{mymatrix}
=
\begin{mymatrix}{rr}
0 & 0 \\
0 & 0
\end{mymatrix}
\end{equation*}

Hence, $A0=0$. 
\end{solution}

Notice that we could also multiply $A$ by the $2 \times 1 $ zero vector given by $\begin{mymatrix}{r}
0 \\
0
\end{mymatrix}$.
The result would be the $2 \times 1$ zero vector. 
Therefore, it is always the case that $A0=0$, for an appropriately sized zero matrix or vector. 
