\subsection{More properties of inverses}

% ======================================================================

In this section, we will use elementary matrices to prove a useful
theorem about the inverse of a square matrix. We start with an
observation about the {\ef} of a right invertible matrix.

\begin{lemma}{{\Ef} of a right invertible matrix}{no-zero-row}
  Suppose that $A$ is right invertible. Then the {\rref} of $A$ does
  not have a row of zeros.
\end{lemma}

\begin{proof}
  Let $R$ be the {\rref} of $A$. Then by Theorem~\ref{thm:form-rua},
  we can write $R=UA$ for some invertible square matrix $U$. By
  assumption, we have $AB=I$, and therefore
  \begin{equation*}
    R(BU^{-1})
    ~=~
    (UA)(BU^{-1})
    ~=~
    U(AB)U^{-1}
    ~=~
    UIU^{-1}
    ~=~
    UU^{-1}
    ~=~
    I.
  \end{equation*}
  If $R$ had a row of zeros, then so would the product
  $R(BU^{-1})$. But since the identity matrix $I$ does not have a row
  of zeros, neither does $R$.
\end{proof}

\begin{theorem}{Right invertible square matrices are invertible}{right-square-left}
  Suppose $A$ and $B$ are square matrices such that $AB=I$. Then it
  follows that $BA=I$, and therefore $B=A^{-1}$. In particular, a
  square matrix is right invertible if and only if it is left
  invertible if and only if it is invertible.
\end{theorem}

\begin{proof}
  Assume $A$ and $B$ are square matrices such that $AB=I$. Let $R$ be
  the {\rref} of $A$. Then by Theorem~\ref{thm:form-rua}, we can write
  $R=UA$ where $U$ is an invertible matrix. Since $AB=I$, we know by
  Lemma~\ref{lem:no-zero-row} that $R$ does not have a row of
  zeros. Since $R$ is a square {\rref} with no row of zeros, each
  column must be a pivot column, and it follows that $R=I$. Hence,
  $UA=I$, and therefore $A$ is left invertible. Moreover, we have
  \begin{equation*}
    B ~=~ IB ~=~ (UA)B ~=~ U(AB) ~=~ UI ~=~ U,
  \end{equation*}
  and therefore $B=U$. It follows that $BA=UA=I$, as claimed.

  To prove the last claim, note that we just proved that for square
  matrices, $AB=I$ implies $BA=I$. Therefore, every right inverse of
  $A$ is also a left inverse, and therefore an inverse. But of course,
  we also have that $BA=I$ implies $AB=I$. This is just the same
  theorem, with the roles of $A$ and $B$ interchanged. Therefore,
  every left inverse of $A$ is also a right inverse.
\end{proof}

This theorem is very useful, because it allows us to test only one of
the products $AB$ or $BA$ in order to check that $B$ is the inverse of
$A$, saving us half of the work. It is important to stress, however,
that this only works for {\em square} matrices. As we saw in
Example~\ref{exa:right-inverse}, non-square matrices can be right
invertible without being left invertible, or vice versa.

