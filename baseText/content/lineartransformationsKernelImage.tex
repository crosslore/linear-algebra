\section{The kernel and image of a linear map}

\begin{outcome}
  \begin{enumerate}
  \item Describe the kernel and image of a linear transformation, and
    find a basis for each.
  \end{enumerate}
\end{outcome}

In this section we will consider the case where the linear transformation is not necessarily an
isomorphism. First consider the following important definition.

\begin{definition}{Kernel and image}{kernel-image}
Let $V$ and $W$ be subspaces of $\R^n$ and let $T:V\mapsto W$ be a linear transformation. Then the image of $T$
denoted as $\func{im}\tup{T} $ is defined to be the set 
\index{linear map!image}
\index{linear map!kernel} 
\begin{equation*}
\func{im}\tup{T} = \set{T (\vect{v}):\vect{v}\in V}
\end{equation*}
In words, it consists of all vectors in $W$ which equal $T(\vect{v})$ for some $
\vect{v}\in V$.

The kernel of $T$, written $\ker \tup{T}$, consists of all $\vect{v}\in V$ such that $T(\vect{v})=\vect{0}$. That is, 
\begin{equation*}
\ker \tup{T} =\set{\vect{v}\in V:T(\vect{v})=\vect{0}}
\end{equation*}
\end{definition}

It follows that $\func{im}\tup{T} $ and $\ker \tup{T} $
are subspaces of $W$ and $V$ respectively.

\begin{proposition}{Kernel and image as subspaces}{kernel-image-subspaces}
Let $V, W$ be subspaces of $\R^n$ and let $T:V\rightarrow W$ be a linear transformation. Then $\ker \tup{
T} $ is a subspace of $V$ and $\func{im}\tup{T} $ is a
subspace of $W$.
\end{proposition}

\begin{proof}
First consider $\ker \tup{T}$. It is necessary to
show that if $\vect{v}_{1},\vect{v}_{2}$ are vectors in $\ker \tup{T} $
and if $a,b$ are scalars, then $a\vect{v}_{1}+b\vect{v}_{2}$ is also in $\ker
\tup{T}$. But 
\begin{equation*}
T\tup{a\vect{v}_{1}+b\vect{v}_{2}} =aT(\vect{v}_{1})+bT(\vect{v}_{2})=a\vect{0}+b\vect{0}=\vect{0}
\end{equation*}
Thus $\ker \tup{T} $ is a subspace of $V$.

Next suppose $T(\vect{v}_{1}),T(\vect{v}_{2})$ are two vectors in $\func{im}\tup{
T}$. Then if $a,b$ are scalars, 
\begin{equation*}
aT(\vect{v}_{2})+bT(\vect{v}_{2})=T\tup{a\vect{v}_{1}+b\vect{v}_{2}}
\end{equation*}
and this last vector is in $\func{im}\tup{T} $ by definition. 
\end{proof}

We will now examine how to find the kernel and image of a linear transformation and describe the basis of each. 

\begin{example}{Kernel and image of a linear transformation}{kernel-image}
Let $T: \R^4 \mapsto \R^2$ be defined by
\[
T \begin{mymatrix}{c}
a \\
b \\
c \\
d
\end{mymatrix} = 
\begin{mymatrix}{c}
a - b \\ 
c + d
\end{mymatrix}
\]
Then $T$ is a linear transformation. Find a basis for $\func{ker}(T)$ and $\func{im}(T)$. 
\end{example}

\begin{solution}
You can verify that $T$ is a linear transformation.

First we will find a basis for $\func{ker}(T)$. To do so, we want to find a way to describe all vectors $\vect{x} \in \R^4$ such that $T(\vect{x}) = \vect{0}$. Let $\vect{x} =  \begin{mymatrix}{c}
a \\
b \\
c \\
d
\end{mymatrix}$ be such a vector. Then
\[
T \begin{mymatrix}{c}
a \\
b \\
c \\
d
\end{mymatrix} = 
\begin{mymatrix}{c}
a - b \\ 
c + d
\end{mymatrix} = 
\begin{mymatrix}{c}
0 \\ 
0
\end{mymatrix}
\]

The values of $a, b, c, d$ that make this true are given by solutions to the system 
\begin{eqnarray*}
a - b &=& 0 \\
c + d &=& 0
\end{eqnarray*}
The solution to this system is $ a = s, b = s, c = t, d = -t$ where $s, t$ are scalars. We can describe $\func{ker}(T)$ as follows.
\[
\func{ker}(T) = \set{\begin{mymatrix}{r}
s \\ 
s \\
t \\
-t 
\end{mymatrix} }
=
\func{span} \set{\begin{mymatrix}{r}
1 \\
1 \\
0 \\
0 
\end{mymatrix}, \begin{mymatrix}{r}
0 \\
0 \\
1 \\
-1
\end{mymatrix} }
\]
Notice that this set is linearly independent and therefore forms a basis for $\func{ker}(T)$. 

We move on to finding a basis for $\func{im}(T)$. We can write the image of $T$ as 
\[
\func{im}(T) = \set{\begin{mymatrix}{c}
a - b \\
c + d
\end{mymatrix}
}
\]
We can write this in the form
\[
\func{span} = \set{
\begin{mymatrix}{r}
1 \\
0
\end{mymatrix}, 
\begin{mymatrix}{r}
-1 \\
0
\end{mymatrix}, 
\begin{mymatrix}{r}
0 \\
1
\end{mymatrix}, 
\begin{mymatrix}{r}
0 \\
1
\end{mymatrix} }
\]
This set is clearly not linearly independent. By removing unnecessary vectors from the set we can create a linearly independent set with the same span. This gives a basis for $\func{im}(T)$ as
\[
\func{im}(T) = \func{span} \set{
\begin{mymatrix}{r}
1 \\
0
\end{mymatrix},
\begin{mymatrix}{r}
0 \\
1
\end{mymatrix}
}
\]
\end{solution}

Recall that a linear transformation $T$ is called one to one if and only if $T(\vect{x}) = \vect{0}$ implies $\vect{x} = \vect{0}$. Using the concept of kernel, we can state this theorem in another way.

\begin{theorem}{One to one and kernel}{one-to-one-kernel}
Let $T$ be a linear transformation where $\func{ker}(T)$ is the kernel of $T$. Then $T$ is one to one if and only if $\func{ker}(T)$ consists of \textbf{only} the zero vector. 
\end{theorem}

A major result is the relation between the dimension of the kernel and
dimension of the image of a linear transformation. In the previous example $\func{ker}(T)$ had dimension $2$, and $\func{im}(T)$ also had dimension of $2$. Is it a coincidence that the dimension of $\Mat_{22}$ is $4 = 2 + 2$? Consider the following theorem. 

\begin{theorem}{Dimension of kernel and image}{dimension-kernel-image}
Let $T:V\rightarrow W$ be a linear transformation where $V,W$ are subspaces of $\R^n$. Suppose the dimension of $V$ is $m$. Then 
\[
m=\dim \tup{\ker \tup{T} } +\dim \tup{\func{im}\tup{
T} } 
\]
\index{rank added to nullity}
\index{nullity}
\index{rank}
\end{theorem}

\begin{proof}
From Proposition \ref{prop:kernel-image-subspaces}, $\func{im}\tup{T} $ is a subspace of $W$. We know that there exists a basis for $\func{im}\tup{T}$, $\set{T(\vect{v}
_{1}),\cdots ,T(\vect{v}_{r})} . $ Similarly, there is a basis for $\ker
\tup{T} ,\set{\vect{u}_{1},\cdots ,\vect{u}_{s}}$. Then if $
\vect{v}\in V$, there exist scalars $c_{i}$ such that 
\begin{equation*}
T(\vect{v})=\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})
\end{equation*}
Hence $T\tup{\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}} =0$. It follows
that $\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}$ is in $\ker \tup{T}$.
Hence there are scalars $a_{i}$ such that 
\begin{equation*}
\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}=\sum_{j=1}^{s}a_{j}\vect{u}_{j}
\end{equation*}
Hence $\vect{v}=\sum_{i=1}^{r}c_{i}\vect{v}_{i}+\sum_{j=1}^{s}a_{j}\vect{u}
_{j}. $ Since $\vect{v}$ is arbitrary, it follows that 
\begin{equation*}
V=\func{span}\set{\vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,
\vect{v}_{r}}
\end{equation*}
If the vectors $\set{\vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,
\vect{v}_{r}} $ are linearly independent, then it will follow that
this set is a basis. Suppose then that 
\begin{equation*}
\sum_{i=1}^{r}c_{i}\vect{v}_{i}+\sum_{j=1}^{s}a_{j}\vect{u}_{j}=0
\end{equation*}
Apply $T$ to both sides to obtain 
\begin{equation*}
\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})+\sum_{j=1}^{s}a_{j}T(\vect{u})
_{j}=\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})=0
\end{equation*}
Since $\set{T(\vect{v}_{1}),\cdots ,T(\vect{v}_{r})} $ is linearly
independent, it follows that each $c_{i}=0$. Hence $\sum_{j=1}^{s}a_{j}\vect{u
}_{j}=0$ and so, since the $\set{\vect{u}_{1},\cdots ,\vect{u}_{s}} $
are linearly independent, it follows that each $a_{j}=0$ also. Therefore $\set{\vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,\vect{v}
_{r}} $ is a basis for $V$ and so 
\begin{equation*}
n=s+r=\dim \tup{\ker \tup{T} } +\dim \tup{\func{im}\tup{
T} } 
\end{equation*}
\end{proof}

The above theorem leads to the next corollary.

\begin{corollary}{}{}
Let $T:V\rightarrow W$ be a linear transformation where $V,W$ are subspaces of $\R^n$. Suppose the dimension of $V$ is $m$. Then 
\[
\dim \tup{\ker \tup{T} } \leq m
\]
\[
\dim \tup{\func{im}\tup{T } } \leq m
\]
\end{corollary}

This follows directly from the fact that $n=\dim \tup{\ker \tup{T} } +\dim \tup{\func{im}\tup{
T} }$.

Consider the following example.

\begin{example}{}{}
Let $T:\R^{2}\rightarrow \R^{3}$ be defined by 
\begin{equation*}
T(\vect{x})=\begin{mymatrix}{rr}
1 & 0 \\ 
1 & 0 \\ 
0 & 1
\end{mymatrix} \vect{x}
\end{equation*}
Then $\func{im}\tup{T} =V$ is a subspace of $\R^{3}$ and $T$
is an isomorphism of $\R^{2}$ and $V$. Find a $2\times 3$-matrix $A$
such that the restriction of multiplication by $A$ to $V=\func{im}\tup{
T} $ equals $T^{-1}$. 
\end{example}

\begin{solution}
Since the two columns of the above matrix are linearly independent, we conclude that $\func{dim}(\func{im}(T)) = 2$ and therefore $\func{dim}(\func{ker}(T)) = 2 - \func{dim}(\func{im}(T)) = 2-2 = 0$ by Theorem \ref{thm:dimension-kernel-image}. Then by Theorem \ref{thm:one-to-one-kernel} it follows that $T$ is one to one. 

Thus $T$ is an isomorphism of $\R^{2}$ and the two dimensional subspace of $\R^{3}$ which is the
span of the columns of the given matrix. Now in particular, 
\begin{equation*}
T(\vect{e}_{1})=\begin{mymatrix}{r}
1 \\ 
1 \\ 
0
\end{mymatrix} ,\ T(\vect{e}_{2})=\begin{mymatrix}{r}
0 \\ 
0 \\ 
1
\end{mymatrix}
\end{equation*}
Thus 
\begin{equation*}
T^{-1}\begin{mymatrix}{r}
1 \\ 
1 \\ 
0
\end{mymatrix} =\vect{e}_{1},\ T^{-1}\begin{mymatrix}{c}
0 \\ 
0 \\ 
1
\end{mymatrix} =\vect{e}_{2}
\end{equation*}
Extend $T^{-1}$ to all of $\R^{3}$ by defining 
\begin{equation*}
T^{-1}\begin{mymatrix}{c}
0 \\ 
1 \\ 
0
\end{mymatrix} =\vect{e}_{1}
\end{equation*}
Notice that the vectors
\begin{equation*}
\set{\begin{mymatrix}{c}
1 \\ 
1 \\ 
0
\end{mymatrix} ,\begin{mymatrix}{c}
0 \\ 
0 \\ 
1
\end{mymatrix} ,\begin{mymatrix}{c}
0 \\ 
1 \\ 
0
\end{mymatrix} } 
\end{equation*}
are linearly independent so $T^{-1}$ can be extended linearly to yield a
linear transformation defined on $\R^{3}$. The matrix of $T^{-1}$
denoted as $A$ needs to satisfy 
\begin{equation*}
A\begin{mymatrix}{rrr}
1 & 0 & 0 \\ 
1 & 0 & 1 \\ 
0 & 1 & 0
\end{mymatrix} =\begin{mymatrix}{rrr}
1 & 0 & 1 \\ 
0 & 1 & 0
\end{mymatrix}
\end{equation*}
and so 
\begin{equation*}
A=\begin{mymatrix}{rrr}
1 & 0 & 1 \\ 
0 & 1 & 0
\end{mymatrix} \begin{mymatrix}{rrr}
1 & 0 & 0 \\ 
1 & 0 & 1 \\ 
0 & 1 & 0
\end{mymatrix}^{-1}=\begin{mymatrix}{rrr}
0 & 1 & 0 \\ 
0 & 0 & 1
\end{mymatrix}
\end{equation*}
Note that 
\begin{equation*}
\begin{mymatrix}{rrr}
0 & 1 & 0 \\ 
0 & 0 & 1
\end{mymatrix} \begin{mymatrix}{c}
1 \\ 
1 \\ 
0
\end{mymatrix} =\begin{mymatrix}{c}
1 \\ 
0
\end{mymatrix}
\end{equation*}
\begin{equation*}
\begin{mymatrix}{rrr}
0 & 1 & 0 \\ 
0 & 0 & 1
\end{mymatrix} \begin{mymatrix}{c}
0 \\ 
0 \\ 
1
\end{mymatrix} =\begin{mymatrix}{c}
0 \\ 
1
\end{mymatrix}
\end{equation*}
so the restriction to $V$ of matrix multiplication by this matrix yields $
T^{-1}$.  
\end{solution}
