\section{Diagonalization}

\begin{outcome}
  \begin{enumerate}
  \item Compute sums, products, and powers of diagonal matrices.
  \item Determine whether a square matrix is diagonalizable, and
    diagonalize it if possible.
  \end{enumerate}
\end{outcome}

A square matrix $D$ is called a \textbf{diagonal matrix}%
\index{diagonal matrix}%
\index{matrix!diagonal matrix}
if all entries except those on the main diagonal are zero. Such
matrices look like the following:
\begin{equation*}
  \begin{mymatrix}{ccccc}
    d_{11} & 0 & \cdots & 0 \\
    0 & d_{22} & \cdots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \cdots & d_{nn} \\
  \end{mymatrix}.
\end{equation*}
Diagonal matrices are particularly easy to work with. For example, the
sum of two diagonal matrices is diagonal. Also, the product of two
diagonal matrices is diagonal, and is computed by taking the product
of corresponding diagonal entries.

\begin{example}{Sums, products, and powers of diagonal matrices}{sums-products-diagonal}
  Compute $A+B$, $AB$, and $A^{4}$, where
  \begin{equation*}
    A = \begin{mymatrix}{rrr}
      2 & 0 & 0 \\
      0 & 3 & 0 \\
      0 & 0 & 4 \\
    \end{mymatrix}
    \quad\mbox{and}\quad
    B = \begin{mymatrix}{rrr}
      1 & 0 & 0 \\
      0 & -2 & 0 \\
      0 & 0 & 2 \\
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We have
  \begin{equation*}
    A+B =
    \begin{mymatrix}{ccc}
      2+1 & 0 & 0 \\
      0 & 3-2 & 0 \\
      0 & 0 & 4+2 \\
    \end{mymatrix}
    =
    \begin{mymatrix}{rrr}
      3 & 0 & 0 \\
      0 & 1 & 0 \\
      0 & 0 & 6 \\
    \end{mymatrix},
  \end{equation*}
  \begin{equation*}
    AB =
    \begin{mymatrix}{ccc}
      2\cdot 1 & 0 & 0 \\
      0 & 3\cdot(-2) & 0 \\
      0 & 0 & 4\cdot 2 \\
    \end{mymatrix}
    =
    \begin{mymatrix}{rrr}
      2 & 0 & 0 \\
      0 & -6 & 0 \\
      0 & 0 & 8 \\
    \end{mymatrix},
  \end{equation*}
  and
  \begin{equation*}
    A^{4} =
    \begin{mymatrix}{ccc}
      2^{4} & 0 & 0 \\
      0 & 3^{4} & 0 \\
      0 & 0 & 4^{4} \\
    \end{mymatrix}
    =
    \begin{mymatrix}{ccc}
      16 & 0 & 0 \\
      0 & 81 & 0 \\
      0 & 0 & 256 \\
    \end{mymatrix}.
  \end{equation*}
  Notice that all operations are computed componentwise on the
  diagonal. Therefore, multiplication of diagonal matrices is much
  simpler than multiplication of general matrices.
\end{solution}

One of the most important problem solving techniques in linear algebra
is \textbf{diagonalization}%
\index{diagonalization}%
\index{matrix!diagonalization}. In a nutshell, the point of
diagonalization is to simplify a problem by replacing an arbitrary
matrix by a diagonal matrix. We say that two square matrices $A$ and
$B$ are \textbf{similar}%
\index{similar matrices}%
\index{matrix!similar} if there exists an invertible matrix $P$ such
that $P^{-1}AP = B$. A matrix is \textbf{diagonalizable}%
\index{matrix!diagonalizable}%
\index{diagonalizable matrix} if it is similar to a diagonal matrix.
This is summarized in the following definition.

\begin{definition}{Diagonalizable matrix}{diagonalizable}
  Let $A$ be an $n\times n$-matrix. Then $A$ is said to be
  \textbf{diagonalizable}%
  \index{diagonalizable matrix} if there exists an invertible matrix
  $P$ and a diagonal matrix $D$ such that
  \begin{equation*}
    P^{-1}AP=D.
  \end{equation*}
\end{definition}

The key connection between diagonalizability, eigenvectors, and
eigenvalues is the following theorem.

\begin{theorem}{Diagonalization and eigenvectors}{eigenvectors-and-diagonalizable}
  An $n\times n$-matrix $A$ is diagonalizable if and only if $A$ has
  $n$ linearly independent eigenvectors.
  \bigskip

  Moreover, in this case, let $P$ be the invertible matrix whose
  columns are $n$ linearly independent eigenvectors of $A$, and let
  $D$ be the diagonal matrix whose diagonal entries are the
  corresponding eigenvalues. Then $P^{-1}AP=D$.
\end{theorem}

\begin{proof}
  Assume that $A$ has $n$ linearly independent eigenvectors
  $\vect{v}_1,\ldots,\vect{v}_n$. Let
  $\eigenvar_1,\ldots,\eigenvar_n$ be the corresponding eigenvalues,
  so that
  \begin{equation}\label{eqn:eigenvectors-and-diagonalizable}
    A\vect{v}_i = \eigenvar_i\vect{v}_i
  \end{equation}
  for all $i=1,\ldots,n$. Let $P$ be the matrix that has
  $\vect{v}_1,\ldots,\vect{v}_n$ as its columns. Then $P$ is
  invertible because $\vect{v}_1,\ldots,\vect{v}_n$ are linearly
  independent. Let $D$ be the diagonal matrix that has
  $\eigenvar_1,\ldots,\eigenvar_n$ as its diagonal entries.  By the
  column method of matrix multiplication, the $i\th$ column of $AP$ is
  $A\vect{v}_i$. Also by the column method of matrix multiplication,
  the $i\th$ column of $PD$ is $\eigenvar_i\vect{v}_i$.  Therefore, by
  {\eqref{eqn:eigenvectors-and-diagonalizable}}, the matrices $AP$ and
  $PD$ have the same columns, i.e.,
  \begin{equation*}
    AP = PD.
  \end{equation*}
  It follows that $P^{-1}AP = D$, as desired.

  Conversely, assume that $A$ is diagonalizable. Then there exists an
  invertible matrix $P$ and a diagonal matrix $D$ such that
  $P^{-1}AP=D$, or equivalently, $AP=PD$. Let
  $\vect{v}_1,\ldots,\vect{v}_n$ be the columns of $P$ and let
  $\eigenvar_1,\ldots,\eigenvar_n$ be the diagonal entries of $D$.
  Again we find that the $i\th$ column of $AP$ is $A\vect{v}_i$ and
  the $i\th$ column of $PD$ is $\eigenvar_i\vect{v}_i$, and therefore
  $A\vect{v}_i = \eigenvar_i\vect{v}_i$ holds for all $i$. It follows
  that $\vect{v}_1,\ldots,\vect{v}_n$ are eigenvectors of $A$. Since
  $P$ is invertible, $\vect{v}_1,\ldots,\vect{v}_n$ are linearly
  independent, so $A$ has $n$ linearly independent eigenvectors.
\end{proof}

\begin{example}{Diagonalizing a matrix}{diagonalize-matrix}
  Diagonalize the matrix
  \begin{equation*}
    A=\begin{mymatrix}{rrr}
      3  & 0 &  2 \\
      6  & 4 &  3 \\
      -4 & 0 & -3 \\
    \end{mymatrix}.
  \end{equation*}
  In other words, find an invertible matrix $P$ and a diagonal matrix
  $D$ such that $P^{-1}AP=D$.
\end{example}

\begin{solution}
  By Theorem~\ref{thm:eigenvectors-and-diagonalizable}, we use the
  eigenvectors of $A$ as the columns of $P$ and the corresponding
  eigenvalues as the diagonal entries of $D$. We already found the
  eigenvectors and -values of $A$ in
  Example~\ref{exa:finding-eigenvalues-eigenvectors}.  They were
  \begin{equation*}
    \vect{v}_1 = \begin{mymatrix}{r} -1 \\ 1 \\ 1 \end{mymatrix}.
    \quad
    \vect{v}_2 = \begin{mymatrix}{r} -1 \\ 0 \\ 2 \end{mymatrix}.
    \quad\mbox{and}\quad
    \vect{v}_3 = \begin{mymatrix}{r} 0 \\ 1 \\ 0 \end{mymatrix}.
  \end{equation*}
  with corresponding eigenvalues $\eigenvar_1=1$, $\eigenvar_2=-1$,
  and $\eigenvar_3=4$. Therefore we can use
  \begin{equation*}
    P = \begin{mymatrix}{rrr}
      -1 & -1 & 0 \\
      1  &  0 & 1 \\
      1  &  2 & 0 \\
    \end{mymatrix}
    \quad\mbox{and}\quad
    D = \begin{mymatrix}{rrr}
      1 &  0 & 0 \\
      0 & -1 & 0 \\
      0 &  0 & 4 \\
    \end{mymatrix}.
  \end{equation*}
  To double-check that $P^{-1}AP$ is indeed equal to $D$, we first
  compute the inverse of $P$:
  \begin{equation*}
    P^{-1} =
    \begin{mymatrix}{rrr}
      -2 & 0 & -1 \\
      1  & 0 &  1 \\
      2  & 1 &  1 \\
    \end{mymatrix}.
  \end{equation*}
  Then
  \begin{equation*}
    P^{-1}AP
    ~=~
    \begin{mymatrix}{rrr}
      -2 & 0 & -1 \\
      1  & 0 &  1 \\
      2  & 1 &  1 \\
    \end{mymatrix}
    \begin{mymatrix}{rrr}
      3  & 0 &  2 \\
      6  & 4 &  3 \\
      -4 & 0 & -3 \\
    \end{mymatrix}
    \begin{mymatrix}{rrr}
      -1 & -1 & 0 \\
      1  &  0 & 1 \\
      1  &  2 & 0 \\
    \end{mymatrix}
    =
    \begin{mymatrix}{rrr}
      1 &  0 & 0 \\
      0 & -1 & 0 \\
      0 &  0 & 4 \\
    \end{mymatrix}
    = D.
  \end{equation*}
  Alternatively, we could have checked that $AP=PD$, which would not
  have required computing $P^{-1}$.
\end{solution}

\begin{example}{Diagonalizing a matrix}{diagonalize-matrix2}
  Diagonalize the matrix
  \begin{equation*}
    A=\begin{mymatrix}{rrr}
      2  &  0 &  0 \\
      1  &  4 & -1 \\
      -2 & -4 &  4 \\
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  First, we will find the characteristic polynomial of $A$:
  \begin{eqnarray*}
    \det(A-\eigenvar I)
    &=&
        \begin{absmatrix}{ccc}
          2-\eigenvar &  0 &  0 \\
          1 &  4-\eigenvar & -1 \\
          -2 & -4 & 4-\eigenvar \\
        \end{absmatrix}
    \\\\[-1ex]
    &=& (2-\eigenvar)
        \begin{absmatrix}{cc}
          4-\eigenvar & -1 \\
          -4 & 4-\eigenvar \\
        \end{absmatrix}
    \\\\[-2ex]
    &=& (2-\eigenvar)\paren{(4-\eigenvar)(4-\eigenvar)-4}
    \\
    &=& (2-\eigenvar)(12-8\eigenvar+\eigenvar^2)
    \\
    &=& (2-\eigenvar)(2-\eigenvar)(6-\eigenvar).
  \end{eqnarray*}
  Therefore, the eigenvalues are $\eigenvar=2$ and $\eigenvar=6$.
  Next, we need to find the eigenvectors. We first find the
  eigenvectors for $\eigenvar = 2$. We solve $(A-2I)\/\vect{v} = \vect{0}$:
  \begin{equation*}
    \begin{mymatrix}{rrr|r}
      0  &  0 &  0 & 0 \\
      1  &  2 & -1 & 0 \\
      -2 & -4 &  2 & 0 \\
    \end{mymatrix}
    \roweq
    \begin{mymatrix}{rrr|r}
      1  &  2 & -1 & 0 \\
      0  &  0 &  0 & 0 \\
      0  &  0 &  0 & 0 \\
    \end{mymatrix}.
  \end{equation*}
  The general solution is
  \begin{equation*}
    t\begin{mymatrix}{r} -2 \\ 1 \\ 0 \end{mymatrix}
    +s\begin{mymatrix}{r} 1 \\ 0 \\ 1 \end{mymatrix},
  \end{equation*}
  where $t,s$ are parameters. Thus, the basic eigenvectors for
  $\eigenvar=2$ are
  \begin{equation*}
    \vect{v}_1 = \begin{mymatrix}{r} -2 \\ 1 \\ 0 \end{mymatrix}
    \quad\mbox{and}\quad
    \vect{v}_2 = \begin{mymatrix}{r}  1 \\ 0 \\ 1 \end{mymatrix}.
  \end{equation*}
  Doing a similar calculation, we find that the basic eigenvector for
  $\eigenvar=6$ is
  \begin{equation*}
    \vect{v}_3 = \begin{mymatrix}{r}  0 \\ 1 \\ -2 \end{mymatrix}.
  \end{equation*}
  By Theorem~\ref{thm:eigenvectors-and-diagonalizable}, we use the
  eigenvectors of $A$ as the columns of $P$ and the corresponding
  eigenvalues as the diagonal entries of $D$. Therefore,
  \begin{equation*}
    P=
    \begin{mymatrix}{rrr}
      -2 & 1 & 0 \\
      1 & 0 & 1 \\
      0 & 1 & -2
    \end{mymatrix}
    \quad\mbox{and}\quad
    D = \begin{mymatrix}{rrr}
      2 & 0 & 0 \\
      0 & 2 & 0 \\
      0 & 0 & 6
    \end{mymatrix}.
  \end{equation*}
  We can double-check this answer by computing
  \begin{equation*}
    \def\arraystretch{1.3}
    P^{-1}AP
    ~=~ \begin{mymatrix}{rrr}
      -\frac{1}{4} & \frac{1}{2} & \frac{1}{4} \\
      \frac{1}{2} & 1 & \frac{1}{2} \\
      \frac{1}{4} & \frac{1}{2} & -\frac{1}{4}
    \end{mymatrix} \begin{mymatrix}{rrr}
      2 & 0 & 0 \\
      1 & 4 & -1 \\
      -2 & -4 & 4
    \end{mymatrix} \begin{mymatrix}{rrr}
      -2 & 1 & 0 \\
      1 & 0 & 1 \\
      0 & 1 & -2
    \end{mymatrix} \\
    ~=~ \begin{mymatrix}{rrr}
      2 & 0 & 0 \\
      0 & 2 & 0 \\
      0 & 0 & 6
    \end{mymatrix}
    ~=~ D.
  \end{equation*}
  Notice that the eigenvalues on the main diagonal of $D$ {\em must}
  be in the same order as the corresponding eigenvectors in $P$. Since
  the eigenvectors $\vect{v}_1$ and $\vect{v}_2$ are both for the
  eigenvalue $\eigenvar=2$, the entry $2$ appears twice in the matrix
  $D$.
\end{solution}

The following example shows that not all matrices are diagonalizable.

\begin{example}{A matrix that cannot be diagonalized}{impossible-diagonalize}
  Show that the matrix $A =
    \begin{mymatrix}{rr}
      1 & 1 \\
      0 & 1
    \end{mymatrix}$ cannot be diagonalized.
\end{example}

\begin{solution}
  Through the usual procedure, we find that the characteristic
  polynomial is $(1-\eigenvar)^2$, and therefore the only eigenvalue is
  $\eigenvar=1$. To find the eigenvectors, we solve the equation
  $(A-I)\vect{v} = \vect{0}$:
  \begin{equation*}
    \begin{mymatrix}{rr|r}
      0 & 1 & 0 \\
      0 & 0 & 0 \\
    \end{mymatrix}.
  \end{equation*}
  The general solution is
  \begin{equation*}
    \vect{v} = t\begin{mymatrix}{r} 1 \\ 0 \end{mymatrix}.
  \end{equation*}
  Because the solution space is 1-dimensional, there is only one basic
  eigenvector:
  \begin{equation*}
    \vect{v}_1 = \begin{mymatrix}{r} 1 \\ 0 \end{mymatrix}.
  \end{equation*}
  Since the matrix $A$ has only one basic eigenvector, we cannot find
  two linearly independent eigenvectors. Therefore, by
  Theorem~\ref{thm:eigenvectors-and-diagonalizable}, $A$ cannot be
  diagonalized.
\end{solution}
