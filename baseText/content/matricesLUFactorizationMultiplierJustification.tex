\subsection{Justification for the  multiplier method}

Why does the multiplier method work for finding the $LU$ factorization?
Suppose $A$ is a matrix which has the property that the {\ef} for $A$ may be achieved without switching rows. Thus every row which is replaced using this
row operation in obtaining the {\ef} may be modified by using a row which
is above it.\index{LU factorization!justification}

\begin{lemma}{Multiplier method and triangular matrices}{multipliermethodtriangularmatrices}
Let $L$ be a lower (upper) triangular matrix $m\times m$
which has ones down the main diagonal. Then $L^{-1}$ also is a lower (upper)
triangular matrix which has ones down the main diagonal. In the case that $L$
is of the form 
\begin{equation}
L=\begin{mymatrix}{cccc}
1 &  &  &  \\ 
a_{1} & 1 &  &  \\ 
\vdots &  & \ddots &  \\ 
a_{n} &  &  & 1
\end{mymatrix}  \label{4nove1h}
\end{equation}
where all entries are zero except for the left column and main diagonal, it
is also the case that $L^{-1}$ is obtained from $L$ by simply multiplying
each entry below the main diagonal in $L$ with $-1$. The same is true if the
single nonzero column is in another position.
\end{lemma}

\begin{proof}Consider the usual setup for finding the inverse $\begin{mymatrix}{cc}
L & I
\end{mymatrix} .$ Then each row operation done to $L$ to reduce to row reduced
echelon form results in changing only the entries in $I$ below the main
diagonal. In the special case of $L$ given in \ref{4nove1h} or the single
nonzero column is in another position, multiplication by $-1$ as described
in the lemma clearly results in $L^{-1}$.
\end{proof}

For a simple illustration of the last claim, 
\begin{equation*}
\begin{mymatrix}{cccccc}
1 & 0 & 0 & 1 & 0 & 0 \\ 
0 & 1 & 0 & 0 & 1 & 0 \\ 
0 & a & 1 & 0 & 0 & 1
\end{mymatrix} \rightarrow \begin{mymatrix}{cccccc}
1 & 0 & 0 & 1 & 0 & 0 \\ 
0 & 1 & 0 & 0 & 1 & 0 \\ 
0 & 0 & 1 & 0 & -a & 1%
\end{array}%
}
\end{equation*}

Now let $A$ be an $m\times n$ matrix, say 
\begin{equation*}
A=\begin{mymatrix}{cccc}
a_{11} & a_{12} & \cdots & a_{1n} \\ 
a_{21} & a_{22} & \cdots & a_{2n} \\ 
\vdots & \vdots &  & \vdots \\ 
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{mymatrix}
\end{equation*}
and assume $A$ can be row reduced to an upper triangular form using only row
operation 3. Thus, in particular, $a_{11}\neq 0$. Multiply on the left by $
E_{1}=$
\begin{equation*}
\begin{mymatrix}{cccc}
1 & 0 & \cdots & 0 \\ 
-
\frac{a_{21}}{a_{11}} & 1 & \cdots & 0 \\ 
\vdots & \vdots & \ddots & \vdots \\ 
-\frac{a_{m1}}{a_{11}} & 0 & \cdots & 1
\end{mymatrix}
\end{equation*}
This is the product of elementary matrices which make modifications in the
first column only. It is equivalent to taking $-a_{21}/a_{11}$ times the
first row and adding to the second. Then taking $-a_{31}/a_{11}$ times the
first row and adding to the third and so forth. The quotients in the first
column of the above matrix are the multipliers. Thus the result is of the
form 
\begin{equation*}
E_{1}A=\begin{mymatrix}{cccc}
a_{11} & a_{12} & \cdots & a_{1n}^{\prime } \\ 
0 & a_{22}^{\prime } & \cdots & a_{2n}^{\prime } \\ 
\vdots & \vdots &  & \vdots \\ 
0 & a_{m2}^{\prime } & \cdots & a_{mn}^{\prime }%
\end{mymatrix}
\end{equation*}
By assumption, $a_{22}^{\prime }\neq 0$ and so it is possible to use this
entry to zero out all the entries below it in the matrix on the right by
multiplication by a matrix of the form $E_{2}=\begin{mymatrix}{cc}
1 & \mathbf{0} \\ 
\mathbf{0} & E
\end{mymatrix} $ where $E$ is an $\mat{m-1} \times \mat{m-1} $
matrix of the form 
\begin{equation*}
E=\begin{mymatrix}{cccc}
1 & 0 & \cdots & 0 \\ 
-\frac{a_{32}^{\prime }}{a_{22}^{\prime }} & 1 & \cdots & 0 \\ 
\vdots & \vdots & \ddots & \vdots \\ 
-\frac{a_{m2}^{\prime }}{a_{22}^{\prime }} & 0 & \cdots & 1
\end{mymatrix}
\end{equation*}
Again, the entries in the first column below the 1 are the multipliers.
Continuing this way, zeroing out the entries below the diagonal entries,
finally leads to 
\begin{equation*}
E_{m-1}E_{n-2}\cdots E_{1}A=U
\end{equation*}
where $U$ is upper triangular. Each $E_{j}$ has all ones down the main
diagonal and is lower triangular. Now multiply both sides by the inverses of
the $E_{j}$ in the reverse order$.$ This yields 
\begin{equation*}
A=E_{1}^{-1}E_{2}^{-1}\cdots E_{m-1}^{-1}U
\end{equation*}
By Lemma \ref{lem:multipliermethodtriangularmatrices}, this implies that the product of those $E_{j}^{-1}$
is a lower triangular matrix having all ones down the main diagonal.

The above discussion and lemma gives the justification for the multiplier
method. The expressions 
\begin{equation*}
\frac{-a_{21}}{a_{11}},\frac{-a_{31}}{a_{11}},\cdots, \frac{-a_{m1}}{a_{11}}
\end{equation*}
denoted respectively by $M_{21},\cdots ,M_{m1}$ to save notation which were
obtained in building $E_{1}$ are the multipliers.
\index{multipliers} Then according to the lemma, to find $E_{1}^{-1}$ you
simply write 
\begin{equation*}
\begin{mymatrix}{cccc}
1 & 0 & \cdots & 0 \\ 
-M_{21} & 1 & \cdots & 0 \\ 
\vdots & \vdots & \ddots & \vdots \\ 
-M_{m1} & 0 & \cdots & 1
\end{mymatrix}
\end{equation*}
Similar considerations apply to the other $E_{j}^{-1}.$ Thus $L$ is a
product of the form 
\begin{equation*}
\begin{mymatrix}{cccc}
1 & 0 & \cdots & 0 \\ 
-M_{21} & 1 & \cdots & 0 \\ 
\vdots & \vdots & \ddots & \vdots \\ 
-M_{m1} & 0 & \cdots & 1
\end{mymatrix} \cdots \begin{mymatrix}{cccc}
1 & 0 & \cdots & 0 \\ 
0 & 1 & \cdots & 0 \\ 
\vdots & 0 & \ddots & \vdots \\ 
0 & \cdots & -M_{m\mat{m-1} } & 1
\end{mymatrix}
\end{equation*}
each factor having at most one nonzero column, the position of which moves
from left to right in scanning the above product of matrices from left to
right. It follows from what we know  about the effect of multiplying
on the left by an elementary matrix that the above product is of the form 
\begin{equation*}
\begin{mymatrix}{ccccc}
1 & 0 & \cdots & 0 & 0 \\ 
-M_{21} & 1 & \cdots & 0 & 0 \\ 
\vdots & -M_{32} & \ddots & \vdots & \vdots \\ 
-M_{\mat{M-1} 1} & \vdots & \cdots & 1 & 0 \\ 
-M_{M1} & -M_{M2} & \cdots & -M_{MM-1} & 1
\end{array}%
}
\end{equation*}

In words, beginning at the left column and moving toward the right, you
simply insert, into the corresponding position in the identity matrix, $-1$
times the multiplier which was used to zero out an entry in that position
below the main diagonal in $A,$ while retaining the main diagonal which
consists entirely of ones. This is $L.$
