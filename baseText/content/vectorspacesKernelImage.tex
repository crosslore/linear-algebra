\section{The kernel and image of a linear map}

\begin{outcome}
  \begin{enumerate}
  \item Describe the kernel and image of a linear transformation.
  \item Use the kernel and image to determine if a linear
    transformation is one to one or onto.
  \end{enumerate}
\end{outcome}

Here we consider the case where the linear map is not necessarily an
isomorphism. First here is a definition of what is meant by the image and
kernel of a linear transformation.

\begin{definition}{Kernel and image}{}
Let $V$ and $W$ be vector spaces and let $T:V\rightarrow W$ be a linear transformation. Then the image of $T$
denoted as $\func{im}\tup{T} $ is defined to be the set 
\begin{equation*}
\set{T(\vect{v}):\vect{v}\in V}
\end{equation*}
In words, it consists of all vectors in $W$ which equal $T(\vect{v})$ for some $
\vect{v}\in V$. The kernel, $\ker \tup{T}$, 
consists of all $\vect{v}\in V$ such that $T(\vect{v})=\vect{0}$. That is, 
\begin{equation*}
\ker \tup{T} =\set{\vect{v}\in V:T(\vect{v})=\vect{0}}
\end{equation*}
\end{definition}

Then in fact, both $\func{im}\tup{T} $ and $\ker \tup{T} $
are subspaces of $W$ and $V$ respectively.

\begin{proposition}{Kernel and image as subspaces}{kernel-image-vector-spaces}
Let $V,W$ be vector spaces and let $T:V\rightarrow W$ be a linear transformation. Then $\ker \tup{
T} \subseteq V$ and $\func{im}\tup{T} \subseteq W$. In fact, they are both subspaces. 
\end{proposition}

\begin{proof}
First consider $\ker \tup{T}$. It is necessary to
show that if $\vect{v}_{1},\vect{v}_{2}$ are vectors in $\ker \tup{T} $
and if $a,b$ are scalars, then $a\vect{v}_{1}+b\vect{v}_{2}$ is also in $\ker
\tup{T}$. But 
\begin{equation*}
T\tup{a\vect{v}_{1}+b\vect{v}_{2}} =aT(\vect{v}_{1})+bT(\vect{v}_{2})=a\vect{0}+b\vect{0}=\vect{0}
\end{equation*}
Thus $\ker \tup{T} $ is a subspace of $V$.

Next suppose $T(\vect{v}_{1}),T(\vect{v}_{2})$ are two vectors in $\func{im}\tup{
T}$. Then if $a,b$ are scalars, 
\begin{equation*}
aT(\vect{v}_{2})+bT(\vect{v}_{2})=T\tup{a\vect{v}_{1}+b\vect{v}_{2}}
\end{equation*}
and this last vector is in $\func{im}\tup{T} $ by definition. 
\end{proof}

Consider the following example.

\begin{example}{Kernel and image of a transformation}{kernel-image}
Let $T:\Poly_1\to\R$ be the linear transformation defined by
\[ T(p(x))=p(1)\mbox{ for all } p(x)\in \Poly_1.\]
Find the kernel and image of $T$.
\end{example}

\begin{solution}
We will first find the kernel of $T$. It consists of all polynomials in $\Poly_1$ that have $1$ for a root. 
\begin{eqnarray*}
\func{ker}(T) & = & \{p(x)\in \Poly_1 ~|~ p(1)=0\} \\
& = & \{ax+b ~|~ a,b\in\R \mbox{ and }a+b=0\} \\
& = & \{ax-a ~|~ a\in\R\}
\end{eqnarray*}
Therefore a basis for $\func{ker}(T)$ is 
\[
\set{x-1 }
\]
Notice that this is a subspace of $\Poly_1$. 

Now consider the image. It consists of all numbers which can be obtained by evaluating all polynomials in $\Poly_1$ at $1$. 
\begin{eqnarray*}
\func{im}(T) & = & \{p(1) ~|~ p(x)\in \Poly_1\} \\
 & = & \{a+b ~|~ ax+b\in \Poly_1\} \\
 & = & \{a+b ~|~ a,b\in\R\}\\
 & = & \R
\end{eqnarray*}
Therefore a basis for $\func{im}(T)$ is 
\[
\set{1 }
\]
Notice that this is a subspace of $\R$, and in fact is the space $\R$ itself. 
\end{solution}

\begin{example}{Kernel and image of a linear transformation}{finding-kernel-image}
Let $T: \Mat_{22} \mapsto \R^2$ be defined by
\[
T \begin{mymatrix}{cc}
a & b \\
c & d 
\end{mymatrix}
 = 
\begin{mymatrix}{c}
a - b \\
c + d
\end{mymatrix}
\]
Then $T$ is a linear transformation. Find a basis for $\func{ker} (T)$ and $\func{im}(T)$.
\end{example}

\begin{solution}
You can verify that $T$ represents a linear transformation. 

Now we want to find a way to describe all matrices $A$ such that $T(A) = \vect{0}$, that is the matrices in $\func{ker}(T)$. 
Suppose $A = \begin{mymatrix}{cc}
a & b \\
c & d 
\end{mymatrix}$ is such a matrix. 
Then
\[
T \begin{mymatrix}{cc}
a & b \\
c & d 
\end{mymatrix}
 = 
\begin{mymatrix}{c}
a - b \\
c + d
\end{mymatrix}
 = 
\begin{mymatrix}{c}
0 \\
0
\end{mymatrix}
\]
The values of $a, b, c, d$ that make this true are given by solutions to the system
\begin{eqnarray*}
a - b &=& 0 \\
c + d &=& 0 
\end{eqnarray*}
The solution is $a = s, b = s, c = t, d = -t$ where $s, t$ are scalars. We can describe $\func{ker}(T)$ as follows.
\[
\func{ker}(T) = 
\set{
\begin{mymatrix}{cc}
s & s \\
t & -t 
\end{mymatrix}
}
=
\func{span}
\set{
\begin{mymatrix}{cc}
1 & 1 \\
0 & 0 
\end{mymatrix}, 
\begin{mymatrix}{cc}
0 & 0 \\
1 & -1 
\end{mymatrix}
}
\]
It is clear that this set is linearly independent and therefore forms a basis for $\func{ker}(T)$. 

We now wish to find a basis for $\func{im}(T)$. We can write the image of $T$ as 
\[
\func{im}(T) = \set{
\begin{mymatrix}{c}
a - b  \\
c + d  
\end{mymatrix}
}
\]
Notice that this can be written as 
\[
\func{span}
\set{
\begin{mymatrix}{c}
1 \\ 
0
\end{mymatrix}, 
\begin{mymatrix}{c}
-1 \\ 
0
\end{mymatrix}, 
\begin{mymatrix}{c}
0 \\ 
1
\end{mymatrix}, 
\begin{mymatrix}{c}
0 \\ 
1
\end{mymatrix} }
\]

However this is clearly not linearly independent. By removing vectors from the set to create an independent set gives a basis of $\func{im}(T)$.
\[
\set{
\begin{mymatrix}{c}
1 \\ 
0
\end{mymatrix}, 
\begin{mymatrix}{c}
0 \\ 
1
\end{mymatrix}
}
\]

Notice that these vectors have the same span as the set above but are now linearly independent.
\end{solution}

A major result is the relation between the dimension of the kernel and
dimension of the image of a linear transformation. A special case was done
earlier in the context of matrices. Recall that for an $m\times n$-matrix $%
A, $ it was the case that the dimension of the kernel of $A$ added to the
rank of $A$ equals $n$. 

\begin{theorem}{Dimension of kernel and image}{}
Let $T:V\rightarrow W$ be a linear transformation where $V,W$ are vector
spaces. Suppose the dimension of $V$ is $n$.
Then $n=\dim \tup{\ker \tup{T} } +\dim \tup{\func{im}
\tup{T} }$.
\end{theorem}

\begin{proof}
From Proposition~\ref{prop:kernel-image-vector-spaces}, $\func{im}\tup{T} $
is a subspace of $W$. By Theorem~\ref{thm:basis-vector-space}, there exists a basis for $
\func{im}\tup{T} ,\set{T(\vect{v}_{1}),\cdots ,T(\vect{v}_{r})}
. $ Similarly, there is a basis for $\ker \tup{T} ,\set{\vect{u}
_{1},\cdots ,\vect{u}_{s}}$. Then if $\vect{v}\in V$, there exist
scalars $c_{i}$ such that 
\begin{equation*}
T(\vect{v})=\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})
\end{equation*}
Hence $T\tup{\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}} =0$. It follows
that $\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}$ is in $\ker \tup{T}$.
Hence there are scalars $a_{i}$ such that 
\begin{equation*}
\vect{v}-\sum_{i=1}^{r}c_{i}\vect{v}_{i}=\sum_{j=1}^{s}a_{j}\vect{u}_{j}
\end{equation*}
Hence $\vect{v}=\sum_{i=1}^{r}c_{i}\vect{v}_{i}+\sum_{j=1}^{s}a_{j}\vect{u}
_{j}. $ Since $\vect{v}$ is arbitrary, it follows that 
\begin{equation*}
V=\func{span}\set{\vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,
\vect{v}_{r}}
\end{equation*}
If the vectors $\set{\vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,
\vect{v}_{r}} $ are linearly independent, then it will follow that
this set is a basis. Suppose then that 
\begin{equation*}
\sum_{i=1}^{r}c_{i}\vect{v}_{i}+\sum_{j=1}^{s}a_{j}\vect{u}_{j}=0
\end{equation*}
Apply $T$ to both sides to obtain 
\begin{equation*}
\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})+\sum_{j=1}^{s}a_{j}T(\vect{u}
_{j})=\sum_{i=1}^{r}c_{i}T(\vect{v}_{i})= \vect{0}
\end{equation*}
Since $\set{T(\vect{v}_{1}),\cdots ,T(\vect{v}_{r})} $ is linearly
independent, it follows that each $c_{i}=0$. Hence $\sum_{j=1}^{s}a_{j}\vect{u
}_{j}=0$ and so, since the $\set{\vect{u}_{1},\cdots ,\vect{u}_{s}} $
are linearly independent, it follows that each $a_{j}=0$ also. It follows
that $\set{\vect{u}_{1},\cdots ,\vect{u}_{s},\vect{v}_{1},\cdots ,\vect{v}
_{r}} $ is a basis for $V$ and so 
\begin{equation*}
n=s+r=\dim \tup{\ker \tup{T} } +\dim \tup{\func{im}\tup{
T} }
\end{equation*}
\end{proof}

Consider the following definition. 

\begin{definition}{Rank of linear transformation}{}
Let $T:V\rightarrow W$ be a linear transformation and suppose $V,W$ are finite dimensional vector spaces. Then
the rank of $T$ denoted as $\func{rank}\tup{T} $ is defined as the
dimension of $\func{im}\tup{T}$. The nullity of $T$ is the
dimension of $\ker \tup{T}$. Thus the above theorem says that $
\func{rank}\tup{T} +\dim \tup{\ker \tup{T} } =\dim
\tup{V}$.
\end{definition}

Recall the following important result. 

\begin{theorem}{Subspace of same dimension}{subspace-vector-space}
Let $V$ be a vector space of dimension $n$ and let $W$ be a
subspace. Then $W=V$ if and only if the dimension of $W$ is also $n$.
\end{theorem}

From this theorem follows the next corollary.

\begin{corollary}{One to one and onto characterization}{one-one-onto-char}
Let $T:V\rightarrow W$ be a linear map where the dimension of $V$ is $n$ and
the dimension of $W$ is $m$. Then $T$ is one to one if and only if $\ker
\tup{T} =\set{\vect{0}} $ and $T$ is onto if and only if $
\func{rank}\tup{T} =m$.
\end{corollary}

\begin{proof}
The statement $\ker \tup{T } =\set{\vect{0}} $
is equivalent to saying if $T \tup{\vect{v} }=\vect{0}$, it follows that $\vect{v}=\vect{0}$
. Thus by Lemma~\ref{lem:one-to-one-abstract} $T$ is one to one. If $T$ is onto, then $
\func{im}\tup{T} =W$ and so $\func{rank}\tup{T} $ which is
defined as the dimension of $\func{im}\tup{T} $ is $m$. If $\func{
rank}\tup{T} =m$, then by Theorem~\ref{thm:subspace-vector-space}, since $\func{im}
\tup{T} $ is a subspace of $W$, it follows that $\func{im}\tup{
T} =W$. 
\end{proof}

\begin{example}{One to one transformation}{one-to-one-kernel}
Let $S:\Poly_2\to\Mat_{22}$ be a linear transformation
defined by
\[ S(ax^2+bx+c)
=
\begin{mymatrix}{cc}
a+b & a+c \\ b-c & b+c \end{mymatrix}
\mbox{ for all }
 ax^2+bx+c\in \Poly_2.\]
Prove that $S$ is one to one but not onto.
\end{example}

\begin{solution}
You may recall this example from earlier in Example~\ref{exa:one-to-one-general}. Here we will determine that $S$ is one to one, but not onto, using the method provided in Corollary~\ref{cor:one-one-onto-char}.

By definition, 
\[ \ker(S)=\{ax^2+bx+c\in \Poly_2 ~|~ a+b=0,
a+c=0, b-c=0, b+c=0\}.\]

Suppose $p(x)=ax^2+bx+c\in\ker(S)$.
This leads to a homogeneous system of four equations in three 
variables.  
Putting the augmented matrix in {\rref}: 

\[ \begin{mymatrix}{rrr|c}
1 & 1 & 0 & 0  \\
1 & 0 & 1 & 0  \\
0 & 1 & -1 & 0  \\
0 & 1 & 1 & 0  \end{mymatrix}
\rightarrow \cdots \rightarrow
\begin{mymatrix}{ccc|c}
1 & 0 & 0 & 0  \\
0 & 1 & 0 & 0  \\
0 & 0 & 1 & 0  \\
0 & 0 & 0 & 0  \end{mymatrix}. \]

Since the unique solution is $a=b=c=0$, $\ker(S)=\{\vect{0}\}$, and thus
$S$ is one-to-one by Corollary~\ref{cor:one-one-onto-char}.

Similarly, by Corollary~\ref{cor:one-one-onto-char}, if $S$ is onto it will have $\func{rank}(S) = \func{dim}(\Mat_{22}) = 4$. The image of $S$ is given by 
\[
\func{im}(S) = \set{\begin{mymatrix}{cc}
a+b & a+c \\ b-c & b+c \end{mymatrix} } = \func{span} \set{\begin{mymatrix}{rr}
1 & 1 \\
0 & 0 \end{mymatrix}, \begin{mymatrix}{rr}
1 & 0 \\
1 & 1 \end{mymatrix}, \begin{mymatrix}{rr}
0 & 1 \\
-1 & 1 \end{mymatrix} }
\]
These matrices are linearly independent which means this set forms a basis for $\func{im}(S)$. Therefore the dimension of $\func{im}(S)$, also called $\func{rank}(S)$, is equal to $3$. It follows that $S$ is not onto. 
\end{solution}
