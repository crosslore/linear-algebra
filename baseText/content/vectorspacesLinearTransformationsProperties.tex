\section{The algebra of linear transformations}

Two linear transformations are considered to be equal if they act in
the same way on all vectors. This is the content of the following
definition.

\begin{definition}{Equal transformations}{equal-transformations}
  Let $S$ and $T$ be linear transformations from $V$ to $W$. We say
  that $S$ and $T$ are \textbf{equal}%
  \index{linear transformation!equality of}%
  \index{equality!of linear transformations}, and we write $S = T$, if
  for all $\vect{v}\in V$,
  \begin{equation*}
    S(\vect{v}) = T(\vect{v}).
  \end{equation*}
\end{definition}

We now consider several operations on linear transformations. These
include addition and scalar multiplication of linear transformations,
as well as the zero transformation.

\begin{definition}{Addition and scalar multiplication of linear transformations}{addition-linear-transformations}
  Let $V$ and $W$ be vector spaces over a field $K$.
  \begin{enumialphparenastyle}
    \begin{enumerate}
    \item The \textbf{zero transformation}%
      \index{zero transformation}%
      \index{linear transformation!zero transformation} $0:V\to W$ is
      defined by $0(\vect{v})=\vect{0}$ for all $\vect{v}\in V$.
    \item If $T,S:V\to W$ are linear transformations, then their
      \textbf{sum}%
      \index{addition!of linear transformations}%
      \index{linear transformation!addition of}
      $T+S:V\to W$ is the linear transformation defined by
      \begin{equation*}
        (T+S)(\vect{v}) = T(\vect{v}) + S(\vect{v})
      \end{equation*}
      for all $\vect{v}\in V$.
    \item If $T:V\to W$ is a linear transformation and $k\in K$, the
      linear transformation%
      \index{scalar multiplication!of linear transformations}%
      \index{linear transformation!scalar multiplication of}
      $kT : V\to W$ is defined by
      \begin{equation*}
        (kT)(\vect{v}) = k(T(\vect{v}))
      \end{equation*}
      for all $\vect{v}\in V$.
    \end{enumerate}
  \end{enumialphparenastyle}
\end{definition}

\begin{proposition}{Addition and scalar multiplication of linear transformations}{addition-linear-transformations}
  If $T,S:V\to W$ are linear transformations, then so are $T+S$ and $kT$.
\end{proposition}

\begin{proof}
  To show that $T+S$ is linear, we must verify that it preserves
  addition and scalar multiplication. Let $\vect{v},\vect{u}\in
  V$. Then we have
  \begin{equation*}
    \begin{array}{r@{~}c@{~}ll}
      (T+S)(\vect{v}+\vect{u})
      &=& T(\vect{v}+\vect{u}) + S(\vect{v}+\vect{u})
      & \mbox{by definition of $T+S$,} \\
      &=& (T(\vect{v}) + T(\vect{u})) + (S(\vect{v}) + S(\vect{u}))
      & \mbox{by linearity of $T$ and $S$,} \\
      &=& (T(\vect{v}) + S(\vect{v})) + (T(\vect{u}) + S(\vect{u}))
      & \mbox{by the associative and commutative laws of vectors,} \\
      &=& (T+S)(\vect{v}) + (T+S)(\vect{u})
      & \mbox{by definition of $T+S$.}
    \end{array}
  \end{equation*}
  Therefore, $T+S$ preserves addition. Also, for $\vect{v}\in V$ and
  $\ell\in K$, we have
  \begin{equation*}
    \begin{array}{r@{~}c@{~}ll}
      (T+S)(\ell\vect{v})
      &=& T(\ell\vect{v}) + S(\ell\vect{v})
      & \mbox{by definition of $T+S$} \\
      &=& \ell T(\vect{v}) + \ell S(\vect{v})
      & \mbox{by linearity of $T$ and $S$} \\
      &=& \ell(T(\vect{v}) + S(\vect{v}))
      & \mbox{by the distributive law over vector addition} \\
      &=& \ell((T+S)(\vect{v}))
      & \mbox{by definition of $T+S$.}
    \end{array}
  \end{equation*}
  Therefore, $T+S$ preserves scalar multiplication, and hence $T+S$ is
  a linear transformation. The proof that $kT$ is a linear
  transformation is left as an exercise.
\end{proof}

There operations satisfy the following properties:

\begin{proposition}{Properties of addition and scalar multiplication of linear transformations}{properties-addition-linear-transformation}
  Let $V,W$ be vector spaces over a field $K$, let $T,S,R:V\to W$
  be linear transformations, and let $k,\ell\in K$ be scalars. Then
  the following hold:%
  \index{properties of addition!linear transformations}%
  \index{linear transformations!properties of addition}%
  \index{linear transformations!addition!properties}%
  \index{properties of scalar multiplication!linear transformations}%
  \index{linear transformations!properties of scalar multiplication}%
  \index{linear transformations!scalar multiplication!properties}
  \begin{itemize}\setlength\itemsep{0em}
  \item Commutative law of addition:
    $T+S = S+T$.
  \item Associative law of addition:
    $(T+S)+R = T+(S+R)$.
  \item The existence of an additive unit: there exists an element $\vect{0}\in
    V$ such that for all $T$,
    $T + 0 = T$.
  \item The law of additive inverses:
    $T + (-T) = 0$.
  \item The distributive law over vector addition:
    $k(T + S) = kT + kS$.
  \item The distributive law over scalar addition:
    $(k + \ell) T = k T + \ell T$.
  \item The associative law for scalar multiplication:
    $k(\ell T) = (k \ell)T$.
  \item The rule for multiplication by one:
    $1T=T$.
  \end{itemize}
\end{proposition}

But these 8 properties are just the vector space laws (A1)--(A4) and
(SM1)--(SM4)! Therefore, the set of linear transformations from $V$ to
$W$, with the above operations of addition and scalar multiplication,
forms a vector space.

\begin{definition}
  Let $V,W$ be vector spaces over a field $K$. We define $\Lin_{V,W}$%
  \index{vector space!of linear transformations}%
  \index{LinVW@$\Lin_{V,W}$} to be the vector space of all linear
  transformations from $V$ to $W$, with the above operations of
  addition and scalar multiplication.
\end{definition}

Another important operation is the composition of linear
transformations. We have already encountered this in
Definition~\ref{def:composite-transformations} for the case of
$\R^n$. Here, we generalize it to linear transformations of arbitrary
vector spaces.  We also consider the identity transformation on a
vector space, which forms the unit for composition.

\begin{definition}{Composition of linear transformations}{composition-linear-transformation}
  Let $V,U,W$ be vector spaces over a field $K$, and let $S:V\to U$
  and $T:U\to W$ be linear transformations.
  \begin{enumialphparenastyle}
    \begin{enumerate}
    \item The
      \textbf{composition}%
      \index{linear transformation!composition}%
      \index{composition of linear transformations} $T\circ S:V\to W$ is
      the linear transformation defined by
      \begin{equation*}
        (T\circ S) (\vect{v}) = T(S(\vect{v}))
      \end{equation*}
      for all $\vect{v}\in V$.
    \item The \textbf{identity transformation}%
      \index{identity transformation}%
      \index{linear transformation!identity transformation}
      $1_V:V\to V$ is defined by $1_V(\vect{v})=\vect{v}$ for all
      $\vect{v}\in V$. We often omit the subscript and just write
      $1:V\to V$ when $V$ is clear from the context.
    \end{enumerate}
  \end{enumialphparenastyle}
\end{definition}

Composition of linear transformations satisfies the following properties:

\begin{proposition}{Properties of composition of linear transformations}{properties-composition}
  Composition of linear transformations satisfies the following
  properties, for all $R,S,T$ as appropriate for each law:%
  \index{properties of composition!linear transformations}%
  \index{linear transformations!properties of composition}%
  \index{linear transformations!composition!properties}%
  \begin{itemize}\setlength\itemsep{0em}
  \item Associative law of composition: 
    $(T\circ S)\circ R = T\circ (S\circ R)$.
  \item Unit laws of composition: $T\circ 1_V = T$ and $1_W\circ T = T$, where
    $T:V\to W$.
  \item Distributive laws: $(T+S)\circ R = T\circ R + S\circ R$ and
    $P\circ (T+S) = P\circ T + P\circ S$.
  \item Zero laws: $0\circ R = 0$ and $R\circ 0 = 0$.
  \item Compatibility with scalar multiplication:
    $(kT)\circ S = k(T\circ S) = T\circ (kS)$, where $k\in K$.
  \end{itemize}
\end{proposition}

Finally, we consider the notion of the inverse of a linear
transformation.

\begin{definition}{Inverse of a linear transformation}{inverse-linear-transformation}
  Let $V,U$ be vector spaces over a field $K$, and let $S:V\to U$ and
  $T:U\to V$ be linear transformations.  We say that $S$ and $T$ are
  \textbf{inverses}%
  \index{inverse!of a linear transformation}%
  \index{linear transformation!inverse} if
  \begin{equation*}
    T\circ S = 1_V
    \quad\mbox{and}\quad
    S\circ T = 1_U.
  \end{equation*}
  In this case, we also write $S=T^{-1}$ and $T=S^{-1}$.  
\end{definition}

\begin{proposition}{Uniqueness of inverses}{uniqueness-inverses-linear-transformation}
  Inverses are unique. In other words, if $S$ and $S'$ are two inverses
  of $T$, then $S=S'$.
\end{proposition}

\begin{proof}
  Suppose both $S$ and $S'$ are inverses of $T$. Consider
  $S\circ T\circ S'$. Since $S$ and $T$ are inverses, this is equal to
  $S'$, but since $T$ and $S'$ are inverses, it is also equal to
  $S$. Therefore, $S=S'$.
\end{proof}

\begin{proposition}{Properties of inverses of linear transformations}{properties-inverse-linear-transformation}
  \begin{itemize}
  \item If $S:V\to U$ and $T:U\to W$ are both invertible, then so is
    $T\circ S$, and we have
    \begin{equation*}
      (T\circ S)^{-1} = S^{-1}\circ T^{-1}.
    \end{equation*}
  \item $1^{-1} = 1$.
  \item If $S:V\to U$ is invertible and $k$ is a non-zero scalar, then
    \begin{equation*}
      (kT)^{-1} = k^{-1}T^{-1}.
    \end{equation*}
  \end{itemize}
\end{proposition}

% ----------------------------------------------------------------------
\subsection{CONTINUE HERE...}

$T(v) = S(v)$: subspace

Consider the following example using the above theorem.

\begin{example}{Linear combination}{linear-transformation-combination2}
  Let $T:\Poly_2 \to \R$ be a linear transformation such that
  \begin{equation*}
    T(x^2+x)=-1; T(x^2-x)=1; T(x^2+1)=3.
  \end{equation*}
  Find $T(4x^2+5x-3)$.
\end{example}

\begin{solution}
  We provide two solutions to this problem.

  \textbf{Solution 1:}
  Suppose $a(x^2+x) + b(x^2-x) + c(x^2+1) = 4x^2+5x-3$.  Then
  \begin{equation*} (a+b+c)x^2 + (a-b)x + c = 4x^2+5x-3.\end{equation*}
  Solving for $a$, $b$, and $c$ results in the unique solution
  $a=6$, $b=1$, $c=-3$.

  Thus
  \begin{eqnarray*}
    T(4x^2+5x-3)
    & = & T(6(x^2+x) + (x^2-x) -3(x^2+1)) \\
    & = & 6T(x^2+x) + T(x^2-x) -3T(x^2+1) \\
    & = & 6(-1) + 1 -3(3) = -14.
  \end{eqnarray*}

  \textbf{Solution 2:}
  Notice that $S=\set{x^2+x, x^2-x, x^2+1}$ is a basis of $\Poly_2$,
  and thus $x^2$, $x$, and $1$ can each be written as a linear
  combination of elements of $S$.

  \begin{eqnarray*}
    x^2 & = & \textstyle \frac{1}{2}(x^2+x) + \frac{1}{2}(x^2-x) \\
    x & = & \textstyle \frac{1}{2}(x^2+x) - \frac{1}{2}(x^2-x) \\
    1 & = & (x^2+1)-\textstyle \frac{1}{2}(x^2+x) - \frac{1}{2}(x^2-x).
  \end{eqnarray*}
  Then
  \begin{eqnarray*}
    T(x^2)
    & = & \textstyle T\paren{\frac{1}{2}(x^2+x) + \frac{1}{2}(x^2-x)}
          =\frac{1}{2}T(x^2+x) + \frac{1}{2}T(x^2-x)\\
    & = & \textstyle \frac{1}{2}(-1) + \frac{1}{2}(1) = 0.  \\
    T(x)
    & = & \textstyle T\paren{\frac{1}{2}(x^2+x) - \frac{1}{2}(x^2-x)}
          = \frac{1}{2}T(x^2+x) - \frac{1}{2}T(x^2-x) \\
    & = & \textstyle \frac{1}{2}(-1) - \frac{1}{2}(1) = -1.\\
    T(1)
    & = & \textstyle T\paren{(x^2+1)-\frac{1}{2}(x^2+x) -
          \frac{1}{2}(x^2-x)}\\
    & = & \textstyle T(x^2+1)-\frac{1}{2}T(x^2+x) - \frac{1}{2}T(x^2-x) \\
    & = & \textstyle 3-\frac{1}{2}(-1) - \frac{1}{2}(1) = 3.
  \end{eqnarray*}
  Therefore,
  \begin{eqnarray*}
    T(4x^2+5x-3) & = & 4T(x^2) + 5T(x) -3T(1) \\
                 & = & 4(0) + 5(-1) - 3(3)=-14.
  \end{eqnarray*}
  The advantage of \textbf{Solution 2} over \textbf{Solution 1} is
  that if you were now asked to find $T(-6x^2-13x+9)$, it is easy to
  use $T(x^2)=0$, $T(x)=-1$ and $T(1)= 3$:
  \begin{eqnarray*}
    T(-6x^2-13x+9) & = & -6T(x^2)-13T(x)+9T(1) \\
                   & = & -6(0)-13(-1)+9(3)=13+27=40.
  \end{eqnarray*}
  More generally,
  \begin{eqnarray*}
    T(ax^2+bx+c) & = & aT(x^2)+bT(x)+cT(1) \\
                 & = & a(0)+b(-1)+c(3)=-b+3c.
  \end{eqnarray*}
\end{solution}

The next theorem argues that it is only necessary to check the action
of the transformations on basis vectors.

\begin{theorem}{Transformation of a spanning set}{transformation-spanning-set}
  Let $V$ and $W$ be vector spaces and suppose that $S$ and $T$ are
  linear transformations from $V$ to $W$. Then in order for $S$ and
  $T$ to be equal, it suffices that $S(\vect{v}_i) = T(\vect{v}_i)$
  where $V=\sspan \set{\vect{v}_1, \vect{v}_2, \ldots, \vect{v}_n}$.
\end{theorem}

This theorem tells us that a linear transformation is completely
determined by its actions on a spanning set. We can also examine the
effect of a linear transformation on a basis.

\begin{theorem}{Transformation of a basis}{transformation-basis}
  Suppose $V$ and $W$ are vector spaces and let
  $\set{\vect{w}_1, \vect{w}_2, \ldots, \vect{w}_n}$ be any given
  vectors in $W$ that may not be distinct. Then there exists a basis
  $\set{\vect{v}_1, \vect{v}_2, \ldots, \vect{v}_n}$ of $V$ and a
  unique linear transformation $T: V \to W$ with
  $T (\vect{v}_i) = \vect{w}_i$.

  Furthermore, if
  \begin{equation*}
    \vect{v} = k_1\vect{v}_1+k_2\vect{v}_2+\ldots+ k_n\vect{v}_n
  \end{equation*}
  is a vector of $V$, then
  \begin{equation*}
    T(\vect{v}) = k_1\vect{w}_1+k_2\vect{w}_2+\ldots+ k_n\vect{w}_n.
  \end{equation*}
\end{theorem}
