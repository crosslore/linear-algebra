\section{Determinants and row operations}

Recall that there are three kinds of elementary row operations%
\index{matrix!row operation}%
\index{matrix!elementary row operation}%
\index{row operation}%
\index{elementary row operation} on matrices:
\begin{enumerate}
\item Switch two rows.
\item Multiply a row by a non-zero number.
\item Add a multiple of one row to another row.
\end{enumerate}
The following theorem examines the effect of these row operations on
the determinant of a matrix.

\begin{theorem}{Effect of row operations on the determinant}{determinant-row-operations}
  Let $A$ be an $n\times n$-matrix.
  \begin{enumerate}
  \item If $B$ is obtained from $A$ by switching two rows, then
    \begin{equation*}
      \det(B) = -\det(A).
    \end{equation*}
  \item If $B$ is obtained from $A$ by multiplying one row by a
    non-zero scalar $k$, then
    \begin{equation*}
      \det(B) = k\det(A).
    \end{equation*}
  \item If $B$ is obtained from $A$ by adding a multiple of one row to
    another row, then
    \begin{equation*}
      \det(B) = \det(A).
    \end{equation*}
  \end{enumerate}
\end{theorem}

Notice that the second part of this theorem is true when we multiply
{\em one} row of the matrix by $k$.  If we were to multiply {\em two}
rows of $A$ by $k$ to obtain $B$, we would have
$\det(B) = k^2 \det(A)$.

\begin{example}{Using row operations to calculate a determinant}{determinant-row-operations1}
  Use row operations to calculate the following determinant:
  \begin{equation*}
    \begin{absmatrix}{rrr}
      1 & 5 & 5 \\
      0 & 0 & -3 \\
      0 & 2 & 7 \\
    \end{absmatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  If we switch the second and third rows, we obtain a triangular
  matrix, of which the determinant is easy to compute. By
  Theorem~\ref{thm:determinant-row-operations}, switching two rows
  negates the determinant. We therefore have:
  \begin{equation*}
    \begin{absmatrix}{rrr}
      1 & 5 & 5 \\
      0 & 0 & -3 \\
      0 & 2 & 7 \\
    \end{absmatrix}
    ~=~
    -\begin{absmatrix}{rrr}
      1 & 5 & 5 \\
      0 & 2 & 7 \\
      0 & 0 & -3 \\
    \end{absmatrix}
    ~=~ -(1\cdot 2\cdot(-3)) ~=~ 6.
  \end{equation*}
\end{solution}

\begin{example}{Using row operations to calculate a determinant}{determinant-row-operations2}
  Use row operations to calculate the following determinant:
  \begin{equation*}
    \begin{absmatrix}{rrr}
      1 & 4 & -2 \\
      1 & 8 & 1 \\
      2 & 4 & -9 \\
    \end{absmatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We can use elementary row operations to reduce this matrix to
  triangular form:
  \begin{equation*}
    \begin{mymatrix}{rrr}
      1 & 4 & -2 \\
      1 & 8 & 1 \\
      2 & 4 & -9 \\
    \end{mymatrix}
    \stackrel{R_2\rowop R_2-R_1}{\sim}
    \begin{mymatrix}{rrr}
      1 & 4 & -2 \\
      0 & 4 & 3 \\
      2 & 4 & -9 \\
    \end{mymatrix}
    \stackrel{R_3\rowop R_3-2R_1}{\sim}
    \begin{mymatrix}{rrr}
      1 & 4 & -2 \\
      0 & 4 & 3 \\
      0 & -4 & -5 \\
    \end{mymatrix}
    \stackrel{R_3\rowop R_3+R_2}{\sim}
    \begin{mymatrix}{rrr}
      1 & 4 & -2 \\
      0 & 4 & 3 \\
      0 & 0 & -2 \\
    \end{mymatrix}.
  \end{equation*}
  Each of the row operations is of the form ``add a multiple of one
  row to another row'', and therefore does not change the
  determinant. We therefore have:
  \begin{equation*}
    \begin{absmatrix}{rrr}
      1 & 4 & -2 \\
      1 & 8 & 1 \\
      2 & 4 & -9 \\
    \end{absmatrix}
    ~=~
    \begin{absmatrix}{rrr}
      1 & 4 & -2 \\
      0 & 4 & 3 \\
      2 & 4 & -9 \\
    \end{absmatrix}
    ~=~
    \begin{absmatrix}{rrr}
      1 & 4 & -2 \\
      0 & 4 & 3 \\
      0 & -4 & -5 \\
    \end{absmatrix}
    ~=~
    \begin{absmatrix}{rrr}
      1 & 4 & -2 \\
      0 & 4 & 3 \\
      0 & 0 & -2 \\
    \end{absmatrix}
    ~=~ 1\cdot 4\cdot(-2) = -8.
  \end{equation*}
\end{solution}

In general, we can convert any square matrix to triangular form using
elementary row operations. In fact, it is always possible to do so
using only elementary operations of the first and third kind (swap two
rows or add a multiple of one row to another). This gives us a very
efficient way to compute determinants. If the matrices are large, this
method is much more efficient than the cofactor method.

\begin{example}{Using row operations to calculate a determinant}{determinant-row-operations3}
  Use elementary row operations of the first and third kind to calculate the
  following determinant:
  \begin{equation*}
    \begin{absmatrix}{rrrr}
      0 & 2 & 1 & 4 \\
      2 & 2 & -4 & -1 \\
      1 & 1 & -2 & -1 \\
      1 & 3 & 2 & 5 \\
    \end{absmatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We use elementary row operations to reduce the matrix to triangular
  form:
  \begin{equation*}
    \begin{array}{ccccc}
      \begin{mymatrix}{rrrr}
        0 & 2 & 1 & 4 \\
        2 & 2 & -4 & -1 \\
        1 & 1 & -2 & -1 \\
        1 & 3 & 2 & 5 \\
      \end{mymatrix}
      &\stackrel{R_1\rowswap R_3}{\sim}&
      \begin{mymatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        2 & 2 & -4 & -1 \\
        0 & 2 & 1 & 4 \\
        1 & 3 & 2 & 5 \\
      \end{mymatrix}
      &\stackrel{R_2\rowop R_2-2R_1}{\sim}&
      \begin{mymatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 0 & 0 & 1 \\
        0 & 2 & 1 & 4 \\
        1 & 3 & 2 & 5 \\
      \end{mymatrix}
      \\\\[-1ex]
      &\stackrel{R_4\rowop R_4-R_1}{\sim}&
      \begin{mymatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 0 & 0 & 1 \\
        0 & 2 & 1 & 4 \\
        0 & 2 & 4 & 6 \\
      \end{mymatrix}
      &\stackrel{R_4\rowop R_4-R_3}{\sim}&
      \begin{mymatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 0 & 0 & 1 \\
        0 & 2 & 1 & 4 \\
        0 & 0 & 3 & 2 \\
      \end{mymatrix}
      \\\\[-1ex]
      &\stackrel{R_2\rowswap R_3}{\sim}&
      \begin{mymatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 2 & 1 & 4 \\
        0 & 0 & 0 & 1 \\
        0 & 0 & 3 & 2 \\
      \end{mymatrix}
      &\stackrel{R_3\rowswap R_4}{\sim}&
      \begin{mymatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 2 & 1 & 4 \\
        0 & 0 & 3 & 2 \\
        0 & 0 & 0 & 1 \\
      \end{mymatrix}
    \end{array}
  \end{equation*}
  By Theorem~\ref{thm:determinant-row-operations}, the determinant
  changes signs each time we swap two rows. The determinant is
  unchanged when we add a multiple of one row to another. Therefore,
  we have
  \begin{equation*}
    \begin{array}{ccccccc}
      \begin{absmatrix}{rrrr}
        0 & 2 & 1 & 4 \\
        2 & 2 & -4 & -1 \\
        1 & 1 & -2 & -1 \\
        1 & 3 & 2 & 5 \\
      \end{absmatrix}
      &=&
      -\begin{absmatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        2 & 2 & -4 & -1 \\
        0 & 2 & 1 & 4 \\
        1 & 3 & 2 & 5 \\
      \end{absmatrix}
      &=&
      -\begin{absmatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 0 & 0 & 1 \\
        0 & 2 & 1 & 4 \\
        1 & 3 & 2 & 5 \\
      \end{absmatrix}
      \\\\[-1ex]
      &=&
      -\begin{absmatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 0 & 0 & 1 \\
        0 & 2 & 1 & 4 \\
        0 & 2 & 4 & 6 \\
      \end{absmatrix}
      &=&
      -\begin{absmatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 0 & 0 & 1 \\
        0 & 2 & 1 & 4 \\
        0 & 0 & 3 & 2 \\
      \end{absmatrix}
      \\\\[-1ex]
      &=&
      +\begin{absmatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 2 & 1 & 4 \\
        0 & 0 & 0 & 1 \\
        0 & 0 & 3 & 2 \\
      \end{absmatrix}
      &=&
      -\begin{absmatrix}{rrrr}
        1 & 1 & -2 & -1 \\
        0 & 2 & 1 & 4 \\
        0 & 0 & 3 & 2 \\
        0 & 0 & 0 & 1 \\
      \end{absmatrix}
      &=& -6.
    \end{array}
  \end{equation*}
  In practice, the last calculation could have been done in a single
  step. All we had to do is count the number of swap operations we
  performed during the row operations. If there is an odd number of
  swap operations, the sign of the determinant changes; otherwise, it
  stays the same.
\end{solution}

% ----------------------------------------------------------------------
\section{Properties of determinants}

One reason that the determinant is such an important quantity is that
it permits us to tell whether a square matrix is invertible.

\begin{theorem}{Determinants and invertible matrices}{determinant-invertible}
  Let $A$ be an $n\times n$-matrix. Then $A$ is invertible%
  \index{determinant!and invertibility}%
  \index{matrix!determinant!and invertibility}%
  \index{invertible matrix!and determinant}%
  \index{matrix!invertible!and determinant} if and
  only if $\det(A) \neq 0$.
\end{theorem}

\begin{proof}
  We know that every matrix $A$ can be converted to echelon form by
  elementary row operations. We also know from
  Theorem~\ref{thm:determinant-row-operations} that no elementary row
  operation changes whether the determinant is zero or not.  Let $R$
  be an echelon form of $A$. Because $R$ is an echelon form, it is
  also an upper triangular matrix. Case 1: $A$ is invertible. In that
  case, the rank of $R$ is $n$, and every diagonal entry of $R$ is a
  pivot entry (therefore non-zero). It follows that $\det(R)\neq 0$,
  which implies $\det(A)\neq 0$. Case 2: $A$ is not invertible. In
  that case, the triangular matrix $R$ contains a row of zeros. It
  follows that $\det(R)=0$, and therefore $\det(A)=0$.
\end{proof}

\begin{example}{Determinants and invertible matrices}{determinant-invertible}
  Determine which of the following matrices are invertible by
  computing their determinants.
  \begin{equation*}
    A = \begin{mymatrix}{rr}
      3 & 6 \\
      2 & 4 \\
    \end{mymatrix},\quad
    B = \begin{mymatrix}{rr}
      2 & 3 \\
      5 & 1 \\
    \end{mymatrix},\quad
    C = \begin{mymatrix}{rrr}
      1 & 2 & -5 \\
      2 & 0 & 2  \\
      3 & 1 & 0  \\
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We have $\det(A) = 3\cdot 4 - 2\cdot 6 = 0$ and $\det(B) = 2\cdot
  1-5\cdot 3 = -13$. Therefore, $B$ is invertible and $A$ is not
  invertible. A quick way to compute the determinant of $C$ is to
  expand it along the third row. We have
  \begin{equation*}
    \det(C)
    = 3\begin{absmatrix}{rr}
      2 & -5 \\
      0 & 2 \\
    \end{absmatrix}
    - 1\begin{absmatrix}{rr}
      1 & -5 \\
      2 & 2 \\
    \end{absmatrix}
    = 3\cdot 4 - 1\cdot 12 = 0.
  \end{equation*}
  Therefore, $C$ is not invertible.
\end{solution}

Another reason the determinant is important is that it compatible with
matrix product.

\begin{theorem}{Determinant of a product}{determinant-of-product}
  Let $A$ and $B$ be $n\times n$-matrices. Then%
  \index{determinant!of product}%
  \index{matrix!determinant!of product}%
  \index{matrix!multiplication!determinant of product}%
  \index{multiplication!determinant of product}%
  \begin{equation*}
    \det(AB) =\det(A)\det(B)
  \end{equation*}
\end{theorem}

\begin{proof}
  We first prove this in case $A=E$ is an elementary matrix. Remember
  from Section~\ref{sec:elementary-matrices} that elementary matrices
  correspond to elementary row operations.
  \begin{enumerate}
  \item If $E$ is an elementary matrix for swapping two rows, then
    $\det(E)=-1$. Also, by Theorem~\ref{thm:determinant-row-operations}(1),
    $\det(EB)=-\det(B)$. Therefore $\det(EB)=\det(E)\det(B)$.
  \item If $E$ is an elementary matrix for multiplying a row by a
    non-zero scalar $k$, then $\det(E)=k$. Also, by
    Theorem~\ref{thm:determinant-row-operations}(2),
    $\det(EB)=k\det(B)$. Therefore $\det(EB)=\det(E)\det(B)$.
  \item If $E$ is an elementary matrix for adding a multiple of one
    row to another, then $\det(E)=1$. Also, by
    Theorem~\ref{thm:determinant-row-operations}(3),
    $\det(EB)=\det(B)$. Therefore $\det(EB)=\det(E)\det(B)$.
  \end{enumerate}
  Now consider the case where $A$ is an arbitrary matrix. Case 1: $A$
  is invertible. Then by Theorem~\ref{thm:prod-elementary}, we can
  write $A$ as a product of elementary matrices $A=E_1E_2\cdots E_k$.
  By repeatedly using the formula $\det(EB)=\det(E)\det(B)$ that we
  proved above, we have
  \begin{equation*}
    \det(AB) = \det(E_1E_2\cdots E_kB) = \det(E_1)\det(E_2)\cdots\det(E_k)\det(B)
    = \det(A)\det(B).
  \end{equation*}
  Case 2: $A$ is not invertible. Then $AB$ is also not invertible
  (because if $C$ were an inverse of $AB$, we would have $ABC=I$, and
  therefore, $BC$ would be an inverse of $A$). Therefore, by
  Theorem~\ref{thm:determinant-invertible}, we have $\det(A)=0$ and
  $\det(AB)=0$. It follows that $\det(AB)=\det(A)\det(B)$.
\end{proof}

\begin{example}{The determinant of a product}{determinant-of-product}
  Compare $\det(AB) $ and $\det(A)\det(B)$, where
  \begin{equation*}
    A=\begin{mymatrix}{rr}
      1 & 2 \\
      -3 & 2
    \end{mymatrix}
    \quad\mbox{and}\quad
    B=\begin{mymatrix}{rr}
      3 & 2 \\
      4 & 1
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We first compute $AB$:
  \begin{equation*}
    AB=\begin{mymatrix}{rr}
      1 & 2 \\
      -3 & 2
    \end{mymatrix} \begin{mymatrix}{rr}
      3 & 2 \\
      4 & 1
    \end{mymatrix} = \begin{mymatrix}{rr}
      11 & 4 \\
      -1 & -4
    \end{mymatrix}.
  \end{equation*}
  The three determinants are
  \begin{equation*}
    \det(AB) = \begin{absmatrix}{rr}
      11 & 4 \\
      -1 & -4
    \end{absmatrix} = -40,
    \quad
    \det(A) = \begin{absmatrix}{rr}
      1 & 2 \\
      -3 & 2
    \end{absmatrix} = 8,
    \quad\mbox{and}\quad
    \det(B) = \begin{absmatrix}{rr}
      3 & 2 \\
      4 & 1
    \end{absmatrix} = -5.
  \end{equation*}
  Therefore $\det(A)\det(B) = 8\cdot(-5) = -40 = \det(AB)$. 
\end{solution}

The following theorem summarizes some properties of determinants we
have discussed so far, as well as additional properties.

\begin{theorem}{Properties of determinants}{properties-of-determinants}
  Let $A,B$ be $n\times n$-matrices. Then:%
  \index{determinant!properties of}%
  \index{properties of determinants}%
  \index{matrix!determinant!properties}%
  \index{matrix!properties of determinants}
  \begin{enumerate}
  \item $\det(AB)=\det(A)\det(B)$.
  \item $\det(I) = 1$.
  \item $A$ is invertible if and only if $\det(A)\neq 0$. Moreover, if
    this is the case, then
    \begin{equation*}
      \det(A^{-1}) = \frac{1}{\det(A)}.
    \end{equation*}
  \item $\det(kA)=k^n\det(A)$.
  \item $\det(A^T) = \det(A)$.
  \end{enumerate}
\end{theorem}

\begin{proof}
  Property 1 is a restatement of
  Theorem~\ref{thm:determinant-of-product}. Property 2 follows from
  Theorem~\ref{thm:determinant-of-triangular-matrix}, because the
  identity matrix is an upper triangular matrix. Property 3: The first
  part is Theorem~\ref{thm:determinant-invertible}. For the second
  part, assume $A$ is invertible. Then by properties 1 and 2,
  $\det(A)\det(A^{-1}) = \det(AA^{-1}) = \det(I) = 1$. The claim
  follows by dividing both sides of the equation by
  $\det(A)$. Property 4 follows from
  Theorem~\ref{thm:determinant-row-operations}(2), because $kA$ is
  obtained from $A$ by multiplying all $n$ rows by $k$. Each time we
  multiple one row by $k$, the determinant is multiplied by
  $k$. Property 5 follows because expanding $\det(A)$ along columns
  amounts to the same thing as expanding $\det(A^T)$ along rows.
\end{proof}

We end this section with a few useful ways of spotting matrices of
determinant 0.

\begin{theorem}
  Let $A$ be an $n\times n$-matrix.
  \begin{enumerate}
  \item If $A$ has a row consisting only of zeros, or a column
    consisting only of zeros, then $\det(A)=0$.
  \item If $A$ has a row that is a scalar multiple of another row, or
    a column that is a scalar multiple of another column, then
    $\det(A)=0$. 
  \end{enumerate}
\end{theorem}

\begin{proof}
  The first property follows by cofactor expansion: simply expand the
  determinant along the row or column that consists only of zeros.
  For the second property, assume that $A$ has a row that is a scalar
  multiple of another row. We can then perform an elementary row
  operation to create a row of zeros. By
  Theorem~\ref{thm:determinant-row-operations}(3), the determinant is
  unchanged, so that $\det(A)=0$. In the case that $A$ has a column
  that is a scalar multiple of another column, we apply the same
  reasoning to $A^T$ and use the fact that $\det(A)=\det(A^T)$.
\end{proof}
