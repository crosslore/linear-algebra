\section{Properties of determinants}

\begin{outcome}
  \begin{enumerate}
  \item Use the determinant of a square matrix to decide whether the
    matrix is invertible.
  \item From the determinants of two matrices, calculate the
    determinant of their product. 
  \item From the determinant of a matrix, calculate the determinant of
    its inverse.
  \item From the determinant of a matrix, calculate the determinant of
    its transpose.
  \item Calculate the determinant of $kA$, if the determinant of $A$
    is known.
  \item Without calculation, find the determinant of a matrix
    containing a row or column of zeros, or a matrix containing a row
    (or column) that is a scalar multiple of another row (or column).
  \item Use algebraic properties to reason about determinants.
  \end{enumerate}
\end{outcome}

One reason that the determinant is such an important quantity is that
it permits us to tell whether a square matrix is invertible.

\begin{theorem}{Determinants and invertible matrices}{determinant-invertible}
  Let $A$ be an $n\times n$-matrix. Then $A$ is invertible%
  \index{determinant!and invertibility}%
  \index{matrix!determinant!and invertibility}%
  \index{invertible matrix!and determinant}%
  \index{matrix!invertible!and determinant} if and
  only if $\det(A) \neq 0$.
\end{theorem}

\begin{proof}
  We know that every matrix $A$ can be converted to echelon form by
  elementary row operations. We also know from
  Theorem~\ref{thm:determinant-row-operations} that no elementary row
  operation changes whether the determinant is zero or not.  Let $R$
  be an echelon form of $A$. Because $R$ is an echelon form, it is
  also an upper triangular matrix. Case 1: $A$ is invertible. In that
  case, the rank of $R$ is $n$, and every diagonal entry of $R$ is a
  pivot entry (therefore non-zero). It follows that $\det(R)\neq 0$,
  which implies $\det(A)\neq 0$. Case 2: $A$ is not invertible. In
  that case, the triangular matrix $R$ contains a row of zeros. It
  follows that $\det(R)=0$, and therefore $\det(A)=0$.
\end{proof}

\begin{example}{Determinants and invertible matrices}{determinant-invertible}
  Determine which of the following matrices are invertible by
  computing their determinants.
  \begin{equation*}
    A = \begin{mymatrix}{rr}
      3 & 6 \\
      2 & 4 \\
    \end{mymatrix},\quad
    B = \begin{mymatrix}{rr}
      2 & 3 \\
      5 & 1 \\
    \end{mymatrix},\quad
    C = \begin{mymatrix}{rrr}
      1 & 2 & -5 \\
      2 & 0 & 2  \\
      3 & 1 & 0  \\
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We have $\det(A) = 3\cdot 4 - 2\cdot 6 = 0$ and $\det(B) = 2\cdot
  1-5\cdot 3 = -13$. Therefore, $B$ is invertible and $A$ is not
  invertible. A quick way to compute the determinant of $C$ is to
  expand it along the third row. We have
  \begin{equation*}
    \det(C)
    = 3\begin{absmatrix}{rr}
      2 & -5 \\
      0 & 2 \\
    \end{absmatrix}
    - 1\begin{absmatrix}{rr}
      1 & -5 \\
      2 & 2 \\
    \end{absmatrix}
    = 3\cdot 4 - 1\cdot 12 = 0.
  \end{equation*}
  Therefore, $C$ is not invertible.
\end{solution}

Another reason the determinant is important is that it compatible with
matrix product.

\begin{theorem}{Determinant of a product}{determinant-of-product}
  Let $A$ and $B$ be $n\times n$-matrices. Then%
  \index{determinant!of product}%
  \index{matrix!determinant!of product}%
  \index{matrix!multiplication!determinant of product}%
  \index{multiplication!determinant of product}%
  \begin{equation*}
    \det(AB) =\det(A)\det(B)
  \end{equation*}
\end{theorem}

\begin{proof}
  We first prove this in case $A=E$ is an elementary matrix. Remember
  from Section~\ref{sec:elementary-matrices} that elementary matrices
  correspond to elementary row operations.
  \begin{enumerate}
  \item If $E$ is an elementary matrix for swapping two rows, then
    $\det(E)=-1$. Also, by Theorem~\ref{thm:determinant-row-operations}(1),
    $\det(EB)=-\det(B)$. Therefore $\det(EB)=\det(E)\det(B)$.
  \item If $E$ is an elementary matrix for multiplying a row by a
    non-zero scalar $k$, then $\det(E)=k$. Also, by
    Theorem~\ref{thm:determinant-row-operations}(2),
    $\det(EB)=k\det(B)$. Therefore $\det(EB)=\det(E)\det(B)$.
  \item If $E$ is an elementary matrix for adding a multiple of one
    row to another, then $\det(E)=1$. Also, by
    Theorem~\ref{thm:determinant-row-operations}(3),
    $\det(EB)=\det(B)$. Therefore $\det(EB)=\det(E)\det(B)$.
  \end{enumerate}
  Now consider the case where $A$ is an arbitrary matrix. Case 1: $A$
  is invertible. Then by Theorem~\ref{thm:prod-elementary}, we can
  write $A$ as a product of elementary matrices $A=E_1E_2\cdots E_k$.
  By repeatedly using the formula $\det(EB)=\det(E)\det(B)$ that we
  proved above, we have
  \begin{equation*}
    \det(AB) = \det(E_1E_2\cdots E_kB) = \det(E_1)\det(E_2)\cdots\det(E_k)\det(B)
    = \det(A)\det(B).
  \end{equation*}
  Case 2: $A$ is not invertible. Then $AB$ is also not invertible
  (because if $C$ were an inverse of $AB$, we would have $ABC=I$, and
  therefore, $BC$ would be an inverse of $A$). Therefore, by
  Theorem~\ref{thm:determinant-invertible}, we have $\det(A)=0$ and
  $\det(AB)=0$. It follows that $\det(AB)=\det(A)\det(B)$.
\end{proof}

\begin{example}{The determinant of a product}{determinant-of-product}
  Compare $\det(AB) $ and $\det(A)\det(B)$, where
  \begin{equation*}
    A=\begin{mymatrix}{rr}
      1 & 2 \\
      -3 & 2
    \end{mymatrix}
    \quad\mbox{and}\quad
    B=\begin{mymatrix}{rr}
      3 & 2 \\
      4 & 1
    \end{mymatrix}.
  \end{equation*}
\end{example}

\begin{solution}
  We first compute $AB$:
  \begin{equation*}
    AB=\begin{mymatrix}{rr}
      1 & 2 \\
      -3 & 2
    \end{mymatrix} \begin{mymatrix}{rr}
      3 & 2 \\
      4 & 1
    \end{mymatrix} = \begin{mymatrix}{rr}
      11 & 4 \\
      -1 & -4
    \end{mymatrix}.
  \end{equation*}
  The three determinants are
  \begin{equation*}
    \det(AB) = \begin{absmatrix}{rr}
      11 & 4 \\
      -1 & -4
    \end{absmatrix} = -40,
    \quad
    \det(A) = \begin{absmatrix}{rr}
      1 & 2 \\
      -3 & 2
    \end{absmatrix} = 8,
    \quad\mbox{and}\quad
    \det(B) = \begin{absmatrix}{rr}
      3 & 2 \\
      4 & 1
    \end{absmatrix} = -5.
  \end{equation*}
  Therefore $\det(A)\det(B) = 8\cdot(-5) = -40 = \det(AB)$. 
\end{solution}

The following theorem summarizes some properties of determinants we
have discussed so far, as well as additional properties.

\begin{theorem}{Properties of determinants}{properties-of-determinants}
  Let $A,B$ be $n\times n$-matrices. Then:%
  \index{determinant!properties of}%
  \index{properties of determinants}%
  \index{matrix!determinant!properties}%
  \index{matrix!properties of determinants}
  \begin{enumerate}
  \item $\det(AB)=\det(A)\det(B)$.
  \item $\det(I) = 1$.
  \item $A$ is invertible if and only if $\det(A)\neq 0$. Moreover, if
    this is the case, then
    \begin{equation*}
      \det(A^{-1}) = \frac{1}{\det(A)}.
    \end{equation*}
  \item $\det(kA)=k^n\det(A)$.
  \item $\det(A^T) = \det(A)$.
  \end{enumerate}
\end{theorem}

\begin{proof}
  Property 1 is a restatement of
  Theorem~\ref{thm:determinant-of-product}. Property 2 follows from
  Theorem~\ref{thm:determinant-of-triangular-matrix}, because the
  identity matrix is an upper triangular matrix. Property 3: The first
  part is Theorem~\ref{thm:determinant-invertible}. For the second
  part, assume $A$ is invertible. Then by properties 1 and 2,
  $\det(A)\det(A^{-1}) = \det(AA^{-1}) = \det(I) = 1$. The claim
  follows by dividing both sides of the equation by
  $\det(A)$. Property 4 follows from
  Theorem~\ref{thm:determinant-row-operations}(2), because $kA$ is
  obtained from $A$ by multiplying all $n$ rows by $k$. Each time we
  multiple one row by $k$, the determinant is multiplied by
  $k$. Property 5 follows because expanding $\det(A)$ along columns
  amounts to the same thing as expanding $\det(A^T)$ along rows.
\end{proof}

We end this section with a few useful ways of spotting matrices of
determinant 0.

\begin{theorem}
  Let $A$ be an $n\times n$-matrix.
  \begin{enumerate}
  \item If $A$ has a row consisting only of zeros, or a column
    consisting only of zeros, then $\det(A)=0$.
  \item If $A$ has a row that is a scalar multiple of another row, or
    a column that is a scalar multiple of another column, then
    $\det(A)=0$. 
  \end{enumerate}
\end{theorem}

\begin{proof}
  The first property follows by cofactor expansion: simply expand the
  determinant along the row or column that consists only of zeros.
  For the second property, assume that $A$ has a row that is a scalar
  multiple of another row. We can then perform an elementary row
  operation to create a row of zeros. By
  Theorem~\ref{thm:determinant-row-operations}(3), the determinant is
  unchanged, so that $\det(A)=0$. In the case that $A$ has a column
  that is a scalar multiple of another column, we apply the same
  reasoning to $A^T$ and use the fact that $\det(A)=\det(A^T)$.
\end{proof}
